1. Graph Clustering & Cuts

 Min Cut / Max Flow:

(Algorithms) Max-flow / Min-cut Theorem by WilliamFiset: Explains the core theorem connecting flow and cuts, often used for standard min-cut.

 https://www.youtube.com/watch?v=oHy3ddI9X3o

 Normalized Cut & Spectral Clustering (Often Covered Together):

(Stanford CS224W) Spectral Clustering by Jure Leskovec: A detailed lecture covering graph Laplacians and their connection to cuts, including Normalized Cut.

 https://www.youtube.com/watch?v=mVkg5FMmLts (Part of a larger lecture, focus on spectral clustering section)

(StatQuest) Spectral Clustering, step-by-step by Josh Starmer: Excellent intuitive explanation of the motivation and steps involved.

 https://www.youtube.com/watch?v=QXokLdRBWQE

2. Random Walks & Markov Chains

 Markov Chains Basics:

(StatQuest) Markov Chains, Clearly Explained! by Josh Starmer: Fundamental concepts explained intuitively.

 https://www.youtube.com/watch?v=i3AkTO90iZM

(3Blue1Brown) Markov chains: Visual intuition behind Markov chains (part of a series).

 https://www.youtube.com/watch?v=d7K_fYPZj_o

 PageRank (Related to Random Walks with Restarts):

(Computerphile) How Google PageRank Works: Explains the core idea of random walks and restarts in the context of PageRank.

 https://www.youtube.com/watch?v=JGQe4kiPnrU

 Markov Clustering (MCL): (Fewer dedicated videos, often mentioned within broader clustering topics)

Search results for "Markov Clustering algorithm explained" might yield specific implementations or shorter explanations. Often covered in bioinformatics contexts.

3. Spectral Clustering (Deeper Dive)

 (See CS224W and StatQuest links under "Normalized Cut" above) They are the primary topic here.

 Graph Laplacian:

(YouTube Search) "Graph Laplacian intuition" or "Graph Laplacian properties": Many videos explain the construction and meaning of the Laplacian matrix. Look for ones explaining the


L=D−WL=D−W

   

definition and the quadratic form


xTLxxTLx

   

.

4. Embeddings & Graph Neural Networks (GNNs)

 Graph Embeddings Introduction:

(Stanford CS224W) Node Embeddings by Jure Leskovec: Covers the motivation and early methods like DeepWalk, Node2Vec (builds foundations for GNNs).

 https://www.youtube.com/watch?v=YvMQG38rVGE (Check the CS224W playlist for the most relevant version)

 GNN Introduction:

(Computerphile) Graph Neural Networks: A high-level overview of what GNNs are and why they are used.

 https://www.youtube.com/watch?v=ihkQ19d632A

(DeepFindr) Graph Neural Networks (GNN) Explained: A concise explanation of the core message passing idea.

 https://www.youtube.com/watch?v=6pICm8Sl36A

 Specific GNN Architectures (GCN, GraphSAGE, GAT):

(Stanford CS224W) Graph Neural Networks 1 & 2 by Jure Leskovec: Covers the foundations and specific architectures like GCN, GraphSAGE in detail.

 Lecture 6: https://www.youtube.com/watch?v=GRCNL6mv3p4

 Lecture 7: https://www.youtube.com/watch?v=QLVMqwpOLPk (Includes GAT)

(YouTube Search) "GCN explained", "GraphSAGE tutorial", "Graph Attention Network GAT": Many tutorials explain these specific models. Look for channels like "AI Coffee Break", "DeepFindr", "Aladdin Persson".

 GNN Expressivity & WL Test:

(Stanford CS224W) GNN Design Space / Theory of GNNs by Jure Leskovec: Discusses limitations, expressivity, and the connection to the WL test.

 (Check relevant lectures in the CS224W series, often around Lecture 8 or later theory lectures)

(Michael Bronstein) Geometric Deep Learning & Graph Neural Networks: More advanced talks often touch upon the theoretical underpinnings and expressivity.

 Search for talks by him, e.g., https://www.youtube.com/watch?v=Lsi17LCzl7E (example talk)

5. Search & Indexing (k-d Trees)

 k-d Trees Explained:

(Algorithms) K-D Tree Construction and Nearest Neighbor Search by WilliamFiset: Detailed explanation of building and querying k-d trees.

 https://www.youtube.com/watch?v=Glp7tvIzbXI

(Computerphile) K-D Trees: Conceptual overview.

 https://www.youtube.com/watch?v=W94M9D_yN4g

6. Locality Sensitive Hashing (LSH)

 LSH Explained:

(Stanford CS231n) Lecture on Approximate Nearest Neighbors (includes LSH): Often covered in computer vision or ML courses.

 Search for CS231n lectures on ANN/LSH.

(Alexander Ihler) Locality Sensitive Hashing (LSH): A university lecture style explanation.

 https://www.youtube.com/watch?v=Arni-Td1F90

(Victor Lavrenko) Locality Sensitive Hashing: Another lecture-style explanation covering the core concepts.

 https://www.youtube.com/watch?v=DZhl94cRAy0

7. Data Streams

 Reservoir Sampling:

(Algorithms) Reservoir Sampling by WilliamFiset: Clear explanation and proof.

 https://www.youtube.com/watch?v=A1iwzSew5QY

(Computer Science) Reservoir Sampling: Another clear explanation.

 https://www.youtube.com/watch?v=Ybra0uGEkEU

 Bloom Filters:

(Computerphile) Bloom Filters: Excellent conceptual explanation.

 https://www.youtube.com/watch?v=qBTduKbGH7c

(Algorithms) Bloom Filters by WilliamFiset: More detailed look at implementation and probability.

 https://www.youtube.com/watch?v=XMZDNtttu44

 Frequent Items / Space-Saving:

(CMU Databases) Lecture on Stream Mining (Heavy Hitters): Covers algorithms like Count-Min Sketch and Misra-Gries (related to Space-Saving).

 Search for CMU Database lectures on stream mining or heavy hitters (e.g., by Andy Pavlo). https://www.youtube.com/watch?v=UEAMfLPZZhE (Example relevant lecture)

(YouTube Search) "Frequent Items Data Stream", "Misra Gries Algorithm", "Space Saving Algorithm Stream": Might yield specific algorithm explanations.
