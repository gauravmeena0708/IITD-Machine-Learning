{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b1a9801",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-10-21T17:15:59.930649Z",
     "iopub.status.busy": "2024-10-21T17:15:59.930009Z",
     "iopub.status.idle": "2024-10-21T17:16:09.654064Z",
     "shell.execute_reply": "2024-10-21T17:16:09.652836Z"
    },
    "papermill": {
     "duration": 9.731698,
     "end_time": "2024-10-21T17:16:09.657908",
     "exception": false,
     "start_time": "2024-10-21T17:15:59.926210",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cp -r /kaggle/input/col774a3/* /kaggle/working/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea67da40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-21T17:16:09.678476Z",
     "iopub.status.busy": "2024-10-21T17:16:09.677373Z",
     "iopub.status.idle": "2024-10-21T17:16:09.696592Z",
     "shell.execute_reply": "2024-10-21T17:16:09.695685Z"
    },
    "papermill": {
     "duration": 0.030628,
     "end_time": "2024-10-21T17:16:09.698613",
     "exception": false,
     "start_time": "2024-10-21T17:16:09.667985",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_scheduler(optimizer, scheduler_type='step', **kwargs):\n",
    "    \"\"\"\n",
    "    Returns the specified learning rate scheduler.\n",
    "\n",
    "    Args:\n",
    "        optimizer: The optimizer for which to schedule the learning rate.\n",
    "        scheduler_type (str): Type of the scheduler ('step', 'cosine', 'plateau', 'exponential', 'cyclic').\n",
    "        **kwargs: Additional arguments depending on the scheduler type.\n",
    "\n",
    "    Returns:\n",
    "        A learning rate scheduler.\n",
    "    \"\"\"\n",
    "    if scheduler_type == 'step':\n",
    "        step_size = kwargs.get('step_size', 30)\n",
    "        gamma = kwargs.get('gamma', 0.1)\n",
    "        return torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "\n",
    "    elif scheduler_type == 'cosine':\n",
    "        T_max = kwargs.get('T_max', 100)\n",
    "        eta_min = kwargs.get('eta_min', 0.0)\n",
    "        return torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=T_max, eta_min=eta_min)\n",
    "\n",
    "    elif scheduler_type == 'plateau':\n",
    "        patience = kwargs.get('patience', 10)\n",
    "        factor = kwargs.get('factor', 0.1)\n",
    "        return torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=patience, factor=factor)\n",
    "\n",
    "    elif scheduler_type == 'exponential':\n",
    "        gamma = kwargs.get('gamma', 0.9)\n",
    "        return torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=gamma)\n",
    "\n",
    "    elif scheduler_type == 'cyclic':\n",
    "        base_lr = kwargs.get('base_lr', 0.001)\n",
    "        max_lr = kwargs.get('max_lr', 0.1)\n",
    "        step_size_up = kwargs.get('step_size_up', 2000)\n",
    "        step_size_down = kwargs.get('step_size_down', step_size_up)  # Defaults to equal steps up/down\n",
    "        mode = kwargs.get('mode', 'triangular')\n",
    "        return torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=base_lr, max_lr=max_lr,\n",
    "                                                 step_size_up=step_size_up, step_size_down=step_size_down, mode=mode)\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported scheduler type: {scheduler_type}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1d5f177",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-21T17:16:09.710838Z",
     "iopub.status.busy": "2024-10-21T17:16:09.710129Z",
     "iopub.status.idle": "2024-10-21T20:27:43.136766Z",
     "shell.execute_reply": "2024-10-21T20:27:43.135579Z"
    },
    "papermill": {
     "duration": 11493.437914,
     "end_time": "2024-10-21T20:27:43.138985",
     "exception": false,
     "start_time": "2024-10-21T17:16:09.701071",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Batch 0, Loss: 4.842, Acc: 1.562%\n",
      "Epoch 0, Batch 100, Loss: 4.642, Acc: 1.284%\n",
      "Epoch 0, Batch 200, Loss: 4.548, Acc: 1.660%\n",
      "Epoch 0, Batch 300, Loss: 4.449, Acc: 2.048%\n",
      "Epoch 0 Training Loss: 4.438, Accuracy: 2.105%\n",
      "Epoch 0, Test Accuracy: 5.11%\n",
      "New best model saved with accuracy: 5.11%\n",
      "Epoch 1, Batch 0, Loss: 4.051, Acc: 3.906%\n",
      "Epoch 1, Batch 100, Loss: 4.033, Acc: 4.842%\n",
      "Epoch 1, Batch 200, Loss: 3.986, Acc: 5.278%\n",
      "Epoch 1, Batch 300, Loss: 3.934, Acc: 5.715%\n",
      "Epoch 1 Training Loss: 3.929, Accuracy: 5.805%\n",
      "Epoch 1, Test Accuracy: 8.23%\n",
      "New best model saved with accuracy: 8.23%\n",
      "Epoch 2, Batch 0, Loss: 3.652, Acc: 10.156%\n",
      "Epoch 2, Batch 100, Loss: 3.697, Acc: 8.238%\n",
      "Epoch 2, Batch 200, Loss: 3.638, Acc: 9.247%\n",
      "Epoch 2, Batch 300, Loss: 3.593, Acc: 10.073%\n",
      "Epoch 2 Training Loss: 3.587, Accuracy: 10.125%\n",
      "Epoch 2, Test Accuracy: 14.91%\n",
      "New best model saved with accuracy: 14.91%\n",
      "Epoch 3, Batch 0, Loss: 3.302, Acc: 13.281%\n",
      "Epoch 3, Batch 100, Loss: 3.346, Acc: 13.591%\n",
      "Epoch 3, Batch 200, Loss: 3.294, Acc: 14.548%\n",
      "Epoch 3, Batch 300, Loss: 3.245, Acc: 15.329%\n",
      "Epoch 3 Training Loss: 3.239, Accuracy: 15.420%\n",
      "Epoch 3, Test Accuracy: 20.23%\n",
      "New best model saved with accuracy: 20.23%\n",
      "Epoch 4, Batch 0, Loss: 3.101, Acc: 14.844%\n",
      "Epoch 4, Batch 100, Loss: 3.019, Acc: 18.247%\n",
      "Epoch 4, Batch 200, Loss: 2.964, Acc: 19.251%\n",
      "Epoch 4, Batch 300, Loss: 2.920, Acc: 19.965%\n",
      "Epoch 4 Training Loss: 2.915, Accuracy: 20.067%\n",
      "Epoch 4, Test Accuracy: 23.32%\n",
      "New best model saved with accuracy: 23.32%\n",
      "Epoch 5, Batch 0, Loss: 2.824, Acc: 19.531%\n",
      "Epoch 5, Batch 100, Loss: 2.747, Acc: 22.641%\n",
      "Epoch 5, Batch 200, Loss: 2.695, Acc: 23.624%\n",
      "Epoch 5, Batch 300, Loss: 2.667, Acc: 24.047%\n",
      "Epoch 5 Training Loss: 2.664, Accuracy: 24.113%\n",
      "Epoch 5, Test Accuracy: 25.28%\n",
      "New best model saved with accuracy: 25.28%\n",
      "Epoch 6, Batch 0, Loss: 2.445, Acc: 29.688%\n",
      "Epoch 6, Batch 100, Loss: 2.512, Acc: 27.119%\n",
      "Epoch 6, Batch 200, Loss: 2.486, Acc: 27.270%\n",
      "Epoch 6, Batch 300, Loss: 2.463, Acc: 27.741%\n",
      "Epoch 6 Training Loss: 2.458, Accuracy: 27.820%\n",
      "Epoch 6, Test Accuracy: 29.05%\n",
      "New best model saved with accuracy: 29.05%\n",
      "Epoch 7, Batch 0, Loss: 2.371, Acc: 27.344%\n",
      "Epoch 7, Batch 100, Loss: 2.349, Acc: 29.757%\n",
      "Epoch 7, Batch 200, Loss: 2.307, Acc: 30.445%\n",
      "Epoch 7, Batch 300, Loss: 2.289, Acc: 30.941%\n",
      "Epoch 7 Training Loss: 2.286, Accuracy: 31.023%\n",
      "Epoch 7, Test Accuracy: 29.32%\n",
      "New best model saved with accuracy: 29.32%\n",
      "Epoch 8, Batch 0, Loss: 2.257, Acc: 29.688%\n",
      "Epoch 8, Batch 100, Loss: 2.162, Acc: 33.880%\n",
      "Epoch 8, Batch 200, Loss: 2.168, Acc: 33.765%\n",
      "Epoch 8, Batch 300, Loss: 2.157, Acc: 33.869%\n",
      "Epoch 8 Training Loss: 2.154, Accuracy: 34.010%\n",
      "Epoch 8, Test Accuracy: 37.62%\n",
      "New best model saved with accuracy: 37.62%\n",
      "Epoch 9, Batch 0, Loss: 2.083, Acc: 35.938%\n",
      "Epoch 9, Batch 100, Loss: 2.068, Acc: 35.829%\n",
      "Epoch 9, Batch 200, Loss: 2.057, Acc: 35.638%\n",
      "Epoch 9, Batch 300, Loss: 2.055, Acc: 35.800%\n",
      "Epoch 9 Training Loss: 2.054, Accuracy: 35.865%\n",
      "Epoch 9, Test Accuracy: 34.73%\n",
      "No improvement for 1 epoch(s)\n",
      "Epoch 10, Batch 0, Loss: 2.071, Acc: 38.281%\n",
      "Epoch 10, Batch 100, Loss: 1.961, Acc: 37.786%\n",
      "Epoch 10, Batch 200, Loss: 1.984, Acc: 37.306%\n",
      "Epoch 10, Batch 300, Loss: 1.971, Acc: 37.627%\n",
      "Epoch 10 Training Loss: 1.974, Accuracy: 37.505%\n",
      "Epoch 10, Test Accuracy: 40.04%\n",
      "New best model saved with accuracy: 40.04%\n",
      "Epoch 11, Batch 0, Loss: 1.690, Acc: 43.750%\n",
      "Epoch 11, Batch 100, Loss: 1.888, Acc: 40.207%\n",
      "Epoch 11, Batch 200, Loss: 1.894, Acc: 39.945%\n",
      "Epoch 11, Batch 300, Loss: 1.896, Acc: 39.737%\n",
      "Epoch 11 Training Loss: 1.899, Accuracy: 39.625%\n",
      "Epoch 11, Test Accuracy: 39.40%\n",
      "No improvement for 1 epoch(s)\n",
      "Epoch 12, Batch 0, Loss: 2.022, Acc: 35.156%\n",
      "Epoch 12, Batch 100, Loss: 1.872, Acc: 39.511%\n",
      "Epoch 12, Batch 200, Loss: 1.858, Acc: 39.797%\n",
      "Epoch 12, Batch 300, Loss: 1.849, Acc: 40.145%\n",
      "Epoch 12 Training Loss: 1.850, Accuracy: 40.222%\n",
      "Epoch 12, Test Accuracy: 41.23%\n",
      "New best model saved with accuracy: 41.23%\n",
      "Epoch 13, Batch 0, Loss: 1.751, Acc: 43.750%\n",
      "Epoch 13, Batch 100, Loss: 1.822, Acc: 40.996%\n",
      "Epoch 13, Batch 200, Loss: 1.804, Acc: 41.531%\n",
      "Epoch 13, Batch 300, Loss: 1.809, Acc: 41.292%\n",
      "Epoch 13 Training Loss: 1.808, Accuracy: 41.288%\n",
      "Epoch 13, Test Accuracy: 41.90%\n",
      "New best model saved with accuracy: 41.90%\n",
      "Epoch 14, Batch 0, Loss: 1.490, Acc: 48.438%\n",
      "Epoch 14, Batch 100, Loss: 1.736, Acc: 43.046%\n",
      "Epoch 14, Batch 200, Loss: 1.761, Acc: 42.397%\n",
      "Epoch 14, Batch 300, Loss: 1.760, Acc: 42.385%\n",
      "Epoch 14 Training Loss: 1.766, Accuracy: 42.218%\n",
      "Epoch 14, Test Accuracy: 36.38%\n",
      "No improvement for 1 epoch(s)\n",
      "Epoch 15, Batch 0, Loss: 1.798, Acc: 40.625%\n",
      "Epoch 15, Batch 100, Loss: 1.748, Acc: 42.420%\n",
      "Epoch 15, Batch 200, Loss: 1.740, Acc: 43.043%\n",
      "Epoch 15, Batch 300, Loss: 1.737, Acc: 43.275%\n",
      "Epoch 15 Training Loss: 1.737, Accuracy: 43.230%\n",
      "Epoch 15, Test Accuracy: 45.01%\n",
      "New best model saved with accuracy: 45.01%\n",
      "Epoch 16, Batch 0, Loss: 1.616, Acc: 46.094%\n",
      "Epoch 16, Batch 100, Loss: 1.687, Acc: 44.199%\n",
      "Epoch 16, Batch 200, Loss: 1.712, Acc: 43.668%\n",
      "Epoch 16, Batch 300, Loss: 1.706, Acc: 43.641%\n",
      "Epoch 16 Training Loss: 1.706, Accuracy: 43.615%\n",
      "Epoch 16, Test Accuracy: 40.35%\n",
      "No improvement for 1 epoch(s)\n",
      "Epoch 17, Batch 0, Loss: 1.794, Acc: 43.750%\n",
      "Epoch 17, Batch 100, Loss: 1.664, Acc: 44.477%\n",
      "Epoch 17, Batch 200, Loss: 1.659, Acc: 44.473%\n",
      "Epoch 17, Batch 300, Loss: 1.665, Acc: 44.425%\n",
      "Epoch 17 Training Loss: 1.667, Accuracy: 44.438%\n",
      "Epoch 17, Test Accuracy: 44.84%\n",
      "No improvement for 2 epoch(s)\n",
      "Epoch 18, Batch 0, Loss: 301.432, Acc: 53.125%\n",
      "Epoch 18, Batch 100, Loss: 4.584, Acc: 46.063%\n",
      "Epoch 18, Batch 200, Loss: 3.122, Acc: 45.340%\n",
      "Epoch 18, Batch 300, Loss: 2.639, Acc: 44.913%\n",
      "Epoch 18 Training Loss: 2.603, Accuracy: 44.900%\n",
      "Epoch 18, Test Accuracy: 45.20%\n",
      "New best model saved with accuracy: 45.20%\n",
      "Epoch 19, Batch 0, Loss: 1.698, Acc: 49.219%\n",
      "Epoch 19, Batch 100, Loss: 1.607, Acc: 45.684%\n",
      "Epoch 19, Batch 200, Loss: 1.622, Acc: 45.262%\n",
      "Epoch 19, Batch 300, Loss: 1.633, Acc: 45.255%\n",
      "Epoch 19 Training Loss: 1.636, Accuracy: 45.212%\n",
      "Epoch 19, Test Accuracy: 48.70%\n",
      "New best model saved with accuracy: 48.70%\n",
      "Epoch 20, Batch 0, Loss: 1.524, Acc: 49.219%\n",
      "Epoch 20, Batch 100, Loss: 1.588, Acc: 46.658%\n",
      "Epoch 20, Batch 200, Loss: 1.585, Acc: 46.677%\n",
      "Epoch 20, Batch 300, Loss: 1.600, Acc: 46.486%\n",
      "Epoch 20 Training Loss: 1.600, Accuracy: 46.468%\n",
      "Epoch 20, Test Accuracy: 45.28%\n",
      "No improvement for 1 epoch(s)\n",
      "Epoch 21, Batch 0, Loss: 1.476, Acc: 46.094%\n",
      "Epoch 21, Batch 100, Loss: 1.573, Acc: 46.705%\n",
      "Epoch 21, Batch 200, Loss: 1.578, Acc: 46.459%\n",
      "Epoch 21, Batch 300, Loss: 1.574, Acc: 46.618%\n",
      "Epoch 21 Training Loss: 1.577, Accuracy: 46.553%\n",
      "Epoch 21, Test Accuracy: 47.27%\n",
      "No improvement for 2 epoch(s)\n",
      "Epoch 22, Batch 0, Loss: 1.442, Acc: 49.219%\n",
      "Epoch 22, Batch 100, Loss: 1.533, Acc: 47.440%\n",
      "Epoch 22, Batch 200, Loss: 1.552, Acc: 47.093%\n",
      "Epoch 22, Batch 300, Loss: 1.557, Acc: 47.220%\n",
      "Epoch 22 Training Loss: 1.557, Accuracy: 47.240%\n",
      "Epoch 22, Test Accuracy: 48.69%\n",
      "No improvement for 3 epoch(s)\n",
      "Epoch 23, Batch 0, Loss: 306.404, Acc: 52.344%\n",
      "Epoch 23, Batch 100, Loss: 4.566, Acc: 47.161%\n",
      "Epoch 23, Batch 200, Loss: 3.066, Acc: 47.248%\n",
      "Epoch 23, Batch 300, Loss: 2.557, Acc: 47.485%\n",
      "Epoch 23 Training Loss: 2.519, Accuracy: 47.475%\n",
      "Epoch 23, Test Accuracy: 47.22%\n",
      "No improvement for 4 epoch(s)\n",
      "Epoch 24, Batch 0, Loss: 1.383, Acc: 48.438%\n",
      "Epoch 24, Batch 100, Loss: 1.511, Acc: 48.236%\n",
      "Epoch 24, Batch 200, Loss: 1.511, Acc: 48.162%\n",
      "Epoch 24, Batch 300, Loss: 1.524, Acc: 47.820%\n",
      "Epoch 24 Training Loss: 1.524, Accuracy: 47.855%\n",
      "Epoch 24, Test Accuracy: 46.32%\n",
      "No improvement for 5 epoch(s)\n",
      "Epoch 25, Batch 0, Loss: 316.307, Acc: 50.781%\n",
      "Epoch 25, Batch 100, Loss: 4.625, Acc: 48.151%\n",
      "Epoch 25, Batch 200, Loss: 3.066, Acc: 48.243%\n",
      "Epoch 25, Batch 300, Loss: 2.553, Acc: 48.232%\n",
      "Epoch 25 Training Loss: 2.516, Accuracy: 48.215%\n",
      "Epoch 25, Test Accuracy: 47.05%\n",
      "No improvement for 6 epoch(s)\n",
      "Epoch 26, Batch 0, Loss: 1.405, Acc: 49.219%\n",
      "Epoch 26, Batch 100, Loss: 1.451, Acc: 49.667%\n",
      "Epoch 26, Batch 200, Loss: 1.467, Acc: 49.141%\n",
      "Epoch 26, Batch 300, Loss: 1.467, Acc: 49.169%\n",
      "Epoch 26 Training Loss: 1.469, Accuracy: 49.127%\n",
      "Epoch 26, Test Accuracy: 49.47%\n",
      "New best model saved with accuracy: 49.47%\n",
      "Epoch 27, Batch 0, Loss: 291.275, Acc: 54.688%\n",
      "Epoch 27, Batch 100, Loss: 4.311, Acc: 49.992%\n",
      "Epoch 27, Batch 200, Loss: 2.899, Acc: 49.495%\n",
      "Epoch 27, Batch 300, Loss: 2.430, Acc: 49.310%\n",
      "Epoch 27 Training Loss: 2.394, Accuracy: 49.285%\n",
      "Epoch 27, Test Accuracy: 50.74%\n",
      "New best model saved with accuracy: 50.74%\n",
      "Epoch 28, Batch 0, Loss: 301.347, Acc: 53.125%\n",
      "Epoch 28, Batch 100, Loss: 4.422, Acc: 49.064%\n",
      "Epoch 28, Batch 200, Loss: 2.955, Acc: 49.133%\n",
      "Epoch 28, Batch 300, Loss: 2.458, Acc: 49.143%\n",
      "Epoch 28 Training Loss: 2.421, Accuracy: 49.167%\n",
      "Epoch 28, Test Accuracy: 44.06%\n",
      "No improvement for 1 epoch(s)\n",
      "Epoch 29, Batch 0, Loss: 286.252, Acc: 55.469%\n",
      "Epoch 29, Batch 100, Loss: 4.238, Acc: 50.503%\n",
      "Epoch 29, Batch 200, Loss: 2.849, Acc: 50.128%\n",
      "Epoch 29, Batch 300, Loss: 2.399, Acc: 49.512%\n",
      "Epoch 29 Training Loss: 2.361, Accuracy: 49.490%\n",
      "Epoch 29, Test Accuracy: 48.92%\n",
      "No improvement for 2 epoch(s)\n",
      "Epoch 30, Batch 0, Loss: 276.165, Acc: 57.031%\n",
      "Epoch 30, Batch 100, Loss: 4.141, Acc: 50.774%\n",
      "Epoch 30, Batch 200, Loss: 2.791, Acc: 50.326%\n",
      "Epoch 30, Batch 300, Loss: 2.344, Acc: 50.091%\n",
      "Epoch 30 Training Loss: 2.312, Accuracy: 50.050%\n",
      "Epoch 30, Test Accuracy: 46.84%\n",
      "No improvement for 3 epoch(s)\n",
      "Epoch 31, Batch 0, Loss: 301.317, Acc: 53.125%\n",
      "Epoch 31, Batch 100, Loss: 4.382, Acc: 50.549%\n",
      "Epoch 31, Batch 200, Loss: 2.908, Acc: 50.626%\n",
      "Epoch 31, Batch 300, Loss: 2.416, Acc: 50.763%\n",
      "Epoch 31 Training Loss: 2.377, Accuracy: 50.770%\n",
      "Epoch 31, Test Accuracy: 51.55%\n",
      "New best model saved with accuracy: 51.55%\n",
      "Epoch 32, Batch 0, Loss: 301.338, Acc: 53.125%\n",
      "Epoch 32, Batch 100, Loss: 4.341, Acc: 50.928%\n",
      "Epoch 32, Batch 200, Loss: 2.873, Acc: 50.840%\n",
      "Epoch 32, Batch 300, Loss: 2.382, Acc: 51.015%\n",
      "Epoch 32 Training Loss: 2.343, Accuracy: 51.035%\n",
      "Epoch 32, Test Accuracy: 51.33%\n",
      "No improvement for 1 epoch(s)\n",
      "Epoch 33, Batch 0, Loss: 1.471, Acc: 40.625%\n",
      "Epoch 33, Batch 100, Loss: 1.348, Acc: 51.640%\n",
      "Epoch 33, Batch 200, Loss: 1.360, Acc: 51.555%\n",
      "Epoch 33, Batch 300, Loss: 1.379, Acc: 51.331%\n",
      "Epoch 33 Training Loss: 1.378, Accuracy: 51.383%\n",
      "Epoch 33, Test Accuracy: 49.06%\n",
      "No improvement for 2 epoch(s)\n",
      "Epoch 34, Batch 0, Loss: 316.386, Acc: 50.781%\n",
      "Epoch 34, Batch 100, Loss: 4.474, Acc: 51.532%\n",
      "Epoch 34, Batch 200, Loss: 2.927, Acc: 51.749%\n",
      "Epoch 34, Batch 300, Loss: 2.414, Acc: 51.562%\n",
      "Epoch 34 Training Loss: 2.374, Accuracy: 51.542%\n",
      "Epoch 34, Test Accuracy: 47.83%\n",
      "No improvement for 3 epoch(s)\n",
      "Epoch 35, Batch 0, Loss: 1.539, Acc: 49.219%\n",
      "Epoch 35, Batch 100, Loss: 1.330, Acc: 52.475%\n",
      "Epoch 35, Batch 200, Loss: 1.345, Acc: 52.161%\n",
      "Epoch 35, Batch 300, Loss: 1.358, Acc: 51.993%\n",
      "Epoch 35 Training Loss: 1.359, Accuracy: 51.990%\n",
      "Epoch 35, Test Accuracy: 49.34%\n",
      "No improvement for 4 epoch(s)\n",
      "Epoch 36, Batch 0, Loss: 291.403, Acc: 54.688%\n",
      "Epoch 36, Batch 100, Loss: 4.191, Acc: 52.908%\n",
      "Epoch 36, Batch 200, Loss: 2.773, Acc: 52.460%\n",
      "Epoch 36, Batch 300, Loss: 2.306, Acc: 52.377%\n",
      "Epoch 36 Training Loss: 2.268, Accuracy: 52.432%\n",
      "Epoch 36, Test Accuracy: 51.59%\n",
      "New best model saved with accuracy: 51.59%\n",
      "Epoch 37, Batch 0, Loss: 311.235, Acc: 51.562%\n",
      "Epoch 37, Batch 100, Loss: 4.379, Acc: 53.434%\n",
      "Epoch 37, Batch 200, Loss: 2.845, Acc: 53.358%\n",
      "Epoch 37, Batch 300, Loss: 2.347, Acc: 53.013%\n",
      "Epoch 37 Training Loss: 2.307, Accuracy: 53.010%\n",
      "Epoch 37, Test Accuracy: 54.05%\n",
      "New best model saved with accuracy: 54.05%\n",
      "Epoch 38, Batch 0, Loss: 311.269, Acc: 51.562%\n",
      "Epoch 38, Batch 100, Loss: 4.337, Acc: 54.378%\n",
      "Epoch 38, Batch 200, Loss: 2.832, Acc: 54.066%\n",
      "Epoch 38, Batch 300, Loss: 2.335, Acc: 53.488%\n",
      "Epoch 38 Training Loss: 2.298, Accuracy: 53.462%\n",
      "Epoch 38, Test Accuracy: 53.29%\n",
      "No improvement for 1 epoch(s)\n",
      "Epoch 39, Batch 0, Loss: 291.300, Acc: 54.688%\n",
      "Epoch 39, Batch 100, Loss: 4.133, Acc: 54.471%\n",
      "Epoch 39, Batch 200, Loss: 2.727, Acc: 54.159%\n",
      "Epoch 39, Batch 300, Loss: 2.263, Acc: 53.543%\n",
      "Epoch 39 Training Loss: 2.229, Accuracy: 53.487%\n",
      "Epoch 39, Test Accuracy: 54.19%\n",
      "New best model saved with accuracy: 54.19%\n",
      "Epoch 40, Batch 0, Loss: 291.200, Acc: 54.688%\n",
      "Epoch 40, Batch 100, Loss: 4.107, Acc: 54.943%\n",
      "Epoch 40, Batch 200, Loss: 2.714, Acc: 54.186%\n",
      "Epoch 40, Batch 300, Loss: 2.244, Acc: 53.906%\n",
      "Epoch 40 Training Loss: 2.207, Accuracy: 53.943%\n",
      "Epoch 40, Test Accuracy: 53.05%\n",
      "No improvement for 1 epoch(s)\n",
      "Epoch 41, Batch 0, Loss: 256.163, Acc: 60.156%\n",
      "Epoch 41, Batch 100, Loss: 3.770, Acc: 54.455%\n",
      "Epoch 41, Batch 200, Loss: 2.525, Acc: 54.672%\n",
      "Epoch 41, Batch 300, Loss: 2.114, Acc: 54.418%\n",
      "Epoch 41 Training Loss: 2.082, Accuracy: 54.352%\n",
      "Epoch 41, Test Accuracy: 50.12%\n",
      "No improvement for 2 epoch(s)\n",
      "Epoch 42, Batch 0, Loss: 286.225, Acc: 55.469%\n",
      "Epoch 42, Batch 100, Loss: 4.064, Acc: 55.322%\n",
      "Epoch 42, Batch 200, Loss: 2.662, Acc: 55.177%\n",
      "Epoch 42, Batch 300, Loss: 2.199, Acc: 54.911%\n",
      "Epoch 42 Training Loss: 2.165, Accuracy: 54.890%\n",
      "Epoch 42, Test Accuracy: 53.73%\n",
      "No improvement for 3 epoch(s)\n",
      "Epoch 43, Batch 0, Loss: 316.179, Acc: 50.781%\n",
      "Epoch 43, Batch 100, Loss: 4.331, Acc: 55.306%\n",
      "Epoch 43, Batch 200, Loss: 2.786, Acc: 55.578%\n",
      "Epoch 43, Batch 300, Loss: 2.276, Acc: 55.347%\n",
      "Epoch 43 Training Loss: 2.239, Accuracy: 55.292%\n",
      "Epoch 43, Test Accuracy: 48.13%\n",
      "No improvement for 4 epoch(s)\n",
      "Epoch 44, Batch 0, Loss: 256.138, Acc: 60.156%\n",
      "Epoch 44, Batch 100, Loss: 3.749, Acc: 54.749%\n",
      "Epoch 44, Batch 200, Loss: 2.500, Acc: 54.691%\n",
      "Epoch 44, Batch 300, Loss: 2.072, Acc: 54.859%\n",
      "Epoch 44 Training Loss: 2.039, Accuracy: 54.877%\n",
      "Epoch 44, Test Accuracy: 53.94%\n",
      "No improvement for 5 epoch(s)\n",
      "Epoch 45, Batch 0, Loss: 316.284, Acc: 50.781%\n",
      "Epoch 45, Batch 100, Loss: 4.306, Acc: 56.683%\n",
      "Epoch 45, Batch 200, Loss: 2.768, Acc: 56.339%\n",
      "Epoch 45, Batch 300, Loss: 2.257, Acc: 55.775%\n",
      "Epoch 45 Training Loss: 2.217, Accuracy: 55.767%\n",
      "Epoch 45, Test Accuracy: 52.59%\n",
      "No improvement for 6 epoch(s)\n",
      "Epoch 46, Batch 0, Loss: 256.013, Acc: 60.156%\n",
      "Epoch 46, Batch 100, Loss: 3.678, Acc: 56.915%\n",
      "Epoch 46, Batch 200, Loss: 2.441, Acc: 56.806%\n",
      "Epoch 46, Batch 300, Loss: 2.029, Acc: 56.559%\n",
      "Epoch 46 Training Loss: 1.999, Accuracy: 56.555%\n",
      "Epoch 46, Test Accuracy: 54.34%\n",
      "New best model saved with accuracy: 54.34%\n",
      "Epoch 47, Batch 0, Loss: 261.131, Acc: 59.375%\n",
      "Epoch 47, Batch 100, Loss: 3.719, Acc: 57.101%\n",
      "Epoch 47, Batch 200, Loss: 2.449, Acc: 56.957%\n",
      "Epoch 47, Batch 300, Loss: 2.033, Acc: 56.707%\n",
      "Epoch 47 Training Loss: 2.003, Accuracy: 56.675%\n",
      "Epoch 47, Test Accuracy: 55.17%\n",
      "New best model saved with accuracy: 55.17%\n",
      "Epoch 48, Batch 0, Loss: 311.064, Acc: 51.562%\n",
      "Epoch 48, Batch 100, Loss: 4.199, Acc: 58.021%\n",
      "Epoch 48, Batch 200, Loss: 2.689, Acc: 57.490%\n",
      "Epoch 48, Batch 300, Loss: 2.178, Acc: 57.592%\n",
      "Epoch 48 Training Loss: 2.141, Accuracy: 57.515%\n",
      "Epoch 48, Test Accuracy: 57.70%\n",
      "New best model saved with accuracy: 57.70%\n",
      "Epoch 49, Batch 0, Loss: 271.154, Acc: 57.812%\n",
      "Epoch 49, Batch 100, Loss: 3.769, Acc: 58.834%\n",
      "Epoch 49, Batch 200, Loss: 2.465, Acc: 58.123%\n",
      "Epoch 49, Batch 300, Loss: 2.035, Acc: 57.620%\n",
      "Epoch 49 Training Loss: 2.001, Accuracy: 57.653%\n",
      "Epoch 49, Test Accuracy: 56.84%\n",
      "No improvement for 1 epoch(s)\n",
      "Epoch 50, Batch 0, Loss: 255.950, Acc: 60.156%\n",
      "Epoch 50, Batch 100, Loss: 3.612, Acc: 59.081%\n",
      "Epoch 50, Batch 200, Loss: 2.380, Acc: 58.535%\n",
      "Epoch 50, Batch 300, Loss: 1.968, Acc: 58.246%\n",
      "Epoch 50 Training Loss: 1.937, Accuracy: 58.248%\n",
      "Epoch 50, Test Accuracy: 53.84%\n",
      "No improvement for 2 epoch(s)\n",
      "Epoch 51, Batch 0, Loss: 1.174, Acc: 48.438%\n",
      "Epoch 51, Batch 100, Loss: 1.092, Acc: 58.748%\n",
      "Epoch 51, Batch 200, Loss: 1.109, Acc: 58.357%\n",
      "Epoch 51, Batch 300, Loss: 1.117, Acc: 58.106%\n",
      "Epoch 51 Training Loss: 1.115, Accuracy: 58.160%\n",
      "Epoch 51, Test Accuracy: 56.55%\n",
      "No improvement for 3 epoch(s)\n",
      "Epoch 52, Batch 0, Loss: 230.846, Acc: 64.062%\n",
      "Epoch 52, Batch 100, Loss: 3.334, Acc: 59.669%\n",
      "Epoch 52, Batch 200, Loss: 2.216, Acc: 59.243%\n",
      "Epoch 52, Batch 300, Loss: 1.846, Acc: 59.180%\n",
      "Epoch 52 Training Loss: 1.819, Accuracy: 59.167%\n",
      "Epoch 52, Test Accuracy: 57.81%\n",
      "New best model saved with accuracy: 57.81%\n",
      "Epoch 53, Batch 0, Loss: 266.162, Acc: 58.594%\n",
      "Epoch 53, Batch 100, Loss: 3.667, Acc: 60.388%\n",
      "Epoch 53, Batch 200, Loss: 2.381, Acc: 59.686%\n",
      "Epoch 53, Batch 300, Loss: 1.954, Acc: 59.463%\n",
      "Epoch 53 Training Loss: 1.923, Accuracy: 59.405%\n",
      "Epoch 53, Test Accuracy: 58.71%\n",
      "New best model saved with accuracy: 58.71%\n",
      "Epoch 54, Batch 0, Loss: 250.966, Acc: 60.938%\n",
      "Epoch 54, Batch 100, Loss: 3.501, Acc: 60.659%\n",
      "Epoch 54, Batch 200, Loss: 2.292, Acc: 59.892%\n",
      "Epoch 54, Batch 300, Loss: 1.880, Acc: 59.767%\n",
      "Epoch 54 Training Loss: 1.852, Accuracy: 59.678%\n",
      "Epoch 54, Test Accuracy: 59.13%\n",
      "New best model saved with accuracy: 59.13%\n",
      "Epoch 55, Batch 0, Loss: 260.971, Acc: 59.375%\n",
      "Epoch 55, Batch 100, Loss: 3.587, Acc: 60.458%\n",
      "Epoch 55, Batch 200, Loss: 2.321, Acc: 60.417%\n",
      "Epoch 55, Batch 300, Loss: 1.901, Acc: 60.185%\n",
      "Epoch 55 Training Loss: 1.871, Accuracy: 60.087%\n",
      "Epoch 55, Test Accuracy: 57.28%\n",
      "No improvement for 1 epoch(s)\n",
      "Epoch 56, Batch 0, Loss: 240.936, Acc: 62.500%\n",
      "Epoch 56, Batch 100, Loss: 3.377, Acc: 61.046%\n",
      "Epoch 56, Batch 200, Loss: 2.203, Acc: 60.883%\n",
      "Epoch 56, Batch 300, Loss: 1.811, Acc: 61.008%\n",
      "Epoch 56 Training Loss: 1.781, Accuracy: 60.972%\n",
      "Epoch 56, Test Accuracy: 57.42%\n",
      "No improvement for 2 epoch(s)\n",
      "Epoch 57, Batch 0, Loss: 265.999, Acc: 58.594%\n",
      "Epoch 57, Batch 100, Loss: 3.621, Acc: 61.224%\n",
      "Epoch 57, Batch 200, Loss: 2.320, Acc: 61.334%\n",
      "Epoch 57, Batch 300, Loss: 1.887, Acc: 61.130%\n",
      "Epoch 57 Training Loss: 1.851, Accuracy: 61.182%\n",
      "Epoch 57, Test Accuracy: 59.30%\n",
      "New best model saved with accuracy: 59.30%\n",
      "Epoch 58, Batch 0, Loss: 240.984, Acc: 62.500%\n",
      "Epoch 58, Batch 100, Loss: 3.336, Acc: 62.376%\n",
      "Epoch 58, Batch 200, Loss: 2.166, Acc: 62.434%\n",
      "Epoch 58, Batch 300, Loss: 1.775, Acc: 62.064%\n",
      "Epoch 58 Training Loss: 1.746, Accuracy: 62.020%\n",
      "Epoch 58, Test Accuracy: 59.03%\n",
      "No improvement for 1 epoch(s)\n",
      "Epoch 59, Batch 0, Loss: 245.907, Acc: 61.719%\n",
      "Epoch 59, Batch 100, Loss: 3.372, Acc: 62.902%\n",
      "Epoch 59, Batch 200, Loss: 2.180, Acc: 62.418%\n",
      "Epoch 59, Batch 300, Loss: 1.777, Acc: 62.339%\n",
      "Epoch 59 Training Loss: 1.749, Accuracy: 62.290%\n",
      "Epoch 59, Test Accuracy: 58.02%\n",
      "No improvement for 2 epoch(s)\n",
      "Epoch 60, Batch 0, Loss: 235.828, Acc: 63.281%\n",
      "Epoch 60, Batch 100, Loss: 3.221, Acc: 63.668%\n",
      "Epoch 60, Batch 200, Loss: 2.086, Acc: 63.270%\n",
      "Epoch 60, Batch 300, Loss: 1.708, Acc: 63.029%\n",
      "Epoch 60 Training Loss: 1.681, Accuracy: 62.983%\n",
      "Epoch 60, Test Accuracy: 60.66%\n",
      "New best model saved with accuracy: 60.66%\n",
      "Epoch 61, Batch 0, Loss: 195.648, Acc: 69.531%\n",
      "Epoch 61, Batch 100, Loss: 2.812, Acc: 64.720%\n",
      "Epoch 61, Batch 200, Loss: 1.876, Acc: 63.798%\n",
      "Epoch 61, Batch 300, Loss: 1.565, Acc: 63.530%\n",
      "Epoch 61 Training Loss: 1.541, Accuracy: 63.453%\n",
      "Epoch 61, Test Accuracy: 62.38%\n",
      "New best model saved with accuracy: 62.38%\n",
      "Epoch 62, Batch 0, Loss: 255.902, Acc: 60.156%\n",
      "Epoch 62, Batch 100, Loss: 3.406, Acc: 64.155%\n",
      "Epoch 62, Batch 200, Loss: 2.151, Acc: 64.455%\n",
      "Epoch 62, Batch 300, Loss: 1.741, Acc: 64.294%\n",
      "Epoch 62 Training Loss: 1.709, Accuracy: 64.257%\n",
      "Epoch 62, Test Accuracy: 61.90%\n",
      "No improvement for 1 epoch(s)\n",
      "Epoch 63, Batch 0, Loss: 220.916, Acc: 65.625%\n",
      "Epoch 63, Batch 100, Loss: 3.050, Acc: 64.604%\n",
      "Epoch 63, Batch 200, Loss: 1.957, Acc: 65.108%\n",
      "Epoch 63, Batch 300, Loss: 1.609, Acc: 64.696%\n",
      "Epoch 63 Training Loss: 1.579, Accuracy: 64.765%\n",
      "Epoch 63, Test Accuracy: 62.20%\n",
      "No improvement for 2 epoch(s)\n",
      "Epoch 64, Batch 0, Loss: 205.755, Acc: 67.969%\n",
      "Epoch 64, Batch 100, Loss: 2.859, Acc: 66.669%\n",
      "Epoch 64, Batch 200, Loss: 1.868, Acc: 65.948%\n",
      "Epoch 64, Batch 300, Loss: 1.535, Acc: 65.698%\n",
      "Epoch 64 Training Loss: 1.513, Accuracy: 65.653%\n",
      "Epoch 64, Test Accuracy: 61.65%\n",
      "No improvement for 3 epoch(s)\n",
      "Epoch 65, Batch 0, Loss: 210.801, Acc: 67.188%\n",
      "Epoch 65, Batch 100, Loss: 2.906, Acc: 65.563%\n",
      "Epoch 65, Batch 200, Loss: 1.866, Acc: 65.994%\n",
      "Epoch 65, Batch 300, Loss: 1.527, Acc: 65.835%\n",
      "Epoch 65 Training Loss: 1.501, Accuracy: 65.780%\n",
      "Epoch 65, Test Accuracy: 63.42%\n",
      "New best model saved with accuracy: 63.42%\n",
      "Epoch 66, Batch 0, Loss: 145.577, Acc: 77.344%\n",
      "Epoch 66, Batch 100, Loss: 2.220, Acc: 67.211%\n",
      "Epoch 66, Batch 200, Loss: 1.520, Acc: 67.094%\n",
      "Epoch 66, Batch 300, Loss: 1.301, Acc: 66.445%\n",
      "Epoch 66 Training Loss: 1.282, Accuracy: 66.442%\n",
      "Epoch 66, Test Accuracy: 63.17%\n",
      "No improvement for 1 epoch(s)\n",
      "Epoch 67, Batch 0, Loss: 180.698, Acc: 71.875%\n",
      "Epoch 67, Batch 100, Loss: 2.539, Acc: 68.131%\n",
      "Epoch 67, Batch 200, Loss: 1.676, Acc: 67.600%\n",
      "Epoch 67, Batch 300, Loss: 1.388, Acc: 67.299%\n",
      "Epoch 67 Training Loss: 1.369, Accuracy: 67.190%\n",
      "Epoch 67, Test Accuracy: 62.28%\n",
      "No improvement for 2 epoch(s)\n",
      "Epoch 68, Batch 0, Loss: 180.800, Acc: 71.875%\n",
      "Epoch 68, Batch 100, Loss: 2.541, Acc: 68.526%\n",
      "Epoch 68, Batch 200, Loss: 1.652, Acc: 68.151%\n",
      "Epoch 68, Batch 300, Loss: 1.366, Acc: 67.914%\n",
      "Epoch 68 Training Loss: 1.345, Accuracy: 67.897%\n",
      "Epoch 68, Test Accuracy: 62.07%\n",
      "No improvement for 3 epoch(s)\n",
      "Epoch 69, Batch 0, Loss: 230.818, Acc: 64.062%\n",
      "Epoch 69, Batch 100, Loss: 3.009, Acc: 68.356%\n",
      "Epoch 69, Batch 200, Loss: 1.888, Acc: 68.361%\n",
      "Epoch 69, Batch 300, Loss: 1.508, Acc: 68.459%\n",
      "Epoch 69 Training Loss: 1.480, Accuracy: 68.460%\n",
      "Epoch 69, Test Accuracy: 65.33%\n",
      "New best model saved with accuracy: 65.33%\n",
      "Epoch 70, Batch 0, Loss: 150.638, Acc: 76.562%\n",
      "Epoch 70, Batch 100, Loss: 2.167, Acc: 70.189%\n",
      "Epoch 70, Batch 200, Loss: 1.448, Acc: 69.547%\n",
      "Epoch 70, Batch 300, Loss: 1.207, Acc: 69.508%\n",
      "Epoch 70 Training Loss: 1.190, Accuracy: 69.445%\n",
      "Epoch 70, Test Accuracy: 65.46%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_70.csv\n",
      "New best model saved with accuracy: 65.46%\n",
      "Epoch 71, Batch 0, Loss: 180.564, Acc: 71.875%\n",
      "Epoch 71, Batch 100, Loss: 2.455, Acc: 70.692%\n",
      "Epoch 71, Batch 200, Loss: 1.573, Acc: 70.892%\n",
      "Epoch 71, Batch 300, Loss: 1.288, Acc: 70.333%\n",
      "Epoch 71 Training Loss: 1.266, Accuracy: 70.325%\n",
      "Epoch 71, Test Accuracy: 63.26%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_71.csv\n",
      "No improvement for 1 epoch(s)\n",
      "Epoch 72, Batch 0, Loss: 215.694, Acc: 66.406%\n",
      "Epoch 72, Batch 100, Loss: 2.771, Acc: 71.272%\n",
      "Epoch 72, Batch 200, Loss: 1.725, Acc: 71.055%\n",
      "Epoch 72, Batch 300, Loss: 1.379, Acc: 70.710%\n",
      "Epoch 72 Training Loss: 1.353, Accuracy: 70.662%\n",
      "Epoch 72, Test Accuracy: 64.27%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_72.csv\n",
      "No improvement for 2 epoch(s)\n",
      "Epoch 73, Batch 0, Loss: 175.648, Acc: 72.656%\n",
      "Epoch 73, Batch 100, Loss: 2.359, Acc: 72.022%\n",
      "Epoch 73, Batch 200, Loss: 1.511, Acc: 71.646%\n",
      "Epoch 73, Batch 300, Loss: 1.226, Acc: 71.379%\n",
      "Epoch 73 Training Loss: 1.207, Accuracy: 71.270%\n",
      "Epoch 73, Test Accuracy: 65.79%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_73.csv\n",
      "New best model saved with accuracy: 65.79%\n",
      "Epoch 74, Batch 0, Loss: 125.406, Acc: 80.469%\n",
      "Epoch 74, Batch 100, Loss: 1.841, Acc: 72.749%\n",
      "Epoch 74, Batch 200, Loss: 1.244, Acc: 72.213%\n",
      "Epoch 74, Batch 300, Loss: 1.042, Acc: 72.231%\n",
      "Epoch 74 Training Loss: 1.025, Accuracy: 72.263%\n",
      "Epoch 74, Test Accuracy: 66.44%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_74.csv\n",
      "New best model saved with accuracy: 66.44%\n",
      "Epoch 75, Batch 0, Loss: 180.636, Acc: 71.875%\n",
      "Epoch 75, Batch 100, Loss: 2.352, Acc: 73.654%\n",
      "Epoch 75, Batch 200, Loss: 1.479, Acc: 73.301%\n",
      "Epoch 75, Batch 300, Loss: 1.191, Acc: 73.072%\n",
      "Epoch 75 Training Loss: 1.169, Accuracy: 73.020%\n",
      "Epoch 75, Test Accuracy: 65.45%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_75.csv\n",
      "No improvement for 1 epoch(s)\n",
      "Epoch 76, Batch 0, Loss: 190.617, Acc: 70.312%\n",
      "Epoch 76, Batch 100, Loss: 2.436, Acc: 74.234%\n",
      "Epoch 76, Batch 200, Loss: 1.498, Acc: 74.522%\n",
      "Epoch 76, Batch 300, Loss: 1.194, Acc: 74.037%\n",
      "Epoch 76 Training Loss: 1.171, Accuracy: 74.022%\n",
      "Epoch 76, Test Accuracy: 66.44%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_76.csv\n",
      "New best model saved with accuracy: 66.44%\n",
      "Epoch 77, Batch 0, Loss: 175.521, Acc: 72.656%\n",
      "Epoch 77, Batch 100, Loss: 2.245, Acc: 75.897%\n",
      "Epoch 77, Batch 200, Loss: 1.396, Acc: 75.365%\n",
      "Epoch 77, Batch 300, Loss: 1.118, Acc: 75.013%\n",
      "Epoch 77 Training Loss: 1.096, Accuracy: 74.960%\n",
      "Epoch 77, Test Accuracy: 66.02%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_77.csv\n",
      "No improvement for 1 epoch(s)\n",
      "Epoch 78, Batch 0, Loss: 165.501, Acc: 74.219%\n",
      "Epoch 78, Batch 100, Loss: 2.121, Acc: 76.717%\n",
      "Epoch 78, Batch 200, Loss: 1.322, Acc: 75.991%\n",
      "Epoch 78, Batch 300, Loss: 1.057, Acc: 75.869%\n",
      "Epoch 78 Training Loss: 1.038, Accuracy: 75.812%\n",
      "Epoch 78, Test Accuracy: 67.21%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_78.csv\n",
      "New best model saved with accuracy: 67.21%\n",
      "Epoch 79, Batch 0, Loss: 145.499, Acc: 77.344%\n",
      "Epoch 79, Batch 100, Loss: 1.905, Acc: 77.127%\n",
      "Epoch 79, Batch 200, Loss: 1.196, Acc: 77.076%\n",
      "Epoch 79, Batch 300, Loss: 0.963, Acc: 76.729%\n",
      "Epoch 79 Training Loss: 0.946, Accuracy: 76.670%\n",
      "Epoch 79, Test Accuracy: 68.67%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_79.csv\n",
      "New best model saved with accuracy: 68.67%\n",
      "Epoch 80, Batch 0, Loss: 155.401, Acc: 75.781%\n",
      "Epoch 80, Batch 100, Loss: 1.975, Acc: 77.955%\n",
      "Epoch 80, Batch 200, Loss: 1.227, Acc: 77.697%\n",
      "Epoch 80, Batch 300, Loss: 0.975, Acc: 77.497%\n",
      "Epoch 80 Training Loss: 0.955, Accuracy: 77.580%\n",
      "Epoch 80, Test Accuracy: 68.62%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_80.csv\n",
      "No improvement for 1 epoch(s)\n",
      "Epoch 81, Batch 0, Loss: 150.526, Acc: 76.562%\n",
      "Epoch 81, Batch 100, Loss: 1.894, Acc: 79.548%\n",
      "Epoch 81, Batch 200, Loss: 1.164, Acc: 79.213%\n",
      "Epoch 81, Batch 300, Loss: 0.922, Acc: 78.982%\n",
      "Epoch 81 Training Loss: 0.904, Accuracy: 78.960%\n",
      "Epoch 81, Test Accuracy: 68.65%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_81.csv\n",
      "No improvement for 2 epoch(s)\n",
      "Epoch 82, Batch 0, Loss: 120.407, Acc: 81.250%\n",
      "Epoch 82, Batch 100, Loss: 1.576, Acc: 80.198%\n",
      "Epoch 82, Batch 200, Loss: 0.986, Acc: 79.983%\n",
      "Epoch 82, Batch 300, Loss: 0.801, Acc: 79.573%\n",
      "Epoch 82 Training Loss: 0.787, Accuracy: 79.472%\n",
      "Epoch 82, Test Accuracy: 69.39%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_82.csv\n",
      "New best model saved with accuracy: 69.39%\n",
      "Epoch 83, Batch 0, Loss: 85.236, Acc: 86.719%\n",
      "Epoch 83, Batch 100, Loss: 1.198, Acc: 81.443%\n",
      "Epoch 83, Batch 200, Loss: 0.792, Acc: 80.787%\n",
      "Epoch 83, Batch 300, Loss: 0.654, Acc: 80.637%\n",
      "Epoch 83 Training Loss: 0.646, Accuracy: 80.600%\n",
      "Epoch 83, Test Accuracy: 69.47%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_83.csv\n",
      "New best model saved with accuracy: 69.47%\n",
      "Epoch 84, Batch 0, Loss: 105.244, Acc: 83.594%\n",
      "Epoch 84, Batch 100, Loss: 1.359, Acc: 82.890%\n",
      "Epoch 84, Batch 200, Loss: 0.862, Acc: 82.039%\n",
      "Epoch 84, Batch 300, Loss: 0.697, Acc: 81.722%\n",
      "Epoch 84 Training Loss: 0.684, Accuracy: 81.722%\n",
      "Epoch 84, Test Accuracy: 69.58%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_84.csv\n",
      "New best model saved with accuracy: 69.58%\n",
      "Epoch 85, Batch 0, Loss: 100.262, Acc: 84.375%\n",
      "Epoch 85, Batch 100, Loss: 1.316, Acc: 82.217%\n",
      "Epoch 85, Batch 200, Loss: 0.821, Acc: 82.525%\n",
      "Epoch 85, Batch 300, Loss: 0.660, Acc: 82.288%\n",
      "Epoch 85 Training Loss: 0.648, Accuracy: 82.295%\n",
      "Epoch 85, Test Accuracy: 69.53%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_85.csv\n",
      "No improvement for 1 epoch(s)\n",
      "Epoch 86, Batch 0, Loss: 125.376, Acc: 80.469%\n",
      "Epoch 86, Batch 100, Loss: 1.541, Acc: 83.060%\n",
      "Epoch 86, Batch 200, Loss: 0.926, Acc: 83.228%\n",
      "Epoch 86, Batch 300, Loss: 0.724, Acc: 83.101%\n",
      "Epoch 86 Training Loss: 0.708, Accuracy: 83.118%\n",
      "Epoch 86, Test Accuracy: 70.37%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_86.csv\n",
      "New best model saved with accuracy: 70.37%\n",
      "Epoch 87, Batch 0, Loss: 140.302, Acc: 78.125%\n",
      "Epoch 87, Batch 100, Loss: 1.664, Acc: 84.700%\n",
      "Epoch 87, Batch 200, Loss: 0.976, Acc: 84.309%\n",
      "Epoch 87, Batch 300, Loss: 0.746, Acc: 84.341%\n",
      "Epoch 87 Training Loss: 0.728, Accuracy: 84.360%\n",
      "Epoch 87, Test Accuracy: 70.58%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_87.csv\n",
      "New best model saved with accuracy: 70.58%\n",
      "Epoch 88, Batch 0, Loss: 95.252, Acc: 85.156%\n",
      "Epoch 88, Batch 100, Loss: 1.189, Acc: 85.342%\n",
      "Epoch 88, Batch 200, Loss: 0.722, Acc: 85.358%\n",
      "Epoch 88, Batch 300, Loss: 0.572, Acc: 85.154%\n",
      "Epoch 88 Training Loss: 0.559, Accuracy: 85.172%\n",
      "Epoch 88, Test Accuracy: 70.85%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_88.csv\n",
      "New best model saved with accuracy: 70.85%\n",
      "Epoch 89, Batch 0, Loss: 55.170, Acc: 91.406%\n",
      "Epoch 89, Batch 100, Loss: 0.776, Acc: 86.301%\n",
      "Epoch 89, Batch 200, Loss: 0.508, Acc: 86.178%\n",
      "Epoch 89, Batch 300, Loss: 0.425, Acc: 85.899%\n",
      "Epoch 89 Training Loss: 0.418, Accuracy: 85.877%\n",
      "Epoch 89, Test Accuracy: 70.89%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_89.csv\n",
      "New best model saved with accuracy: 70.89%\n",
      "Epoch 90, Batch 0, Loss: 50.102, Acc: 92.188%\n",
      "Epoch 90, Batch 100, Loss: 0.719, Acc: 86.873%\n",
      "Epoch 90, Batch 200, Loss: 0.477, Acc: 86.548%\n",
      "Epoch 90, Batch 300, Loss: 0.392, Acc: 86.649%\n",
      "Epoch 90 Training Loss: 0.385, Accuracy: 86.698%\n",
      "Epoch 90, Test Accuracy: 71.56%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_90.csv\n",
      "New best model saved with accuracy: 71.56%\n",
      "Epoch 91, Batch 0, Loss: 85.188, Acc: 86.719%\n",
      "Epoch 91, Batch 100, Loss: 1.052, Acc: 87.075%\n",
      "Epoch 91, Batch 200, Loss: 0.633, Acc: 87.259%\n",
      "Epoch 91, Batch 300, Loss: 0.493, Acc: 87.214%\n",
      "Epoch 91 Training Loss: 0.482, Accuracy: 87.153%\n",
      "Epoch 91, Test Accuracy: 71.33%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_91.csv\n",
      "No improvement for 1 epoch(s)\n",
      "Epoch 92, Batch 0, Loss: 100.320, Acc: 84.375%\n",
      "Epoch 92, Batch 100, Loss: 1.187, Acc: 87.894%\n",
      "Epoch 92, Batch 200, Loss: 0.693, Acc: 87.963%\n",
      "Epoch 92, Batch 300, Loss: 0.526, Acc: 87.978%\n",
      "Epoch 92 Training Loss: 0.514, Accuracy: 87.985%\n",
      "Epoch 92, Test Accuracy: 71.67%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_92.csv\n",
      "New best model saved with accuracy: 71.67%\n",
      "Epoch 93, Batch 0, Loss: 50.230, Acc: 92.188%\n",
      "Epoch 93, Batch 100, Loss: 0.675, Acc: 88.359%\n",
      "Epoch 93, Batch 200, Loss: 0.432, Acc: 88.227%\n",
      "Epoch 93, Batch 300, Loss: 0.350, Acc: 88.235%\n",
      "Epoch 93 Training Loss: 0.344, Accuracy: 88.195%\n",
      "Epoch 93, Test Accuracy: 71.84%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_93.csv\n",
      "New best model saved with accuracy: 71.84%\n",
      "Epoch 94, Batch 0, Loss: 75.162, Acc: 88.281%\n",
      "Epoch 94, Batch 100, Loss: 0.911, Acc: 88.977%\n",
      "Epoch 94, Batch 200, Loss: 0.543, Acc: 89.082%\n",
      "Epoch 94, Batch 300, Loss: 0.420, Acc: 89.039%\n",
      "Epoch 94 Training Loss: 0.411, Accuracy: 89.020%\n",
      "Epoch 94, Test Accuracy: 72.08%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_94.csv\n",
      "New best model saved with accuracy: 72.08%\n",
      "Epoch 95, Batch 0, Loss: 65.185, Acc: 89.844%\n",
      "Epoch 95, Batch 100, Loss: 0.807, Acc: 89.534%\n",
      "Epoch 95, Batch 200, Loss: 0.489, Acc: 89.490%\n",
      "Epoch 95, Batch 300, Loss: 0.384, Acc: 89.283%\n",
      "Epoch 95 Training Loss: 0.377, Accuracy: 89.285%\n",
      "Epoch 95, Test Accuracy: 71.77%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_95.csv\n",
      "No improvement for 1 epoch(s)\n",
      "Epoch 96, Batch 0, Loss: 95.197, Acc: 85.156%\n",
      "Epoch 96, Batch 100, Loss: 1.114, Acc: 89.055%\n",
      "Epoch 96, Batch 200, Loss: 0.639, Acc: 89.179%\n",
      "Epoch 96, Batch 300, Loss: 0.485, Acc: 89.031%\n",
      "Epoch 96 Training Loss: 0.472, Accuracy: 89.007%\n",
      "Epoch 96, Test Accuracy: 71.92%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_96.csv\n",
      "No improvement for 2 epoch(s)\n",
      "Epoch 97, Batch 0, Loss: 70.204, Acc: 89.062%\n",
      "Epoch 97, Batch 100, Loss: 0.847, Acc: 90.145%\n",
      "Epoch 97, Batch 200, Loss: 0.506, Acc: 89.914%\n",
      "Epoch 97, Batch 300, Loss: 0.392, Acc: 89.763%\n",
      "Epoch 97 Training Loss: 0.384, Accuracy: 89.713%\n",
      "Epoch 97, Test Accuracy: 72.03%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_97.csv\n",
      "No improvement for 3 epoch(s)\n",
      "Epoch 98, Batch 0, Loss: 90.206, Acc: 85.938%\n",
      "Epoch 98, Batch 100, Loss: 1.040, Acc: 90.347%\n",
      "Epoch 98, Batch 200, Loss: 0.600, Acc: 90.135%\n",
      "Epoch 98, Batch 300, Loss: 0.454, Acc: 90.010%\n",
      "Epoch 98 Training Loss: 0.443, Accuracy: 89.972%\n",
      "Epoch 98, Test Accuracy: 72.06%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_98.csv\n",
      "No improvement for 4 epoch(s)\n",
      "Epoch 99, Batch 0, Loss: 65.157, Acc: 89.844%\n",
      "Epoch 99, Batch 100, Loss: 0.801, Acc: 89.968%\n",
      "Epoch 99, Batch 200, Loss: 0.482, Acc: 89.840%\n",
      "Epoch 99, Batch 300, Loss: 0.374, Acc: 89.823%\n",
      "Epoch 99 Training Loss: 0.365, Accuracy: 89.835%\n",
      "Epoch 99, Test Accuracy: 71.99%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_99.csv\n",
      "No improvement for 5 epoch(s)\n",
      "Epoch 100, Batch 0, Loss: 75.178, Acc: 88.281%\n",
      "Epoch 100, Batch 100, Loss: 0.905, Acc: 89.271%\n",
      "Epoch 100, Batch 200, Loss: 0.528, Acc: 89.727%\n",
      "Epoch 100, Batch 300, Loss: 0.405, Acc: 89.784%\n",
      "Epoch 100 Training Loss: 0.395, Accuracy: 89.795%\n",
      "Epoch 100, Test Accuracy: 71.98%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_100.csv\n",
      "No improvement for 6 epoch(s)\n",
      "Epoch 101, Batch 0, Loss: 90.240, Acc: 85.938%\n",
      "Epoch 101, Batch 100, Loss: 1.051, Acc: 89.913%\n",
      "Epoch 101, Batch 200, Loss: 0.603, Acc: 90.127%\n",
      "Epoch 101, Batch 300, Loss: 0.455, Acc: 90.005%\n",
      "Epoch 101 Training Loss: 0.443, Accuracy: 90.030%\n",
      "Epoch 101, Test Accuracy: 72.08%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_101.csv\n",
      "New best model saved with accuracy: 72.08%\n",
      "Epoch 102, Batch 0, Loss: 60.152, Acc: 90.625%\n",
      "Epoch 102, Batch 100, Loss: 0.756, Acc: 89.604%\n",
      "Epoch 102, Batch 200, Loss: 0.457, Acc: 89.782%\n",
      "Epoch 102, Batch 300, Loss: 0.358, Acc: 89.750%\n",
      "Epoch 102 Training Loss: 0.350, Accuracy: 89.775%\n",
      "Epoch 102, Test Accuracy: 72.16%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_102.csv\n",
      "New best model saved with accuracy: 72.16%\n",
      "Epoch 103, Batch 0, Loss: 80.150, Acc: 87.500%\n",
      "Epoch 103, Batch 100, Loss: 0.944, Acc: 89.937%\n",
      "Epoch 103, Batch 200, Loss: 0.551, Acc: 89.949%\n",
      "Epoch 103, Batch 300, Loss: 0.422, Acc: 89.854%\n",
      "Epoch 103 Training Loss: 0.412, Accuracy: 89.838%\n",
      "Epoch 103, Test Accuracy: 71.90%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_103.csv\n",
      "No improvement for 1 epoch(s)\n",
      "Epoch 104, Batch 0, Loss: 70.243, Acc: 89.062%\n",
      "Epoch 104, Batch 100, Loss: 0.851, Acc: 89.619%\n",
      "Epoch 104, Batch 200, Loss: 0.507, Acc: 89.525%\n",
      "Epoch 104, Batch 300, Loss: 0.391, Acc: 89.465%\n",
      "Epoch 104 Training Loss: 0.382, Accuracy: 89.510%\n",
      "Epoch 104, Test Accuracy: 72.19%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_104.csv\n",
      "New best model saved with accuracy: 72.19%\n",
      "Epoch 105, Batch 0, Loss: 60.188, Acc: 90.625%\n",
      "Epoch 105, Batch 100, Loss: 0.749, Acc: 89.558%\n",
      "Epoch 105, Batch 200, Loss: 0.459, Acc: 89.502%\n",
      "Epoch 105, Batch 300, Loss: 0.357, Acc: 89.704%\n",
      "Epoch 105 Training Loss: 0.351, Accuracy: 89.657%\n",
      "Epoch 105, Test Accuracy: 72.28%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_105.csv\n",
      "New best model saved with accuracy: 72.28%\n",
      "Epoch 106, Batch 0, Loss: 80.219, Acc: 87.500%\n",
      "Epoch 106, Batch 100, Loss: 0.954, Acc: 89.782%\n",
      "Epoch 106, Batch 200, Loss: 0.561, Acc: 89.614%\n",
      "Epoch 106, Batch 300, Loss: 0.430, Acc: 89.413%\n",
      "Epoch 106 Training Loss: 0.420, Accuracy: 89.362%\n",
      "Epoch 106, Test Accuracy: 71.73%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_106.csv\n",
      "No improvement for 1 epoch(s)\n",
      "Epoch 107, Batch 0, Loss: 100.183, Acc: 84.375%\n",
      "Epoch 107, Batch 100, Loss: 1.145, Acc: 89.666%\n",
      "Epoch 107, Batch 200, Loss: 0.653, Acc: 89.700%\n",
      "Epoch 107, Batch 300, Loss: 0.491, Acc: 89.563%\n",
      "Epoch 107 Training Loss: 0.478, Accuracy: 89.565%\n",
      "Epoch 107, Test Accuracy: 71.64%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_107.csv\n",
      "No improvement for 2 epoch(s)\n",
      "Epoch 108, Batch 0, Loss: 55.132, Acc: 91.406%\n",
      "Epoch 108, Batch 100, Loss: 0.701, Acc: 89.813%\n",
      "Epoch 108, Batch 200, Loss: 0.442, Acc: 89.265%\n",
      "Epoch 108, Batch 300, Loss: 0.353, Acc: 89.104%\n",
      "Epoch 108 Training Loss: 0.346, Accuracy: 89.097%\n",
      "Epoch 108, Test Accuracy: 71.55%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_108.csv\n",
      "No improvement for 3 epoch(s)\n",
      "Epoch 109, Batch 0, Loss: 90.146, Acc: 85.938%\n",
      "Epoch 109, Batch 100, Loss: 1.060, Acc: 89.264%\n",
      "Epoch 109, Batch 200, Loss: 0.621, Acc: 88.993%\n",
      "Epoch 109, Batch 300, Loss: 0.476, Acc: 88.785%\n",
      "Epoch 109 Training Loss: 0.464, Accuracy: 88.785%\n",
      "Epoch 109, Test Accuracy: 71.31%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_109.csv\n",
      "No improvement for 4 epoch(s)\n",
      "Epoch 110, Batch 0, Loss: 80.169, Acc: 87.500%\n",
      "Epoch 110, Batch 100, Loss: 0.969, Acc: 89.016%\n",
      "Epoch 110, Batch 200, Loss: 0.583, Acc: 88.581%\n",
      "Epoch 110, Batch 300, Loss: 0.451, Acc: 88.473%\n",
      "Epoch 110 Training Loss: 0.440, Accuracy: 88.490%\n",
      "Epoch 110, Test Accuracy: 71.28%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_110.csv\n",
      "No improvement for 5 epoch(s)\n",
      "Epoch 111, Batch 0, Loss: 90.256, Acc: 85.938%\n",
      "Epoch 111, Batch 100, Loss: 1.079, Acc: 88.227%\n",
      "Epoch 111, Batch 200, Loss: 0.640, Acc: 87.955%\n",
      "Epoch 111, Batch 300, Loss: 0.490, Acc: 88.053%\n",
      "Epoch 111 Training Loss: 0.479, Accuracy: 88.060%\n",
      "Epoch 111, Test Accuracy: 70.75%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_111.csv\n",
      "No improvement for 6 epoch(s)\n",
      "Epoch 112, Batch 0, Loss: 45.098, Acc: 92.969%\n",
      "Epoch 112, Batch 100, Loss: 0.649, Acc: 87.616%\n",
      "Epoch 112, Batch 200, Loss: 0.430, Acc: 87.457%\n",
      "Epoch 112, Batch 300, Loss: 0.360, Acc: 87.152%\n",
      "Epoch 112 Training Loss: 0.354, Accuracy: 87.135%\n",
      "Epoch 112, Test Accuracy: 70.16%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_112.csv\n",
      "No improvement for 7 epoch(s)\n",
      "Epoch 113, Batch 0, Loss: 70.201, Acc: 89.062%\n",
      "Epoch 113, Batch 100, Loss: 0.903, Acc: 87.252%\n",
      "Epoch 113, Batch 200, Loss: 0.569, Acc: 86.730%\n",
      "Epoch 113, Batch 300, Loss: 0.458, Acc: 86.540%\n",
      "Epoch 113 Training Loss: 0.448, Accuracy: 86.550%\n",
      "Epoch 113, Test Accuracy: 69.50%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_113.csv\n",
      "No improvement for 8 epoch(s)\n",
      "Epoch 114, Batch 0, Loss: 105.242, Acc: 83.594%\n",
      "Epoch 114, Batch 100, Loss: 1.264, Acc: 86.440%\n",
      "Epoch 114, Batch 200, Loss: 0.762, Acc: 85.766%\n",
      "Epoch 114, Batch 300, Loss: 0.597, Acc: 85.481%\n",
      "Epoch 114 Training Loss: 0.585, Accuracy: 85.397%\n",
      "Epoch 114, Test Accuracy: 69.89%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_114.csv\n",
      "No improvement for 9 epoch(s)\n",
      "Epoch 115, Batch 0, Loss: 65.183, Acc: 89.844%\n",
      "Epoch 115, Batch 100, Loss: 0.892, Acc: 85.373%\n",
      "Epoch 115, Batch 200, Loss: 0.596, Acc: 84.639%\n",
      "Epoch 115, Batch 300, Loss: 0.493, Acc: 84.448%\n",
      "Epoch 115 Training Loss: 0.486, Accuracy: 84.368%\n",
      "Epoch 115, Test Accuracy: 69.00%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_115.csv\n",
      "No improvement for 10 epoch(s)\n",
      "Epoch 116, Batch 0, Loss: 65.244, Acc: 89.844%\n",
      "Epoch 116, Batch 100, Loss: 0.923, Acc: 83.741%\n",
      "Epoch 116, Batch 200, Loss: 0.614, Acc: 83.656%\n",
      "Epoch 116, Batch 300, Loss: 0.518, Acc: 83.212%\n",
      "Epoch 116 Training Loss: 0.511, Accuracy: 83.188%\n",
      "Epoch 116, Test Accuracy: 68.77%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_116.csv\n",
      "No improvement for 11 epoch(s)\n",
      "Epoch 117, Batch 0, Loss: 125.274, Acc: 80.469%\n",
      "Epoch 117, Batch 100, Loss: 1.542, Acc: 83.277%\n",
      "Epoch 117, Batch 200, Loss: 0.956, Acc: 82.280%\n",
      "Epoch 117, Batch 300, Loss: 0.759, Acc: 81.761%\n",
      "Epoch 117 Training Loss: 0.745, Accuracy: 81.657%\n",
      "Epoch 117, Test Accuracy: 67.81%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_117.csv\n",
      "No improvement for 12 epoch(s)\n",
      "Epoch 118, Batch 0, Loss: 100.356, Acc: 84.375%\n",
      "Epoch 118, Batch 100, Loss: 1.332, Acc: 82.024%\n",
      "Epoch 118, Batch 200, Loss: 0.855, Acc: 81.316%\n",
      "Epoch 118, Batch 300, Loss: 0.702, Acc: 80.604%\n",
      "Epoch 118 Training Loss: 0.691, Accuracy: 80.558%\n",
      "Epoch 118, Test Accuracy: 67.07%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_118.csv\n",
      "No improvement for 13 epoch(s)\n",
      "Epoch 119, Batch 0, Loss: 165.372, Acc: 74.219%\n",
      "Epoch 119, Batch 100, Loss: 2.009, Acc: 80.593%\n",
      "Epoch 119, Batch 200, Loss: 1.229, Acc: 79.660%\n",
      "Epoch 119, Batch 300, Loss: 0.963, Acc: 79.280%\n",
      "Epoch 119 Training Loss: 0.942, Accuracy: 79.270%\n",
      "Epoch 119, Test Accuracy: 67.28%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_119.csv\n",
      "No improvement for 14 epoch(s)\n",
      "Epoch 120, Batch 0, Loss: 125.354, Acc: 80.469%\n",
      "Epoch 120, Batch 100, Loss: 1.663, Acc: 78.636%\n",
      "Epoch 120, Batch 200, Loss: 1.062, Acc: 77.993%\n",
      "Epoch 120, Batch 300, Loss: 0.869, Acc: 77.494%\n",
      "Epoch 120 Training Loss: 0.854, Accuracy: 77.460%\n",
      "Epoch 120, Test Accuracy: 66.63%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_120.csv\n",
      "No improvement for 15 epoch(s)\n",
      "Epoch 121, Batch 0, Loss: 140.412, Acc: 78.125%\n",
      "Epoch 121, Batch 100, Loss: 1.836, Acc: 77.444%\n",
      "Epoch 121, Batch 200, Loss: 1.175, Acc: 76.753%\n",
      "Epoch 121, Batch 300, Loss: 0.959, Acc: 76.391%\n",
      "Epoch 121 Training Loss: 0.941, Accuracy: 76.397%\n",
      "Epoch 121, Test Accuracy: 66.16%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_121.csv\n",
      "No improvement for 16 epoch(s)\n",
      "Epoch 122, Batch 0, Loss: 125.470, Acc: 80.469%\n",
      "Epoch 122, Batch 100, Loss: 1.748, Acc: 75.410%\n",
      "Epoch 122, Batch 200, Loss: 1.150, Acc: 75.016%\n",
      "Epoch 122, Batch 300, Loss: 0.945, Acc: 74.974%\n",
      "Epoch 122 Training Loss: 0.930, Accuracy: 74.892%\n",
      "Epoch 122, Test Accuracy: 65.30%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_122.csv\n",
      "No improvement for 17 epoch(s)\n",
      "Epoch 123, Batch 0, Loss: 160.520, Acc: 75.000%\n",
      "Epoch 123, Batch 100, Loss: 2.105, Acc: 75.882%\n",
      "Epoch 123, Batch 200, Loss: 1.332, Acc: 74.922%\n",
      "Epoch 123, Batch 300, Loss: 1.080, Acc: 74.434%\n",
      "Epoch 123 Training Loss: 1.062, Accuracy: 74.382%\n",
      "Epoch 123, Test Accuracy: 64.71%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_123.csv\n",
      "No improvement for 18 epoch(s)\n",
      "Epoch 124, Batch 0, Loss: 150.543, Acc: 76.562%\n",
      "Epoch 124, Batch 100, Loss: 2.038, Acc: 74.319%\n",
      "Epoch 124, Batch 200, Loss: 1.331, Acc: 73.348%\n",
      "Epoch 124, Batch 300, Loss: 1.095, Acc: 73.012%\n",
      "Epoch 124 Training Loss: 1.076, Accuracy: 73.040%\n",
      "Epoch 124, Test Accuracy: 62.99%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_124.csv\n",
      "No improvement for 19 epoch(s)\n",
      "Epoch 125, Batch 0, Loss: 140.372, Acc: 78.125%\n",
      "Epoch 125, Batch 100, Loss: 1.999, Acc: 73.229%\n",
      "Epoch 125, Batch 200, Loss: 1.314, Acc: 72.812%\n",
      "Epoch 125, Batch 300, Loss: 1.099, Acc: 72.041%\n",
      "Epoch 125 Training Loss: 1.081, Accuracy: 72.040%\n",
      "Epoch 125, Test Accuracy: 63.17%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_125.csv\n",
      "No improvement for 20 epoch(s)\n",
      "Epoch 126, Batch 0, Loss: 160.516, Acc: 75.000%\n",
      "Epoch 126, Batch 100, Loss: 2.200, Acc: 72.432%\n",
      "Epoch 126, Batch 200, Loss: 1.430, Acc: 71.583%\n",
      "Epoch 126, Batch 300, Loss: 1.177, Acc: 71.317%\n",
      "Epoch 126 Training Loss: 1.157, Accuracy: 71.272%\n",
      "Epoch 126, Test Accuracy: 62.84%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_126.csv\n",
      "No improvement for 21 epoch(s)\n",
      "Epoch 127, Batch 0, Loss: 195.581, Acc: 69.531%\n",
      "Epoch 127, Batch 100, Loss: 2.568, Acc: 71.612%\n",
      "Epoch 127, Batch 200, Loss: 1.638, Acc: 70.538%\n",
      "Epoch 127, Batch 300, Loss: 1.332, Acc: 70.320%\n",
      "Epoch 127 Training Loss: 1.308, Accuracy: 70.270%\n",
      "Epoch 127, Test Accuracy: 60.76%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_127.csv\n",
      "No improvement for 22 epoch(s)\n",
      "Epoch 128, Batch 0, Loss: 230.625, Acc: 64.062%\n",
      "Epoch 128, Batch 100, Loss: 2.954, Acc: 69.740%\n",
      "Epoch 128, Batch 200, Loss: 1.835, Acc: 69.718%\n",
      "Epoch 128, Batch 300, Loss: 1.472, Acc: 69.199%\n",
      "Epoch 128 Training Loss: 1.445, Accuracy: 69.123%\n",
      "Epoch 128, Test Accuracy: 61.34%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_128.csv\n",
      "No improvement for 23 epoch(s)\n",
      "Epoch 129, Batch 0, Loss: 210.619, Acc: 67.188%\n",
      "Epoch 129, Batch 100, Loss: 2.762, Acc: 70.258%\n",
      "Epoch 129, Batch 200, Loss: 1.741, Acc: 69.609%\n",
      "Epoch 129, Batch 300, Loss: 1.415, Acc: 69.228%\n",
      "Epoch 129 Training Loss: 1.390, Accuracy: 69.155%\n",
      "Epoch 129, Test Accuracy: 60.81%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_129.csv\n",
      "No improvement for 24 epoch(s)\n",
      "Epoch 130, Batch 0, Loss: 185.681, Acc: 71.094%\n",
      "Epoch 130, Batch 100, Loss: 2.580, Acc: 68.851%\n",
      "Epoch 130, Batch 200, Loss: 1.657, Acc: 68.972%\n",
      "Epoch 130, Batch 300, Loss: 1.359, Acc: 68.825%\n",
      "Epoch 130 Training Loss: 1.337, Accuracy: 68.770%\n",
      "Epoch 130, Test Accuracy: 61.49%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_130.csv\n",
      "No improvement for 25 epoch(s)\n",
      "Epoch 131, Batch 0, Loss: 175.687, Acc: 72.656%\n",
      "Epoch 131, Batch 100, Loss: 2.471, Acc: 68.642%\n",
      "Epoch 131, Batch 200, Loss: 1.637, Acc: 67.973%\n",
      "Epoch 131, Batch 300, Loss: 1.354, Acc: 67.683%\n",
      "Epoch 131 Training Loss: 1.333, Accuracy: 67.683%\n",
      "Epoch 131, Test Accuracy: 60.77%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_131.csv\n",
      "No improvement for 26 epoch(s)\n",
      "Epoch 132, Batch 0, Loss: 180.678, Acc: 71.875%\n",
      "Epoch 132, Batch 100, Loss: 2.535, Acc: 68.379%\n",
      "Epoch 132, Batch 200, Loss: 1.664, Acc: 67.693%\n",
      "Epoch 132, Batch 300, Loss: 1.378, Acc: 67.473%\n",
      "Epoch 132 Training Loss: 1.358, Accuracy: 67.388%\n",
      "Epoch 132, Test Accuracy: 59.99%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_132.csv\n",
      "No improvement for 27 epoch(s)\n",
      "Epoch 133, Batch 0, Loss: 210.804, Acc: 67.188%\n",
      "Epoch 133, Batch 100, Loss: 2.846, Acc: 67.404%\n",
      "Epoch 133, Batch 200, Loss: 1.829, Acc: 66.768%\n",
      "Epoch 133, Batch 300, Loss: 1.501, Acc: 66.432%\n",
      "Epoch 133 Training Loss: 1.475, Accuracy: 66.422%\n",
      "Epoch 133, Test Accuracy: 58.62%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_133.csv\n",
      "No improvement for 28 epoch(s)\n",
      "Epoch 134, Batch 0, Loss: 210.811, Acc: 67.188%\n",
      "Epoch 134, Batch 100, Loss: 2.863, Acc: 67.041%\n",
      "Epoch 134, Batch 200, Loss: 1.849, Acc: 66.472%\n",
      "Epoch 134, Batch 300, Loss: 1.512, Acc: 66.248%\n",
      "Epoch 134 Training Loss: 1.487, Accuracy: 66.260%\n",
      "Epoch 134, Test Accuracy: 60.67%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_134.csv\n",
      "No improvement for 29 epoch(s)\n",
      "Epoch 135, Batch 0, Loss: 230.757, Acc: 64.062%\n",
      "Epoch 135, Batch 100, Loss: 3.051, Acc: 67.041%\n",
      "Epoch 135, Batch 200, Loss: 1.942, Acc: 66.418%\n",
      "Epoch 135, Batch 300, Loss: 1.587, Acc: 65.887%\n",
      "Epoch 135 Training Loss: 1.558, Accuracy: 65.905%\n",
      "Epoch 135, Test Accuracy: 58.66%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_135.csv\n",
      "No improvement for 30 epoch(s)\n",
      "Epoch 136, Batch 0, Loss: 225.836, Acc: 64.844%\n",
      "Epoch 136, Batch 100, Loss: 3.039, Acc: 66.360%\n",
      "Epoch 136, Batch 200, Loss: 1.960, Acc: 65.831%\n",
      "Epoch 136, Batch 300, Loss: 1.599, Acc: 65.482%\n",
      "Epoch 136 Training Loss: 1.570, Accuracy: 65.480%\n",
      "Epoch 136, Test Accuracy: 59.79%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_136.csv\n",
      "No improvement for 31 epoch(s)\n",
      "Epoch 137, Batch 0, Loss: 185.676, Acc: 71.094%\n",
      "Epoch 137, Batch 100, Loss: 2.653, Acc: 66.097%\n",
      "Epoch 137, Batch 200, Loss: 1.772, Acc: 65.205%\n",
      "Epoch 137, Batch 300, Loss: 1.471, Acc: 65.132%\n",
      "Epoch 137 Training Loss: 1.448, Accuracy: 65.123%\n",
      "Epoch 137, Test Accuracy: 62.05%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_137.csv\n",
      "No improvement for 32 epoch(s)\n",
      "Epoch 138, Batch 0, Loss: 210.645, Acc: 67.188%\n",
      "Epoch 138, Batch 100, Loss: 2.913, Acc: 65.903%\n",
      "Epoch 138, Batch 200, Loss: 1.891, Acc: 65.532%\n",
      "Epoch 138, Batch 300, Loss: 1.561, Acc: 65.119%\n",
      "Epoch 138 Training Loss: 1.535, Accuracy: 65.127%\n",
      "Epoch 138, Test Accuracy: 59.88%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_138.csv\n",
      "No improvement for 33 epoch(s)\n",
      "Epoch 139, Batch 0, Loss: 215.854, Acc: 66.406%\n",
      "Epoch 139, Batch 100, Loss: 2.987, Acc: 65.292%\n",
      "Epoch 139, Batch 200, Loss: 1.946, Acc: 64.863%\n",
      "Epoch 139, Batch 300, Loss: 1.595, Acc: 64.815%\n",
      "Epoch 139 Training Loss: 1.568, Accuracy: 64.797%\n",
      "Epoch 139, Test Accuracy: 57.22%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_139.csv\n",
      "No improvement for 34 epoch(s)\n",
      "Epoch 140, Batch 0, Loss: 220.740, Acc: 65.625%\n",
      "Epoch 140, Batch 100, Loss: 3.029, Acc: 65.014%\n",
      "Epoch 140, Batch 200, Loss: 1.960, Acc: 65.023%\n",
      "Epoch 140, Batch 300, Loss: 1.618, Acc: 64.434%\n",
      "Epoch 140 Training Loss: 1.591, Accuracy: 64.433%\n",
      "Epoch 140, Test Accuracy: 58.80%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_140.csv\n",
      "No improvement for 35 epoch(s)\n",
      "Epoch 141, Batch 0, Loss: 190.818, Acc: 70.312%\n",
      "Epoch 141, Batch 100, Loss: 2.767, Acc: 64.356%\n",
      "Epoch 141, Batch 200, Loss: 1.838, Acc: 64.346%\n",
      "Epoch 141, Batch 300, Loss: 1.545, Acc: 63.616%\n",
      "Epoch 141 Training Loss: 1.523, Accuracy: 63.553%\n",
      "Epoch 141, Test Accuracy: 59.47%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_141.csv\n",
      "No improvement for 36 epoch(s)\n",
      "Epoch 142, Batch 0, Loss: 205.856, Acc: 67.969%\n",
      "Epoch 142, Batch 100, Loss: 2.939, Acc: 64.225%\n",
      "Epoch 142, Batch 200, Loss: 1.936, Acc: 63.561%\n",
      "Epoch 142, Batch 300, Loss: 1.604, Acc: 63.248%\n",
      "Epoch 142 Training Loss: 1.578, Accuracy: 63.250%\n",
      "Epoch 142, Test Accuracy: 59.57%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_142.csv\n",
      "No improvement for 37 epoch(s)\n",
      "Epoch 143, Batch 0, Loss: 240.846, Acc: 62.500%\n",
      "Epoch 143, Batch 100, Loss: 3.257, Acc: 64.503%\n",
      "Epoch 143, Batch 200, Loss: 2.113, Acc: 63.441%\n",
      "Epoch 143, Batch 300, Loss: 1.727, Acc: 63.131%\n",
      "Epoch 143 Training Loss: 1.698, Accuracy: 63.072%\n",
      "Epoch 143, Test Accuracy: 58.82%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_143.csv\n",
      "No improvement for 38 epoch(s)\n",
      "Epoch 144, Batch 0, Loss: 255.828, Acc: 60.156%\n",
      "Epoch 144, Batch 100, Loss: 3.451, Acc: 63.088%\n",
      "Epoch 144, Batch 200, Loss: 2.208, Acc: 62.624%\n",
      "Epoch 144, Batch 300, Loss: 1.794, Acc: 62.734%\n",
      "Epoch 144 Training Loss: 1.762, Accuracy: 62.750%\n",
      "Epoch 144, Test Accuracy: 58.91%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_144.csv\n",
      "No improvement for 39 epoch(s)\n",
      "Epoch 145, Batch 0, Loss: 235.971, Acc: 63.281%\n",
      "Epoch 145, Batch 100, Loss: 3.247, Acc: 64.047%\n",
      "Epoch 145, Batch 200, Loss: 2.102, Acc: 63.456%\n",
      "Epoch 145, Batch 300, Loss: 1.730, Acc: 62.840%\n",
      "Epoch 145 Training Loss: 1.704, Accuracy: 62.795%\n",
      "Epoch 145, Test Accuracy: 53.51%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_145.csv\n",
      "No improvement for 40 epoch(s)\n",
      "Epoch 146, Batch 0, Loss: 240.988, Acc: 62.500%\n",
      "Epoch 146, Batch 100, Loss: 3.316, Acc: 62.686%\n",
      "Epoch 146, Batch 200, Loss: 2.148, Acc: 62.395%\n",
      "Epoch 146, Batch 300, Loss: 1.759, Acc: 62.243%\n",
      "Epoch 146 Training Loss: 1.730, Accuracy: 62.225%\n",
      "Epoch 146, Test Accuracy: 58.60%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_146.csv\n",
      "No improvement for 41 epoch(s)\n",
      "Epoch 147, Batch 0, Loss: 225.938, Acc: 64.844%\n",
      "Epoch 147, Batch 100, Loss: 3.169, Acc: 62.655%\n",
      "Epoch 147, Batch 200, Loss: 2.074, Acc: 62.364%\n",
      "Epoch 147, Batch 300, Loss: 1.718, Acc: 62.054%\n",
      "Epoch 147 Training Loss: 1.691, Accuracy: 61.975%\n",
      "Epoch 147, Test Accuracy: 60.34%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_147.csv\n",
      "No improvement for 42 epoch(s)\n",
      "Epoch 148, Batch 0, Loss: 266.029, Acc: 58.594%\n",
      "Epoch 148, Batch 100, Loss: 3.565, Acc: 63.057%\n",
      "Epoch 148, Batch 200, Loss: 2.291, Acc: 62.263%\n",
      "Epoch 148, Batch 300, Loss: 1.862, Acc: 61.877%\n",
      "Epoch 148 Training Loss: 1.829, Accuracy: 61.855%\n",
      "Epoch 148, Test Accuracy: 54.91%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_148.csv\n",
      "No improvement for 43 epoch(s)\n",
      "Epoch 149, Batch 0, Loss: 250.907, Acc: 60.938%\n",
      "Epoch 149, Batch 100, Loss: 3.458, Acc: 62.229%\n",
      "Epoch 149, Batch 200, Loss: 2.232, Acc: 61.929%\n",
      "Epoch 149, Batch 300, Loss: 1.828, Acc: 61.867%\n",
      "Epoch 149 Training Loss: 1.797, Accuracy: 61.778%\n",
      "Epoch 149, Test Accuracy: 53.41%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_149.csv\n",
      "No improvement for 44 epoch(s)\n",
      "Epoch 150, Batch 0, Loss: 230.952, Acc: 64.062%\n",
      "Epoch 150, Batch 100, Loss: 3.263, Acc: 61.487%\n",
      "Epoch 150, Batch 200, Loss: 2.145, Acc: 61.369%\n",
      "Epoch 150, Batch 300, Loss: 1.778, Acc: 61.156%\n",
      "Epoch 150 Training Loss: 1.751, Accuracy: 61.123%\n",
      "Epoch 150, Test Accuracy: 56.64%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_150.csv\n",
      "No improvement for 45 epoch(s)\n",
      "Epoch 151, Batch 0, Loss: 205.867, Acc: 67.969%\n",
      "Epoch 151, Batch 100, Loss: 2.998, Acc: 61.966%\n",
      "Epoch 151, Batch 200, Loss: 2.019, Acc: 61.147%\n",
      "Epoch 151, Batch 300, Loss: 1.696, Acc: 60.691%\n",
      "Epoch 151 Training Loss: 1.673, Accuracy: 60.678%\n",
      "Epoch 151, Test Accuracy: 57.22%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_151.csv\n",
      "No improvement for 46 epoch(s)\n",
      "Epoch 152, Batch 0, Loss: 261.005, Acc: 59.375%\n",
      "Epoch 152, Batch 100, Loss: 3.604, Acc: 60.613%\n",
      "Epoch 152, Batch 200, Loss: 2.338, Acc: 60.347%\n",
      "Epoch 152, Batch 300, Loss: 1.909, Acc: 60.382%\n",
      "Epoch 152 Training Loss: 1.878, Accuracy: 60.305%\n",
      "Epoch 152, Test Accuracy: 54.60%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_152.csv\n",
      "No improvement for 47 epoch(s)\n",
      "Epoch 153, Batch 0, Loss: 240.882, Acc: 62.500%\n",
      "Epoch 153, Batch 100, Loss: 3.400, Acc: 61.054%\n",
      "Epoch 153, Batch 200, Loss: 2.230, Acc: 60.681%\n",
      "Epoch 153, Batch 300, Loss: 1.842, Acc: 60.478%\n",
      "Epoch 153 Training Loss: 1.813, Accuracy: 60.450%\n",
      "Epoch 153, Test Accuracy: 56.64%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_153.csv\n",
      "No improvement for 48 epoch(s)\n",
      "Epoch 154, Batch 0, Loss: 271.147, Acc: 57.812%\n",
      "Epoch 154, Batch 100, Loss: 3.686, Acc: 61.324%\n",
      "Epoch 154, Batch 200, Loss: 2.376, Acc: 60.615%\n",
      "Epoch 154, Batch 300, Loss: 1.944, Acc: 60.024%\n",
      "Epoch 154 Training Loss: 1.911, Accuracy: 59.955%\n",
      "Epoch 154, Test Accuracy: 56.01%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_154.csv\n",
      "No improvement for 49 epoch(s)\n",
      "Epoch 155, Batch 0, Loss: 270.994, Acc: 57.812%\n",
      "Epoch 155, Batch 100, Loss: 3.717, Acc: 60.288%\n",
      "Epoch 155, Batch 200, Loss: 2.404, Acc: 59.667%\n",
      "Epoch 155, Batch 300, Loss: 1.966, Acc: 59.500%\n",
      "Epoch 155 Training Loss: 1.930, Accuracy: 59.492%\n",
      "Epoch 155, Test Accuracy: 57.91%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_155.csv\n",
      "No improvement for 50 epoch(s)\n",
      "Epoch 156, Batch 0, Loss: 215.853, Acc: 66.406%\n",
      "Epoch 156, Batch 100, Loss: 3.180, Acc: 59.909%\n",
      "Epoch 156, Batch 200, Loss: 2.138, Acc: 59.426%\n",
      "Epoch 156, Batch 300, Loss: 1.802, Acc: 59.108%\n",
      "Epoch 156 Training Loss: 1.775, Accuracy: 59.025%\n",
      "Epoch 156, Test Accuracy: 54.86%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_156.csv\n",
      "No improvement for 51 epoch(s)\n",
      "Epoch 157, Batch 0, Loss: 230.941, Acc: 64.062%\n",
      "Epoch 157, Batch 100, Loss: 3.328, Acc: 59.769%\n",
      "Epoch 157, Batch 200, Loss: 2.213, Acc: 59.511%\n",
      "Epoch 157, Batch 300, Loss: 1.846, Acc: 59.170%\n",
      "Epoch 157 Training Loss: 1.818, Accuracy: 59.120%\n",
      "Epoch 157, Test Accuracy: 52.01%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_157.csv\n",
      "No improvement for 52 epoch(s)\n",
      "Epoch 158, Batch 0, Loss: 266.143, Acc: 58.594%\n",
      "Epoch 158, Batch 100, Loss: 3.703, Acc: 59.530%\n",
      "Epoch 158, Batch 200, Loss: 2.415, Acc: 58.811%\n",
      "Epoch 158, Batch 300, Loss: 1.983, Acc: 58.669%\n",
      "Epoch 158 Training Loss: 1.950, Accuracy: 58.625%\n",
      "Epoch 158, Test Accuracy: 53.25%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_158.csv\n",
      "No improvement for 53 epoch(s)\n",
      "Epoch 159, Batch 0, Loss: 215.940, Acc: 66.406%\n",
      "Epoch 159, Batch 100, Loss: 3.218, Acc: 59.166%\n",
      "Epoch 159, Batch 200, Loss: 2.172, Acc: 59.041%\n",
      "Epoch 159, Batch 300, Loss: 1.821, Acc: 58.622%\n",
      "Epoch 159 Training Loss: 1.796, Accuracy: 58.605%\n",
      "Epoch 159, Test Accuracy: 56.31%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_159.csv\n",
      "No improvement for 54 epoch(s)\n",
      "Epoch 160, Batch 0, Loss: 250.992, Acc: 60.938%\n",
      "Epoch 160, Batch 100, Loss: 3.546, Acc: 59.886%\n",
      "Epoch 160, Batch 200, Loss: 2.351, Acc: 58.940%\n",
      "Epoch 160, Batch 300, Loss: 1.959, Acc: 58.230%\n",
      "Epoch 160 Training Loss: 1.929, Accuracy: 58.190%\n",
      "Epoch 160, Test Accuracy: 54.90%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_160.csv\n",
      "No improvement for 55 epoch(s)\n",
      "Epoch 161, Batch 0, Loss: 1.297, Acc: 49.219%\n",
      "Epoch 161, Batch 100, Loss: 1.106, Acc: 58.857%\n",
      "Epoch 161, Batch 200, Loss: 1.116, Acc: 58.497%\n",
      "Epoch 161, Batch 300, Loss: 1.134, Acc: 58.020%\n",
      "Epoch 161 Training Loss: 1.135, Accuracy: 58.040%\n",
      "Epoch 161, Test Accuracy: 54.73%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_161.csv\n",
      "No improvement for 56 epoch(s)\n",
      "Epoch 162, Batch 0, Loss: 240.868, Acc: 62.500%\n",
      "Epoch 162, Batch 100, Loss: 3.489, Acc: 58.292%\n",
      "Epoch 162, Batch 200, Loss: 2.329, Acc: 57.937%\n",
      "Epoch 162, Batch 300, Loss: 1.947, Acc: 57.553%\n",
      "Epoch 162 Training Loss: 1.918, Accuracy: 57.517%\n",
      "Epoch 162, Test Accuracy: 53.66%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_162.csv\n",
      "No improvement for 57 epoch(s)\n",
      "Epoch 163, Batch 0, Loss: 311.320, Acc: 51.562%\n",
      "Epoch 163, Batch 100, Loss: 4.222, Acc: 57.248%\n",
      "Epoch 163, Batch 200, Loss: 2.695, Acc: 57.408%\n",
      "Epoch 163, Batch 300, Loss: 2.189, Acc: 57.366%\n",
      "Epoch 163 Training Loss: 2.151, Accuracy: 57.328%\n",
      "Epoch 163, Test Accuracy: 51.34%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_163.csv\n",
      "No improvement for 58 epoch(s)\n",
      "Epoch 164, Batch 0, Loss: 251.022, Acc: 60.938%\n",
      "Epoch 164, Batch 100, Loss: 3.606, Acc: 57.658%\n",
      "Epoch 164, Batch 200, Loss: 2.384, Acc: 57.451%\n",
      "Epoch 164, Batch 300, Loss: 1.983, Acc: 57.402%\n",
      "Epoch 164 Training Loss: 1.955, Accuracy: 57.333%\n",
      "Epoch 164, Test Accuracy: 52.63%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_164.csv\n",
      "No improvement for 59 epoch(s)\n",
      "Epoch 165, Batch 0, Loss: 251.116, Acc: 60.938%\n",
      "Epoch 165, Batch 100, Loss: 3.635, Acc: 57.178%\n",
      "Epoch 165, Batch 200, Loss: 2.408, Acc: 57.272%\n",
      "Epoch 165, Batch 300, Loss: 2.007, Acc: 56.878%\n",
      "Epoch 165 Training Loss: 1.981, Accuracy: 56.735%\n",
      "Epoch 165, Test Accuracy: 53.29%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_165.csv\n",
      "No improvement for 60 epoch(s)\n",
      "Epoch 166, Batch 0, Loss: 286.163, Acc: 55.469%\n",
      "Epoch 166, Batch 100, Loss: 3.965, Acc: 57.186%\n",
      "Epoch 166, Batch 200, Loss: 2.585, Acc: 56.965%\n",
      "Epoch 166, Batch 300, Loss: 2.128, Acc: 56.561%\n",
      "Epoch 166 Training Loss: 2.092, Accuracy: 56.572%\n",
      "Epoch 166, Test Accuracy: 56.95%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_166.csv\n",
      "No improvement for 61 epoch(s)\n",
      "Epoch 167, Batch 0, Loss: 261.053, Acc: 59.375%\n",
      "Epoch 167, Batch 100, Loss: 3.741, Acc: 57.534%\n",
      "Epoch 167, Batch 200, Loss: 2.472, Acc: 57.288%\n",
      "Epoch 167, Batch 300, Loss: 2.058, Acc: 56.735%\n",
      "Epoch 167 Training Loss: 2.025, Accuracy: 56.742%\n",
      "Epoch 167, Test Accuracy: 50.55%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_167.csv\n",
      "No improvement for 62 epoch(s)\n",
      "Epoch 168, Batch 0, Loss: 281.203, Acc: 56.250%\n",
      "Epoch 168, Batch 100, Loss: 3.926, Acc: 56.799%\n",
      "Epoch 168, Batch 200, Loss: 2.580, Acc: 56.242%\n",
      "Epoch 168, Batch 300, Loss: 2.127, Acc: 56.061%\n",
      "Epoch 168 Training Loss: 2.093, Accuracy: 56.015%\n",
      "Epoch 168, Test Accuracy: 54.01%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_168.csv\n",
      "No improvement for 63 epoch(s)\n",
      "Epoch 169, Batch 0, Loss: 281.163, Acc: 56.250%\n",
      "Epoch 169, Batch 100, Loss: 3.933, Acc: 57.101%\n",
      "Epoch 169, Batch 200, Loss: 2.578, Acc: 56.254%\n",
      "Epoch 169, Batch 300, Loss: 2.129, Acc: 56.040%\n",
      "Epoch 169 Training Loss: 2.098, Accuracy: 55.945%\n",
      "Epoch 169, Test Accuracy: 54.57%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_169.csv\n",
      "No improvement for 64 epoch(s)\n",
      "Epoch 170, Batch 0, Loss: 276.197, Acc: 57.031%\n",
      "Epoch 170, Batch 100, Loss: 3.920, Acc: 55.979%\n",
      "Epoch 170, Batch 200, Loss: 2.576, Acc: 55.807%\n",
      "Epoch 170, Batch 300, Loss: 2.123, Acc: 55.752%\n",
      "Epoch 170 Training Loss: 2.093, Accuracy: 55.660%\n",
      "Epoch 170, Test Accuracy: 51.80%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_170.csv\n",
      "No improvement for 65 epoch(s)\n",
      "Epoch 171, Batch 0, Loss: 1.446, Acc: 49.219%\n",
      "Epoch 171, Batch 100, Loss: 1.210, Acc: 56.095%\n",
      "Epoch 171, Batch 200, Loss: 1.213, Acc: 55.694%\n",
      "Epoch 171, Batch 300, Loss: 1.222, Acc: 55.419%\n",
      "Epoch 171 Training Loss: 1.225, Accuracy: 55.312%\n",
      "Epoch 171, Test Accuracy: 53.33%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_171.csv\n",
      "No improvement for 66 epoch(s)\n",
      "Epoch 172, Batch 0, Loss: 311.306, Acc: 51.562%\n",
      "Epoch 172, Batch 100, Loss: 4.294, Acc: 55.461%\n",
      "Epoch 172, Batch 200, Loss: 2.770, Acc: 55.515%\n",
      "Epoch 172, Batch 300, Loss: 2.262, Acc: 55.505%\n",
      "Epoch 172 Training Loss: 2.225, Accuracy: 55.472%\n",
      "Epoch 172, Test Accuracy: 54.88%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_172.csv\n",
      "No improvement for 67 epoch(s)\n",
      "Epoch 173, Batch 0, Loss: 291.258, Acc: 54.688%\n",
      "Epoch 173, Batch 100, Loss: 4.082, Acc: 55.685%\n",
      "Epoch 173, Batch 200, Loss: 2.671, Acc: 55.504%\n",
      "Epoch 173, Batch 300, Loss: 2.208, Acc: 55.116%\n",
      "Epoch 173 Training Loss: 2.174, Accuracy: 54.987%\n",
      "Epoch 173, Test Accuracy: 52.79%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_173.csv\n",
      "No improvement for 68 epoch(s)\n",
      "Epoch 174, Batch 0, Loss: 271.126, Acc: 57.812%\n",
      "Epoch 174, Batch 100, Loss: 3.902, Acc: 55.051%\n",
      "Epoch 174, Batch 200, Loss: 2.599, Acc: 54.664%\n",
      "Epoch 174, Batch 300, Loss: 2.153, Acc: 54.812%\n",
      "Epoch 174 Training Loss: 2.118, Accuracy: 54.785%\n",
      "Epoch 174, Test Accuracy: 49.77%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_174.csv\n",
      "No improvement for 69 epoch(s)\n",
      "Epoch 175, Batch 0, Loss: 286.184, Acc: 55.469%\n",
      "Epoch 175, Batch 100, Loss: 4.061, Acc: 55.554%\n",
      "Epoch 175, Batch 200, Loss: 2.668, Acc: 54.847%\n",
      "Epoch 175, Batch 300, Loss: 2.204, Acc: 54.607%\n",
      "Epoch 175 Training Loss: 2.169, Accuracy: 54.630%\n",
      "Epoch 175, Test Accuracy: 50.58%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_175.csv\n",
      "No improvement for 70 epoch(s)\n",
      "Epoch 176, Batch 0, Loss: 296.254, Acc: 53.906%\n",
      "Epoch 176, Batch 100, Loss: 4.153, Acc: 55.554%\n",
      "Epoch 176, Batch 200, Loss: 2.711, Acc: 55.274%\n",
      "Epoch 176, Batch 300, Loss: 2.232, Acc: 55.152%\n",
      "Epoch 176 Training Loss: 2.195, Accuracy: 55.125%\n",
      "Epoch 176, Test Accuracy: 47.02%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_176.csv\n",
      "No improvement for 71 epoch(s)\n",
      "Epoch 177, Batch 0, Loss: 306.250, Acc: 52.344%\n",
      "Epoch 177, Batch 100, Loss: 4.278, Acc: 54.092%\n",
      "Epoch 177, Batch 200, Loss: 2.780, Acc: 54.159%\n",
      "Epoch 177, Batch 300, Loss: 2.289, Acc: 54.078%\n",
      "Epoch 177 Training Loss: 2.251, Accuracy: 54.010%\n",
      "Epoch 177, Test Accuracy: 52.47%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_177.csv\n",
      "No improvement for 72 epoch(s)\n",
      "Epoch 178, Batch 0, Loss: 235.927, Acc: 63.281%\n",
      "Epoch 178, Batch 100, Loss: 3.565, Acc: 55.353%\n",
      "Epoch 178, Batch 200, Loss: 2.418, Acc: 55.037%\n",
      "Epoch 178, Batch 300, Loss: 2.048, Acc: 54.524%\n",
      "Epoch 178 Training Loss: 2.022, Accuracy: 54.395%\n",
      "Epoch 178, Test Accuracy: 50.12%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_178.csv\n",
      "No improvement for 73 epoch(s)\n",
      "Epoch 179, Batch 0, Loss: 296.195, Acc: 53.906%\n",
      "Epoch 179, Batch 100, Loss: 4.197, Acc: 54.672%\n",
      "Epoch 179, Batch 200, Loss: 2.763, Acc: 54.069%\n",
      "Epoch 179, Batch 300, Loss: 2.274, Acc: 53.906%\n",
      "Epoch 179 Training Loss: 2.237, Accuracy: 53.905%\n",
      "Epoch 179, Test Accuracy: 50.78%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_179.csv\n",
      "No improvement for 74 epoch(s)\n",
      "Epoch 180, Batch 0, Loss: 286.308, Acc: 55.469%\n",
      "Epoch 180, Batch 100, Loss: 4.067, Acc: 54.788%\n",
      "Epoch 180, Batch 200, Loss: 2.687, Acc: 54.408%\n",
      "Epoch 180, Batch 300, Loss: 2.233, Acc: 54.039%\n",
      "Epoch 180 Training Loss: 2.197, Accuracy: 54.030%\n",
      "Epoch 180, Test Accuracy: 49.05%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_180.csv\n",
      "No improvement for 75 epoch(s)\n",
      "Epoch 181, Batch 0, Loss: 311.433, Acc: 51.562%\n",
      "Epoch 181, Batch 100, Loss: 4.362, Acc: 53.883%\n",
      "Epoch 181, Batch 200, Loss: 2.827, Acc: 54.042%\n",
      "Epoch 181, Batch 300, Loss: 2.320, Acc: 53.932%\n",
      "Epoch 181 Training Loss: 2.281, Accuracy: 53.962%\n",
      "Epoch 181, Test Accuracy: 51.47%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_181.csv\n",
      "No improvement for 76 epoch(s)\n",
      "Epoch 182, Batch 0, Loss: 316.149, Acc: 50.781%\n",
      "Epoch 182, Batch 100, Loss: 4.396, Acc: 54.904%\n",
      "Epoch 182, Batch 200, Loss: 2.855, Acc: 54.590%\n",
      "Epoch 182, Batch 300, Loss: 2.342, Acc: 54.345%\n",
      "Epoch 182 Training Loss: 2.302, Accuracy: 54.307%\n",
      "Epoch 182, Test Accuracy: 48.75%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_182.csv\n",
      "No improvement for 77 epoch(s)\n",
      "Epoch 183, Batch 0, Loss: 276.276, Acc: 57.031%\n",
      "Epoch 183, Batch 100, Loss: 3.988, Acc: 54.850%\n",
      "Epoch 183, Batch 200, Loss: 2.651, Acc: 54.435%\n",
      "Epoch 183, Batch 300, Loss: 2.205, Acc: 54.098%\n",
      "Epoch 183 Training Loss: 2.172, Accuracy: 54.100%\n",
      "Epoch 183, Test Accuracy: 50.95%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_183.csv\n",
      "No improvement for 78 epoch(s)\n",
      "Epoch 184, Batch 0, Loss: 256.134, Acc: 60.156%\n",
      "Epoch 184, Batch 100, Loss: 3.810, Acc: 53.852%\n",
      "Epoch 184, Batch 200, Loss: 2.569, Acc: 53.836%\n",
      "Epoch 184, Batch 300, Loss: 2.152, Acc: 53.496%\n",
      "Epoch 184 Training Loss: 2.118, Accuracy: 53.557%\n",
      "Epoch 184, Test Accuracy: 49.34%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_184.csv\n",
      "No improvement for 79 epoch(s)\n",
      "Epoch 185, Batch 0, Loss: 1.479, Acc: 50.000%\n",
      "Epoch 185, Batch 100, Loss: 1.282, Acc: 53.991%\n",
      "Epoch 185, Batch 200, Loss: 1.296, Acc: 53.801%\n",
      "Epoch 185, Batch 300, Loss: 1.315, Acc: 53.340%\n",
      "Epoch 185 Training Loss: 1.320, Accuracy: 53.278%\n",
      "Epoch 185, Test Accuracy: 56.01%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_185.csv\n",
      "No improvement for 80 epoch(s)\n",
      "Epoch 186, Batch 0, Loss: 296.234, Acc: 53.906%\n",
      "Epoch 186, Batch 100, Loss: 4.201, Acc: 53.960%\n",
      "Epoch 186, Batch 200, Loss: 2.767, Acc: 53.584%\n",
      "Epoch 186, Batch 300, Loss: 2.299, Acc: 53.182%\n",
      "Epoch 186 Training Loss: 2.260, Accuracy: 53.255%\n",
      "Epoch 186, Test Accuracy: 48.48%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_186.csv\n",
      "No improvement for 81 epoch(s)\n",
      "Epoch 187, Batch 0, Loss: 1.484, Acc: 45.312%\n",
      "Epoch 187, Batch 100, Loss: 1.288, Acc: 53.790%\n",
      "Epoch 187, Batch 200, Loss: 1.314, Acc: 53.370%\n",
      "Epoch 187, Batch 300, Loss: 1.324, Acc: 53.208%\n",
      "Epoch 187 Training Loss: 1.327, Accuracy: 53.117%\n",
      "Epoch 187, Test Accuracy: 53.82%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_187.csv\n",
      "No improvement for 82 epoch(s)\n",
      "Epoch 188, Batch 0, Loss: 271.249, Acc: 57.812%\n",
      "Epoch 188, Batch 100, Loss: 3.947, Acc: 54.672%\n",
      "Epoch 188, Batch 200, Loss: 2.648, Acc: 53.984%\n",
      "Epoch 188, Batch 300, Loss: 2.210, Acc: 53.847%\n",
      "Epoch 188 Training Loss: 2.179, Accuracy: 53.727%\n",
      "Epoch 188, Test Accuracy: 46.34%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_188.csv\n",
      "No improvement for 83 epoch(s)\n",
      "Epoch 189, Batch 0, Loss: 301.167, Acc: 53.125%\n",
      "Epoch 189, Batch 100, Loss: 4.309, Acc: 52.893%\n",
      "Epoch 189, Batch 200, Loss: 2.827, Acc: 52.946%\n",
      "Epoch 189, Batch 300, Loss: 2.331, Acc: 52.834%\n",
      "Epoch 189 Training Loss: 2.290, Accuracy: 52.945%\n",
      "Epoch 189, Test Accuracy: 43.53%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_189.csv\n",
      "No improvement for 84 epoch(s)\n",
      "Epoch 190, Batch 0, Loss: 281.113, Acc: 56.250%\n",
      "Epoch 190, Batch 100, Loss: 4.056, Acc: 54.394%\n",
      "Epoch 190, Batch 200, Loss: 2.701, Acc: 53.626%\n",
      "Epoch 190, Batch 300, Loss: 2.250, Acc: 53.237%\n",
      "Epoch 190 Training Loss: 2.216, Accuracy: 53.225%\n",
      "Epoch 190, Test Accuracy: 49.38%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_190.csv\n",
      "No improvement for 85 epoch(s)\n",
      "Epoch 191, Batch 0, Loss: 276.254, Acc: 57.031%\n",
      "Epoch 191, Batch 100, Loss: 4.036, Acc: 53.256%\n",
      "Epoch 191, Batch 200, Loss: 2.682, Acc: 53.296%\n",
      "Epoch 191, Batch 300, Loss: 2.232, Acc: 53.091%\n",
      "Epoch 191 Training Loss: 2.199, Accuracy: 53.105%\n",
      "Epoch 191, Test Accuracy: 46.66%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_191.csv\n",
      "No improvement for 86 epoch(s)\n",
      "Epoch 192, Batch 0, Loss: 291.442, Acc: 54.688%\n",
      "Epoch 192, Batch 100, Loss: 4.187, Acc: 53.318%\n",
      "Epoch 192, Batch 200, Loss: 2.764, Acc: 53.354%\n",
      "Epoch 192, Batch 300, Loss: 2.294, Acc: 52.993%\n",
      "Epoch 192 Training Loss: 2.258, Accuracy: 52.977%\n",
      "Epoch 192, Test Accuracy: 48.73%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_192.csv\n",
      "No improvement for 87 epoch(s)\n",
      "Epoch 193, Batch 0, Loss: 241.147, Acc: 62.500%\n",
      "Epoch 193, Batch 100, Loss: 3.715, Acc: 53.032%\n",
      "Epoch 193, Batch 200, Loss: 2.531, Acc: 52.927%\n",
      "Epoch 193, Batch 300, Loss: 2.139, Acc: 52.627%\n",
      "Epoch 193 Training Loss: 2.108, Accuracy: 52.655%\n",
      "Epoch 193, Test Accuracy: 46.84%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_193.csv\n",
      "No improvement for 88 epoch(s)\n",
      "Epoch 194, Batch 0, Loss: 311.344, Acc: 51.562%\n",
      "Epoch 194, Batch 100, Loss: 4.382, Acc: 53.117%\n",
      "Epoch 194, Batch 200, Loss: 2.860, Acc: 53.121%\n",
      "Epoch 194, Batch 300, Loss: 2.359, Acc: 52.801%\n",
      "Epoch 194 Training Loss: 2.323, Accuracy: 52.737%\n",
      "Epoch 194, Test Accuracy: 46.70%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_194.csv\n",
      "No improvement for 89 epoch(s)\n",
      "Epoch 195, Batch 0, Loss: 261.119, Acc: 59.375%\n",
      "Epoch 195, Batch 100, Loss: 3.885, Acc: 54.316%\n",
      "Epoch 195, Batch 200, Loss: 2.602, Acc: 53.755%\n",
      "Epoch 195, Batch 300, Loss: 2.188, Acc: 53.400%\n",
      "Epoch 195 Training Loss: 2.157, Accuracy: 53.320%\n",
      "Epoch 195, Test Accuracy: 48.01%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_195.csv\n",
      "No improvement for 90 epoch(s)\n",
      "Epoch 196, Batch 0, Loss: 261.273, Acc: 59.375%\n",
      "Epoch 196, Batch 100, Loss: 3.889, Acc: 53.024%\n",
      "Epoch 196, Batch 200, Loss: 2.620, Acc: 53.074%\n",
      "Epoch 196, Batch 300, Loss: 2.200, Acc: 52.964%\n",
      "Epoch 196 Training Loss: 2.166, Accuracy: 52.920%\n",
      "Epoch 196, Test Accuracy: 47.45%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_196.csv\n",
      "No improvement for 91 epoch(s)\n",
      "Epoch 197, Batch 0, Loss: 306.219, Acc: 52.344%\n",
      "Epoch 197, Batch 100, Loss: 4.311, Acc: 53.365%\n",
      "Epoch 197, Batch 200, Loss: 2.836, Acc: 52.783%\n",
      "Epoch 197, Batch 300, Loss: 2.346, Acc: 52.764%\n",
      "Epoch 197 Training Loss: 2.308, Accuracy: 52.715%\n",
      "Epoch 197, Test Accuracy: 49.86%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_197.csv\n",
      "No improvement for 92 epoch(s)\n",
      "Epoch 198, Batch 0, Loss: 261.357, Acc: 59.375%\n",
      "Epoch 198, Batch 100, Loss: 3.891, Acc: 53.790%\n",
      "Epoch 198, Batch 200, Loss: 2.616, Acc: 53.218%\n",
      "Epoch 198, Batch 300, Loss: 2.201, Acc: 52.785%\n",
      "Epoch 198 Training Loss: 2.168, Accuracy: 52.797%\n",
      "Epoch 198, Test Accuracy: 48.18%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_198.csv\n",
      "No improvement for 93 epoch(s)\n",
      "Epoch 199, Batch 0, Loss: 306.298, Acc: 52.344%\n",
      "Epoch 199, Batch 100, Loss: 4.331, Acc: 53.504%\n",
      "Epoch 199, Batch 200, Loss: 2.848, Acc: 52.942%\n",
      "Epoch 199, Batch 300, Loss: 2.345, Acc: 52.912%\n",
      "Epoch 199 Training Loss: 2.305, Accuracy: 52.915%\n",
      "Epoch 199, Test Accuracy: 51.80%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_199.csv\n",
      "No improvement for 94 epoch(s)\n",
      "Epoch 200, Batch 0, Loss: 306.445, Acc: 52.344%\n",
      "Epoch 200, Batch 100, Loss: 4.305, Acc: 54.455%\n",
      "Epoch 200, Batch 200, Loss: 2.826, Acc: 53.735%\n",
      "Epoch 200, Batch 300, Loss: 2.344, Acc: 53.099%\n",
      "Epoch 200 Training Loss: 2.307, Accuracy: 53.030%\n",
      "Epoch 200, Test Accuracy: 53.05%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_200.csv\n",
      "No improvement for 95 epoch(s)\n",
      "Epoch 201, Batch 0, Loss: 1.337, Acc: 48.438%\n",
      "Epoch 201, Batch 100, Loss: 1.326, Acc: 52.854%\n",
      "Epoch 201, Batch 200, Loss: 1.332, Acc: 52.690%\n",
      "Epoch 201, Batch 300, Loss: 1.345, Acc: 52.432%\n",
      "Epoch 201 Training Loss: 1.345, Accuracy: 52.470%\n",
      "Epoch 201, Test Accuracy: 52.92%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_201.csv\n",
      "No improvement for 96 epoch(s)\n",
      "Epoch 202, Batch 0, Loss: 251.184, Acc: 60.938%\n",
      "Epoch 202, Batch 100, Loss: 3.819, Acc: 53.148%\n",
      "Epoch 202, Batch 200, Loss: 2.582, Acc: 53.082%\n",
      "Epoch 202, Batch 300, Loss: 2.172, Acc: 52.858%\n",
      "Epoch 202 Training Loss: 2.143, Accuracy: 52.752%\n",
      "Epoch 202, Test Accuracy: 49.16%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_202.csv\n",
      "No improvement for 97 epoch(s)\n",
      "Epoch 203, Batch 0, Loss: 306.482, Acc: 52.344%\n",
      "Epoch 203, Batch 100, Loss: 4.332, Acc: 53.512%\n",
      "Epoch 203, Batch 200, Loss: 2.835, Acc: 53.098%\n",
      "Epoch 203, Batch 300, Loss: 2.335, Acc: 52.907%\n",
      "Epoch 203 Training Loss: 2.301, Accuracy: 52.820%\n",
      "Epoch 203, Test Accuracy: 46.88%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_203.csv\n",
      "No improvement for 98 epoch(s)\n",
      "Epoch 204, Batch 0, Loss: 261.361, Acc: 59.375%\n",
      "Epoch 204, Batch 100, Loss: 3.890, Acc: 53.156%\n",
      "Epoch 204, Batch 200, Loss: 2.622, Acc: 52.993%\n",
      "Epoch 204, Batch 300, Loss: 2.202, Acc: 52.749%\n",
      "Epoch 204 Training Loss: 2.169, Accuracy: 52.750%\n",
      "Epoch 204, Test Accuracy: 50.09%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_204.csv\n",
      "No improvement for 99 epoch(s)\n",
      "Epoch 205, Batch 0, Loss: 316.348, Acc: 50.781%\n",
      "Epoch 205, Batch 100, Loss: 4.455, Acc: 52.792%\n",
      "Epoch 205, Batch 200, Loss: 2.905, Acc: 52.674%\n",
      "Epoch 205, Batch 300, Loss: 2.388, Acc: 52.505%\n",
      "Epoch 205 Training Loss: 2.350, Accuracy: 52.453%\n",
      "Epoch 205, Test Accuracy: 48.26%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_205.csv\n",
      "No improvement for 100 epoch(s)\n",
      "Epoch 206, Batch 0, Loss: 311.229, Acc: 51.562%\n",
      "Epoch 206, Batch 100, Loss: 4.381, Acc: 53.249%\n",
      "Epoch 206, Batch 200, Loss: 2.867, Acc: 53.055%\n",
      "Epoch 206, Batch 300, Loss: 2.369, Acc: 52.673%\n",
      "Epoch 206 Training Loss: 2.327, Accuracy: 52.722%\n",
      "Epoch 206, Test Accuracy: 51.39%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_206.csv\n",
      "No improvement for 101 epoch(s)\n",
      "Epoch 207, Batch 0, Loss: 1.385, Acc: 49.219%\n",
      "Epoch 207, Batch 100, Loss: 1.299, Acc: 53.775%\n",
      "Epoch 207, Batch 200, Loss: 1.312, Acc: 53.560%\n",
      "Epoch 207, Batch 300, Loss: 1.327, Acc: 53.180%\n",
      "Epoch 207 Training Loss: 1.329, Accuracy: 53.053%\n",
      "Epoch 207, Test Accuracy: 50.90%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_207.csv\n",
      "No improvement for 102 epoch(s)\n",
      "Epoch 208, Batch 0, Loss: 281.116, Acc: 56.250%\n",
      "Epoch 208, Batch 100, Loss: 4.062, Acc: 54.425%\n",
      "Epoch 208, Batch 200, Loss: 2.706, Acc: 53.689%\n",
      "Epoch 208, Batch 300, Loss: 2.261, Acc: 53.148%\n",
      "Epoch 208 Training Loss: 2.223, Accuracy: 53.218%\n",
      "Epoch 208, Test Accuracy: 49.13%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_208.csv\n",
      "No improvement for 103 epoch(s)\n",
      "Epoch 209, Batch 0, Loss: 291.299, Acc: 54.688%\n",
      "Epoch 209, Batch 100, Loss: 4.169, Acc: 53.643%\n",
      "Epoch 209, Batch 200, Loss: 2.755, Acc: 53.187%\n",
      "Epoch 209, Batch 300, Loss: 2.281, Acc: 53.078%\n",
      "Epoch 209 Training Loss: 2.244, Accuracy: 53.110%\n",
      "Epoch 209, Test Accuracy: 53.10%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_209.csv\n",
      "No improvement for 104 epoch(s)\n",
      "Epoch 210, Batch 0, Loss: 281.425, Acc: 56.250%\n",
      "Epoch 210, Batch 100, Loss: 4.058, Acc: 54.865%\n",
      "Epoch 210, Batch 200, Loss: 2.705, Acc: 53.805%\n",
      "Epoch 210, Batch 300, Loss: 2.255, Acc: 53.481%\n",
      "Epoch 210 Training Loss: 2.223, Accuracy: 53.415%\n",
      "Epoch 210, Test Accuracy: 51.09%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_210.csv\n",
      "No improvement for 105 epoch(s)\n",
      "Epoch 211, Batch 0, Loss: 266.305, Acc: 58.594%\n",
      "Epoch 211, Batch 100, Loss: 3.908, Acc: 54.231%\n",
      "Epoch 211, Batch 200, Loss: 2.631, Acc: 53.529%\n",
      "Epoch 211, Batch 300, Loss: 2.202, Acc: 53.296%\n",
      "Epoch 211 Training Loss: 2.169, Accuracy: 53.285%\n",
      "Epoch 211, Test Accuracy: 47.43%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_211.csv\n",
      "No improvement for 106 epoch(s)\n",
      "Epoch 212, Batch 0, Loss: 301.338, Acc: 53.125%\n",
      "Epoch 212, Batch 100, Loss: 4.271, Acc: 53.860%\n",
      "Epoch 212, Batch 200, Loss: 2.802, Acc: 53.537%\n",
      "Epoch 212, Batch 300, Loss: 2.313, Acc: 53.418%\n",
      "Epoch 212 Training Loss: 2.277, Accuracy: 53.380%\n",
      "Epoch 212, Test Accuracy: 54.59%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_212.csv\n",
      "No improvement for 107 epoch(s)\n",
      "Epoch 213, Batch 0, Loss: 276.113, Acc: 57.031%\n",
      "Epoch 213, Batch 100, Loss: 4.023, Acc: 53.543%\n",
      "Epoch 213, Batch 200, Loss: 2.683, Acc: 53.444%\n",
      "Epoch 213, Batch 300, Loss: 2.223, Acc: 53.626%\n",
      "Epoch 213 Training Loss: 2.188, Accuracy: 53.617%\n",
      "Epoch 213, Test Accuracy: 52.77%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_213.csv\n",
      "No improvement for 108 epoch(s)\n",
      "Epoch 214, Batch 0, Loss: 296.258, Acc: 53.906%\n",
      "Epoch 214, Batch 100, Loss: 4.193, Acc: 54.935%\n",
      "Epoch 214, Batch 200, Loss: 2.773, Acc: 53.945%\n",
      "Epoch 214, Batch 300, Loss: 2.300, Acc: 53.460%\n",
      "Epoch 214 Training Loss: 2.267, Accuracy: 53.432%\n",
      "Epoch 214, Test Accuracy: 54.42%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_214.csv\n",
      "No improvement for 109 epoch(s)\n",
      "Epoch 215, Batch 0, Loss: 291.084, Acc: 54.688%\n",
      "Epoch 215, Batch 100, Loss: 4.163, Acc: 53.728%\n",
      "Epoch 215, Batch 200, Loss: 2.743, Acc: 53.389%\n",
      "Epoch 215, Batch 300, Loss: 2.274, Acc: 53.213%\n",
      "Epoch 215 Training Loss: 2.237, Accuracy: 53.237%\n",
      "Epoch 215, Test Accuracy: 47.44%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_215.csv\n",
      "No improvement for 110 epoch(s)\n",
      "Epoch 216, Batch 0, Loss: 281.450, Acc: 56.250%\n",
      "Epoch 216, Batch 100, Loss: 4.062, Acc: 53.953%\n",
      "Epoch 216, Batch 200, Loss: 2.679, Acc: 54.151%\n",
      "Epoch 216, Batch 300, Loss: 2.236, Acc: 53.545%\n",
      "Epoch 216 Training Loss: 2.202, Accuracy: 53.560%\n",
      "Epoch 216, Test Accuracy: 39.12%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_216.csv\n",
      "No improvement for 111 epoch(s)\n",
      "Epoch 217, Batch 0, Loss: 261.280, Acc: 59.375%\n",
      "Epoch 217, Batch 100, Loss: 3.831, Acc: 55.028%\n",
      "Epoch 217, Batch 200, Loss: 2.573, Acc: 54.260%\n",
      "Epoch 217, Batch 300, Loss: 2.156, Acc: 53.857%\n",
      "Epoch 217 Training Loss: 2.124, Accuracy: 53.852%\n",
      "Epoch 217, Test Accuracy: 53.07%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_217.csv\n",
      "No improvement for 112 epoch(s)\n",
      "Epoch 218, Batch 0, Loss: 261.294, Acc: 59.375%\n",
      "Epoch 218, Batch 100, Loss: 3.864, Acc: 54.045%\n",
      "Epoch 218, Batch 200, Loss: 2.587, Acc: 54.050%\n",
      "Epoch 218, Batch 300, Loss: 2.153, Acc: 54.184%\n",
      "Epoch 218 Training Loss: 2.120, Accuracy: 54.120%\n",
      "Epoch 218, Test Accuracy: 52.38%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_218.csv\n",
      "No improvement for 113 epoch(s)\n",
      "Epoch 219, Batch 0, Loss: 301.236, Acc: 53.125%\n",
      "Epoch 219, Batch 100, Loss: 4.269, Acc: 53.798%\n",
      "Epoch 219, Batch 200, Loss: 2.793, Acc: 53.720%\n",
      "Epoch 219, Batch 300, Loss: 2.295, Acc: 53.898%\n",
      "Epoch 219 Training Loss: 2.255, Accuracy: 53.940%\n",
      "Epoch 219, Test Accuracy: 45.20%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_219.csv\n",
      "No improvement for 114 epoch(s)\n",
      "Epoch 220, Batch 0, Loss: 291.302, Acc: 54.688%\n",
      "Epoch 220, Batch 100, Loss: 4.148, Acc: 54.332%\n",
      "Epoch 220, Batch 200, Loss: 2.721, Acc: 54.241%\n",
      "Epoch 220, Batch 300, Loss: 2.247, Acc: 54.093%\n",
      "Epoch 220 Training Loss: 2.208, Accuracy: 54.165%\n",
      "Epoch 220, Test Accuracy: 49.31%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_220.csv\n",
      "No improvement for 115 epoch(s)\n",
      "Epoch 221, Batch 0, Loss: 296.254, Acc: 53.906%\n",
      "Epoch 221, Batch 100, Loss: 4.188, Acc: 54.432%\n",
      "Epoch 221, Batch 200, Loss: 2.740, Acc: 54.575%\n",
      "Epoch 221, Batch 300, Loss: 2.258, Acc: 54.506%\n",
      "Epoch 221 Training Loss: 2.220, Accuracy: 54.528%\n",
      "Epoch 221, Test Accuracy: 51.15%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_221.csv\n",
      "No improvement for 116 epoch(s)\n",
      "Epoch 222, Batch 0, Loss: 220.921, Acc: 65.625%\n",
      "Epoch 222, Batch 100, Loss: 3.434, Acc: 55.020%\n",
      "Epoch 222, Batch 200, Loss: 2.365, Acc: 54.528%\n",
      "Epoch 222, Batch 300, Loss: 2.006, Acc: 54.568%\n",
      "Epoch 222 Training Loss: 1.978, Accuracy: 54.583%\n",
      "Epoch 222, Test Accuracy: 50.07%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_222.csv\n",
      "No improvement for 117 epoch(s)\n",
      "Epoch 223, Batch 0, Loss: 291.304, Acc: 54.688%\n",
      "Epoch 223, Batch 100, Loss: 4.104, Acc: 55.453%\n",
      "Epoch 223, Batch 200, Loss: 2.693, Acc: 55.018%\n",
      "Epoch 223, Batch 300, Loss: 2.217, Acc: 54.986%\n",
      "Epoch 223 Training Loss: 2.182, Accuracy: 54.930%\n",
      "Epoch 223, Test Accuracy: 49.62%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_223.csv\n",
      "No improvement for 118 epoch(s)\n",
      "Epoch 224, Batch 0, Loss: 281.245, Acc: 56.250%\n",
      "Epoch 224, Batch 100, Loss: 4.007, Acc: 55.662%\n",
      "Epoch 224, Batch 200, Loss: 2.639, Acc: 55.263%\n",
      "Epoch 224, Batch 300, Loss: 2.185, Acc: 55.178%\n",
      "Epoch 224 Training Loss: 2.148, Accuracy: 55.200%\n",
      "Epoch 224, Test Accuracy: 53.47%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_224.csv\n",
      "No improvement for 119 epoch(s)\n",
      "Epoch 225, Batch 0, Loss: 266.068, Acc: 58.594%\n",
      "Epoch 225, Batch 100, Loss: 3.847, Acc: 56.095%\n",
      "Epoch 225, Batch 200, Loss: 2.566, Acc: 55.399%\n",
      "Epoch 225, Batch 300, Loss: 2.142, Acc: 54.999%\n",
      "Epoch 225 Training Loss: 2.110, Accuracy: 54.898%\n",
      "Epoch 225, Test Accuracy: 50.58%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_225.csv\n",
      "No improvement for 120 epoch(s)\n",
      "Epoch 226, Batch 0, Loss: 271.034, Acc: 57.812%\n",
      "Epoch 226, Batch 100, Loss: 3.896, Acc: 55.430%\n",
      "Epoch 226, Batch 200, Loss: 2.593, Acc: 55.030%\n",
      "Epoch 226, Batch 300, Loss: 2.148, Acc: 55.129%\n",
      "Epoch 226 Training Loss: 2.115, Accuracy: 55.130%\n",
      "Epoch 226, Test Accuracy: 53.74%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_226.csv\n",
      "No improvement for 121 epoch(s)\n",
      "Epoch 227, Batch 0, Loss: 291.270, Acc: 54.688%\n",
      "Epoch 227, Batch 100, Loss: 4.109, Acc: 55.724%\n",
      "Epoch 227, Batch 200, Loss: 2.676, Acc: 55.469%\n",
      "Epoch 227, Batch 300, Loss: 2.204, Acc: 55.323%\n",
      "Epoch 227 Training Loss: 2.168, Accuracy: 55.310%\n",
      "Epoch 227, Test Accuracy: 55.20%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_227.csv\n",
      "No improvement for 122 epoch(s)\n",
      "Epoch 228, Batch 0, Loss: 261.139, Acc: 59.375%\n",
      "Epoch 228, Batch 100, Loss: 3.786, Acc: 55.917%\n",
      "Epoch 228, Batch 200, Loss: 2.523, Acc: 55.683%\n",
      "Epoch 228, Batch 300, Loss: 2.104, Acc: 55.303%\n",
      "Epoch 228 Training Loss: 2.070, Accuracy: 55.258%\n",
      "Epoch 228, Test Accuracy: 50.19%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_228.csv\n",
      "No improvement for 123 epoch(s)\n",
      "Epoch 229, Batch 0, Loss: 1.316, Acc: 49.219%\n",
      "Epoch 229, Batch 100, Loss: 1.206, Acc: 56.320%\n",
      "Epoch 229, Batch 200, Loss: 1.215, Acc: 55.900%\n",
      "Epoch 229, Batch 300, Loss: 1.226, Acc: 55.791%\n",
      "Epoch 229 Training Loss: 1.227, Accuracy: 55.758%\n",
      "Epoch 229, Test Accuracy: 53.75%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_229.csv\n",
      "No improvement for 124 epoch(s)\n",
      "Epoch 230, Batch 0, Loss: 235.901, Acc: 63.281%\n",
      "Epoch 230, Batch 100, Loss: 3.528, Acc: 56.621%\n",
      "Epoch 230, Batch 200, Loss: 2.378, Acc: 56.405%\n",
      "Epoch 230, Batch 300, Loss: 1.994, Acc: 56.247%\n",
      "Epoch 230 Training Loss: 1.969, Accuracy: 56.240%\n",
      "Epoch 230, Test Accuracy: 53.98%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_230.csv\n",
      "No improvement for 125 epoch(s)\n",
      "Epoch 231, Batch 0, Loss: 216.078, Acc: 66.406%\n",
      "Epoch 231, Batch 100, Loss: 3.348, Acc: 55.956%\n",
      "Epoch 231, Batch 200, Loss: 2.288, Acc: 55.752%\n",
      "Epoch 231, Batch 300, Loss: 1.927, Acc: 56.074%\n",
      "Epoch 231 Training Loss: 1.903, Accuracy: 56.065%\n",
      "Epoch 231, Test Accuracy: 47.55%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_231.csv\n",
      "No improvement for 126 epoch(s)\n",
      "Epoch 232, Batch 0, Loss: 251.206, Acc: 60.938%\n",
      "Epoch 232, Batch 100, Loss: 3.648, Acc: 57.379%\n",
      "Epoch 232, Batch 200, Loss: 2.425, Acc: 57.276%\n",
      "Epoch 232, Batch 300, Loss: 2.028, Acc: 56.883%\n",
      "Epoch 232 Training Loss: 2.000, Accuracy: 56.840%\n",
      "Epoch 232, Test Accuracy: 54.05%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_232.csv\n",
      "No improvement for 127 epoch(s)\n",
      "Epoch 233, Batch 0, Loss: 1.278, Acc: 46.875%\n",
      "Epoch 233, Batch 100, Loss: 1.160, Acc: 56.807%\n",
      "Epoch 233, Batch 200, Loss: 1.187, Acc: 56.580%\n",
      "Epoch 233, Batch 300, Loss: 1.186, Acc: 56.751%\n",
      "Epoch 233 Training Loss: 1.189, Accuracy: 56.715%\n",
      "Epoch 233, Test Accuracy: 54.17%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_233.csv\n",
      "No improvement for 128 epoch(s)\n",
      "Epoch 234, Batch 0, Loss: 286.279, Acc: 55.469%\n",
      "Epoch 234, Batch 100, Loss: 3.986, Acc: 57.302%\n",
      "Epoch 234, Batch 200, Loss: 2.586, Acc: 57.319%\n",
      "Epoch 234, Batch 300, Loss: 2.121, Acc: 57.197%\n",
      "Epoch 234 Training Loss: 2.085, Accuracy: 57.218%\n",
      "Epoch 234, Test Accuracy: 50.58%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_234.csv\n",
      "No improvement for 129 epoch(s)\n",
      "Epoch 235, Batch 0, Loss: 296.174, Acc: 53.906%\n",
      "Epoch 235, Batch 100, Loss: 4.071, Acc: 57.372%\n",
      "Epoch 235, Batch 200, Loss: 2.625, Acc: 57.416%\n",
      "Epoch 235, Batch 300, Loss: 2.145, Acc: 57.301%\n",
      "Epoch 235 Training Loss: 2.110, Accuracy: 57.252%\n",
      "Epoch 235, Test Accuracy: 55.42%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_235.csv\n",
      "No improvement for 130 epoch(s)\n",
      "Epoch 236, Batch 0, Loss: 215.963, Acc: 66.406%\n",
      "Epoch 236, Batch 100, Loss: 3.264, Acc: 58.130%\n",
      "Epoch 236, Batch 200, Loss: 2.229, Acc: 57.906%\n",
      "Epoch 236, Batch 300, Loss: 1.878, Acc: 57.607%\n",
      "Epoch 236 Training Loss: 1.851, Accuracy: 57.617%\n",
      "Epoch 236, Test Accuracy: 53.59%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_236.csv\n",
      "No improvement for 131 epoch(s)\n",
      "Epoch 237, Batch 0, Loss: 271.113, Acc: 57.812%\n",
      "Epoch 237, Batch 100, Loss: 3.791, Acc: 58.903%\n",
      "Epoch 237, Batch 200, Loss: 2.477, Acc: 58.178%\n",
      "Epoch 237, Batch 300, Loss: 2.046, Acc: 57.662%\n",
      "Epoch 237 Training Loss: 2.010, Accuracy: 57.708%\n",
      "Epoch 237, Test Accuracy: 56.78%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_237.csv\n",
      "No improvement for 132 epoch(s)\n",
      "Epoch 238, Batch 0, Loss: 270.920, Acc: 57.812%\n",
      "Epoch 238, Batch 100, Loss: 3.784, Acc: 58.810%\n",
      "Epoch 238, Batch 200, Loss: 2.462, Acc: 58.446%\n",
      "Epoch 238, Batch 300, Loss: 2.033, Acc: 57.986%\n",
      "Epoch 238 Training Loss: 2.000, Accuracy: 57.935%\n",
      "Epoch 238, Test Accuracy: 53.90%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_238.csv\n",
      "No improvement for 133 epoch(s)\n",
      "Epoch 239, Batch 0, Loss: 301.287, Acc: 53.125%\n",
      "Epoch 239, Batch 100, Loss: 4.079, Acc: 59.390%\n",
      "Epoch 239, Batch 200, Loss: 2.619, Acc: 58.329%\n",
      "Epoch 239, Batch 300, Loss: 2.133, Acc: 58.075%\n",
      "Epoch 239 Training Loss: 2.095, Accuracy: 58.085%\n",
      "Epoch 239, Test Accuracy: 55.69%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_239.csv\n",
      "No improvement for 134 epoch(s)\n",
      "Epoch 240, Batch 0, Loss: 225.864, Acc: 64.844%\n",
      "Epoch 240, Batch 100, Loss: 3.301, Acc: 59.421%\n",
      "Epoch 240, Batch 200, Loss: 2.226, Acc: 58.784%\n",
      "Epoch 240, Batch 300, Loss: 1.862, Acc: 58.607%\n",
      "Epoch 240 Training Loss: 1.835, Accuracy: 58.623%\n",
      "Epoch 240, Test Accuracy: 55.99%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_240.csv\n",
      "No improvement for 135 epoch(s)\n",
      "Epoch 241, Batch 0, Loss: 290.993, Acc: 54.688%\n",
      "Epoch 241, Batch 100, Loss: 3.951, Acc: 59.259%\n",
      "Epoch 241, Batch 200, Loss: 2.538, Acc: 58.843%\n",
      "Epoch 241, Batch 300, Loss: 2.062, Acc: 58.866%\n",
      "Epoch 241 Training Loss: 2.027, Accuracy: 58.852%\n",
      "Epoch 241, Test Accuracy: 56.95%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_241.csv\n",
      "No improvement for 136 epoch(s)\n",
      "Epoch 242, Batch 0, Loss: 301.124, Acc: 53.125%\n",
      "Epoch 242, Batch 100, Loss: 4.034, Acc: 59.839%\n",
      "Epoch 242, Batch 200, Loss: 2.565, Acc: 59.756%\n",
      "Epoch 242, Batch 300, Loss: 2.087, Acc: 59.240%\n",
      "Epoch 242 Training Loss: 2.050, Accuracy: 59.227%\n",
      "Epoch 242, Test Accuracy: 54.91%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_242.csv\n",
      "No improvement for 137 epoch(s)\n",
      "Epoch 243, Batch 0, Loss: 291.154, Acc: 54.688%\n",
      "Epoch 243, Batch 100, Loss: 3.946, Acc: 59.816%\n",
      "Epoch 243, Batch 200, Loss: 2.515, Acc: 59.682%\n",
      "Epoch 243, Batch 300, Loss: 2.043, Acc: 59.333%\n",
      "Epoch 243 Training Loss: 2.010, Accuracy: 59.290%\n",
      "Epoch 243, Test Accuracy: 50.98%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_243.csv\n",
      "No improvement for 138 epoch(s)\n",
      "Epoch 244, Batch 0, Loss: 230.907, Acc: 64.062%\n",
      "Epoch 244, Batch 100, Loss: 3.305, Acc: 60.620%\n",
      "Epoch 244, Batch 200, Loss: 2.203, Acc: 59.896%\n",
      "Epoch 244, Batch 300, Loss: 1.832, Acc: 59.692%\n",
      "Epoch 244 Training Loss: 1.805, Accuracy: 59.693%\n",
      "Epoch 244, Test Accuracy: 55.37%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_244.csv\n",
      "No improvement for 139 epoch(s)\n",
      "Epoch 245, Batch 0, Loss: 256.049, Acc: 60.156%\n",
      "Epoch 245, Batch 100, Loss: 3.550, Acc: 60.791%\n",
      "Epoch 245, Batch 200, Loss: 2.315, Acc: 60.304%\n",
      "Epoch 245, Batch 300, Loss: 1.903, Acc: 60.016%\n",
      "Epoch 245 Training Loss: 1.871, Accuracy: 59.928%\n",
      "Epoch 245, Test Accuracy: 58.34%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_245.csv\n",
      "No improvement for 140 epoch(s)\n",
      "Epoch 246, Batch 0, Loss: 276.248, Acc: 57.031%\n",
      "Epoch 246, Batch 100, Loss: 3.732, Acc: 61.309%\n",
      "Epoch 246, Batch 200, Loss: 2.396, Acc: 60.759%\n",
      "Epoch 246, Batch 300, Loss: 1.948, Acc: 60.808%\n",
      "Epoch 246 Training Loss: 1.914, Accuracy: 60.693%\n",
      "Epoch 246, Test Accuracy: 59.60%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_246.csv\n",
      "No improvement for 141 epoch(s)\n",
      "Epoch 247, Batch 0, Loss: 230.893, Acc: 64.062%\n",
      "Epoch 247, Batch 100, Loss: 3.279, Acc: 61.665%\n",
      "Epoch 247, Batch 200, Loss: 2.146, Acc: 61.404%\n",
      "Epoch 247, Batch 300, Loss: 1.779, Acc: 61.194%\n",
      "Epoch 247 Training Loss: 1.751, Accuracy: 61.163%\n",
      "Epoch 247, Test Accuracy: 59.77%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_247.csv\n",
      "No improvement for 142 epoch(s)\n",
      "Epoch 248, Batch 0, Loss: 235.985, Acc: 63.281%\n",
      "Epoch 248, Batch 100, Loss: 3.320, Acc: 61.641%\n",
      "Epoch 248, Batch 200, Loss: 2.185, Acc: 60.992%\n",
      "Epoch 248, Batch 300, Loss: 1.798, Acc: 60.940%\n",
      "Epoch 248 Training Loss: 1.765, Accuracy: 60.992%\n",
      "Epoch 248, Test Accuracy: 54.70%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_248.csv\n",
      "No improvement for 143 epoch(s)\n",
      "Epoch 249, Batch 0, Loss: 215.895, Acc: 66.406%\n",
      "Epoch 249, Batch 100, Loss: 3.098, Acc: 62.562%\n",
      "Epoch 249, Batch 200, Loss: 2.074, Acc: 61.443%\n",
      "Epoch 249, Batch 300, Loss: 1.727, Acc: 61.262%\n",
      "Epoch 249 Training Loss: 1.701, Accuracy: 61.285%\n",
      "Epoch 249, Test Accuracy: 59.24%\n",
      "Predictions and probabilities saved to predictions_and_probabilities_epoch_249.csv\n",
      "No improvement for 144 epoch(s)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Early stopping parameters\n",
    "early_stopping_patience = 150  # Number of epochs with no improvement to stop training\n",
    "best_test_accuracy = 0.0  # Best test accuracy seen so far\n",
    "epochs_no_improvement = 0  # Counter for how many epochs with no improvement\n",
    "\n",
    "# Data Augmentation for Training Set\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),             # Random cropping with padding\n",
    "    transforms.RandomHorizontalFlip(),                # Random horizontal flip\n",
    "    transforms.RandomRotation(15),                    # Randomly rotate by 15 degrees\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Random jitter in brightness, contrast, etc.\n",
    "    transforms.ToTensor(),                            # Convert images to tensors\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize the images\n",
    "])\n",
    "\n",
    "# Data Transformations for the Test Set (no augmentation)\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),                            # Convert images to tensors\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize the images\n",
    "])\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "class CIFAR100Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, file_path, transform=None):\n",
    "        with open(file_path, 'rb') as f:\n",
    "            self.data = pickle.load(f)\n",
    "        self.transform = transform  # Add transform argument\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, label = self.data[idx]\n",
    "        \n",
    "        # Convert the tensor to a PIL image before applying transforms\n",
    "        if isinstance(image, torch.Tensor):\n",
    "            image = image.permute(1, 2, 0).numpy()  # Convert torch tensor to numpy array (H, W, C)\n",
    "            image = Image.fromarray((image * 255).astype('uint8'))  # Convert numpy array to PIL Image\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)  # Apply the transform\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "\n",
    "\n",
    "# Load train and test datasets with the new augmentations for the training set\n",
    "train_dataset = CIFAR100Dataset('train.pkl', transform=transform_train)\n",
    "test_dataset = CIFAR100Dataset('test.pkl', transform=transform_test)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "# Set paths and other parameters\n",
    "PENALTY_WEIGHT = 5 # Weight for penalizing incorrect predictions after 50% accuracy\n",
    "SAVE_PATH = './saved_models/'  # Directory to save model checkpoints\n",
    "if not os.path.exists(SAVE_PATH):\n",
    "    os.makedirs(SAVE_PATH)\n",
    "\n",
    "# Temperature Scaling class\n",
    "class TemperatureScaling(nn.Module):\n",
    "    def __init__(self, init_temp=1.0):\n",
    "        super(TemperatureScaling, self).__init__()\n",
    "        self.temperature = nn.Parameter(torch.ones(1) * init_temp)\n",
    "\n",
    "    def forward(self, logits):\n",
    "        return logits / self.temperature\n",
    "\n",
    "# Focal Loss for handling imbalanced datasets\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, outputs, targets):\n",
    "        BCE_loss = F.cross_entropy(outputs, targets, reduction='none')\n",
    "        pt = torch.exp(-BCE_loss)  # Get the probability\n",
    "        focal_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n",
    "        return focal_loss.mean()\n",
    "\n",
    "# Custom Loss Function with Focal Loss and Penalty for Wrong Predictions after 50% Accuracy\n",
    "def custom_loss_function(outputs, targets, current_accuracy):\n",
    "    # Apply softmax to get probabilities\n",
    "    probabilities = F.softmax(outputs, dim=1)\n",
    "    \n",
    "    # Get the max probability (confidence) and corresponding predicted class\n",
    "    confidences, predicted_classes = torch.max(probabilities, dim=1)\n",
    "    \n",
    "    # Calculate the Focal Loss for class imbalance\n",
    "    focal_loss = FocalLoss()(outputs, targets)\n",
    "    \n",
    "    # Heavily penalize wrong argmax predictions if training accuracy > 50%\n",
    "    wrong_predictions = (predicted_classes != targets).float()\n",
    "    if current_accuracy > 0.5:\n",
    "        wrong_prediction_penalty = PENALTY_WEIGHT * wrong_predictions.sum()\n",
    "    else:\n",
    "        wrong_prediction_penalty = 0\n",
    "\n",
    "    # Calculate the total loss\n",
    "    total_loss = focal_loss + wrong_prediction_penalty\n",
    "    return total_loss\n",
    "\n",
    "# WideResNeXt Block\n",
    "class WideResNeXtBlock(nn.Module):\n",
    "    expansion = 2  # Expansion factor for WideResNeXt\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1, cardinality=32, widen_factor=2):\n",
    "        super(WideResNeXtBlock, self).__init__()\n",
    "        D = cardinality * widen_factor\n",
    "        self.conv1 = nn.Conv2d(in_planes, D, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(D)\n",
    "        self.conv2 = nn.Conv2d(D, D, kernel_size=3, stride=stride, padding=1, groups=cardinality, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(D)\n",
    "        self.conv3 = nn.Conv2d(D, planes * WideResNeXtBlock.expansion, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * WideResNeXtBlock.expansion)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != planes * WideResNeXtBlock.expansion:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, planes * WideResNeXtBlock.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * WideResNeXtBlock.expansion)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.relu(self.bn1(self.conv1(x)))\n",
    "        out = torch.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = torch.relu(out)\n",
    "        return out\n",
    "\n",
    "# WideResNeXt Model with Temperature Scaling\n",
    "class WideResNeXt(nn.Module):\n",
    "    def __init__(self, block, num_blocks, cardinality=32, widen_factor=2, num_classes=100):\n",
    "        super(WideResNeXt, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1, cardinality=cardinality, widen_factor=widen_factor)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2, cardinality=cardinality, widen_factor=widen_factor)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2, cardinality=cardinality, widen_factor=widen_factor)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2, cardinality=cardinality, widen_factor=widen_factor)\n",
    "\n",
    "        self.dropout = nn.Dropout(p=0.5)  # Add Dropout layer with 0.5 probability\n",
    "        self.linear = nn.Linear(512 * WideResNeXtBlock.expansion, num_classes)\n",
    "        self.temperature_scaling = TemperatureScaling()  # Temperature scaling layer\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride, cardinality, widen_factor):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride, cardinality, widen_factor))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = torch.nn.functional.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.dropout(out)  # Apply Dropout before the final linear layer\n",
    "        out = self.linear(out)\n",
    "        out = self.temperature_scaling(out)  # Apply temperature scaling before softmax\n",
    "        return out\n",
    "\n",
    "def train_with_penalty(epoch):\n",
    "    model.train()  # Set the model to training mode\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()  # Zero the gradients for the optimizer\n",
    "        \n",
    "        outputs = model(inputs)  # Forward pass\n",
    "        \n",
    "        # Calculate the overall training accuracy before updating weights\n",
    "        probabilities = F.softmax(outputs, dim=1)\n",
    "        _, predicted_classes = torch.max(probabilities, dim=1)\n",
    "        \n",
    "        correct_predictions = predicted_classes.eq(targets).sum().item()\n",
    "        total += targets.size(0)\n",
    "        current_accuracy = correct_predictions / total\n",
    "        \n",
    "        # Calculate the custom loss with penalties if training accuracy > 50%\n",
    "        loss = custom_loss_function(outputs, targets, current_accuracy)\n",
    "        loss.backward()  # Backpropagation\n",
    "        optimizer.step()  # Update weights\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        correct += correct_predictions\n",
    "\n",
    "        if batch_idx % 100 == 0:  # Print every 100 batches\n",
    "            print(f'Epoch {epoch}, Batch {batch_idx}, Loss: {train_loss / (batch_idx + 1):.3f}, Acc: {100.*correct/total:.3f}%')\n",
    "\n",
    "    # At the end of the epoch, print the final training accuracy\n",
    "    print(f'Epoch {epoch} Training Loss: {train_loss / len(trainloader):.3f}, Accuracy: {100.*correct/total:.3f}%')\n",
    "\n",
    "import csv\n",
    "\n",
    "# Function to calculate accuracy based on True_label data in test_info.csv and save predictions and probabilities\n",
    "def test_accuracy(epoch, test_info_path):\n",
    "    global best_test_accuracy, epochs_no_improvement\n",
    "    model.eval()\n",
    "    correct_all = 0\n",
    "    total_all = 0\n",
    "\n",
    "    # Load True_label from test_info.csv\n",
    "    test_info = pd.read_csv(test_info_path)\n",
    "    true_labels = test_info['True_label'].values\n",
    "    ids = test_info['ID'].values  # Assuming the test_info.csv also contains 'ID' column\n",
    "\n",
    "    predictions = []  # Store predictions\n",
    "    probabilities_list = []  # Store probabilities for each sample\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            probabilities = F.softmax(outputs, dim=1)  # Get probabilities for each class\n",
    "            _, predicted_classes = torch.max(probabilities, dim=1)  # Get predicted class\n",
    "\n",
    "            # Store predictions and probabilities\n",
    "            predictions.extend(predicted_classes.cpu().numpy())\n",
    "            probabilities_list.extend(probabilities.cpu().numpy())  # Save softmax probabilities for each sample\n",
    "\n",
    "    # Calculate accuracy based on True_label\n",
    "    correct_all = (predictions == true_labels).sum()\n",
    "    total_all = len(true_labels)\n",
    "\n",
    "    # Print accuracy\n",
    "    test_accuracy = 100. * correct_all / total_all\n",
    "    print(f\"Epoch {epoch}, Test Accuracy: {test_accuracy:.2f}%\")\n",
    "\n",
    "    # Save predictions and probabilities to CSV after epoch 70\n",
    "    if epoch >= 70:\n",
    "        save_predictions_and_probabilities_to_csv(ids, predictions, probabilities_list, epoch)\n",
    "\n",
    "    # Check for improvement and early stopping condition\n",
    "    if test_accuracy > best_test_accuracy:\n",
    "        best_test_accuracy = test_accuracy\n",
    "        epochs_no_improvement = 0  # Reset the counter when improvement is seen\n",
    "        # Optionally save the model\n",
    "        save_model_checkpoint(epoch)\n",
    "    else:\n",
    "        epochs_no_improvement += 1  # No improvement\n",
    "        print(f'No improvement for {epochs_no_improvement} epoch(s)')\n",
    "    \n",
    "    # Stop if no improvement for 10 epochs\n",
    "    if epochs_no_improvement >= early_stopping_patience:\n",
    "        print(f\"Early stopping at epoch {epoch} due to no improvement for {early_stopping_patience} epochs.\")\n",
    "        return True  # Signal to stop training\n",
    "    return False\n",
    "\n",
    "def save_predictions_and_probabilities_to_csv(ids, predictions, probabilities, epoch):\n",
    "    \"\"\"\n",
    "    Save the predictions and probabilities to a CSV file.\n",
    "    The CSV will contain the following columns: ID, Predicted_label, and probabilities for each class (Prob_Class0, Prob_Class1, ..., Prob_Class99).\n",
    "    \"\"\"\n",
    "    probabilities_df = pd.DataFrame(probabilities, columns=[f'Prob_Class{i}' for i in range(100)])\n",
    "    predictions_df = pd.DataFrame({'ID': ids, 'Predicted_label': predictions})\n",
    "    \n",
    "    # Combine the predictions and probabilities into a single DataFrame\n",
    "    df = pd.concat([predictions_df, probabilities_df], axis=1)\n",
    "    \n",
    "    # Save to CSV with the epoch number in the filename\n",
    "    csv_filename = f'predictions_and_probabilities_epoch_{epoch}.csv'\n",
    "    df.to_csv(csv_filename, index=False)\n",
    "    print(f\"Predictions and probabilities saved to {csv_filename}\")\n",
    "\n",
    "\n",
    "def save_model_checkpoint(epoch):\n",
    "    save_path = os.path.join(SAVE_PATH, f'best_model_{str(epoch)}.pth')\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    print(f\"New best model saved with accuracy: {best_test_accuracy:.2f}%\")\n",
    "\n",
    "# Model, loss, optimizer, and scheduler\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = WideResNeXt(WideResNeXtBlock, [3, 4, 6, 3], cardinality=32, widen_factor=2).to(device)\n",
    "\n",
    "# Example optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = get_scheduler(optimizer, 'cosine')\n",
    "# Define CyclicLR scheduler (to be used for the first 70 epochs)\n",
    "cyclic_scheduler = torch.optim.lr_scheduler.CyclicLR(\n",
    "    optimizer,\n",
    "    base_lr=0.001,\n",
    "    max_lr=0.1,\n",
    "    step_size_up=20\n",
    ")\n",
    "\n",
    "# Define StepLR scheduler (to be used after epoch 70)\n",
    "step_scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "    optimizer,\n",
    "    step_size=30,  # Decay every 30 epochs\n",
    "    gamma=0.1  # Reduce learning rate by a factor of 0.1\n",
    ")\n",
    "\n",
    "# Training loop with scheduler switching\n",
    "for epoch in range(0, 250):\n",
    "    train_with_penalty(epoch)  # Perform training for this epoch\n",
    "    stop_training = test_accuracy(epoch, 'test_info.csv')  # Evaluate test accuracy\n",
    "\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    if stop_training:\n",
    "        break  # Stop the training loop if early stopping is triggered\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5820167,
     "sourceId": 9673417,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 11508.168839,
   "end_time": "2024-10-21T20:27:45.391155",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-10-21T17:15:57.222316",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
