{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c650b4c",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-10-18T07:05:25.187113Z",
     "iopub.status.busy": "2024-10-18T07:05:25.186566Z",
     "iopub.status.idle": "2024-10-18T10:38:07.751844Z",
     "shell.execute_reply": "2024-10-18T10:38:07.750730Z"
    },
    "papermill": {
     "duration": 12762.571589,
     "end_time": "2024-10-18T10:38:07.754092",
     "exception": false,
     "start_time": "2024-10-18T07:05:25.182503",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data/cifar-100-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 169001437/169001437 [00:02<00:00, 68182663.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-100-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n",
      "Epoch [1/151], Loss: 4.3830, Accuracy: 3.46%\n",
      "Epoch [2/151], Loss: 3.8521, Accuracy: 9.24%\n",
      "Epoch [3/151], Loss: 3.4939, Accuracy: 15.55%\n",
      "Epoch [4/151], Loss: 3.1445, Accuracy: 22.19%\n",
      "Epoch [5/151], Loss: 2.8039, Accuracy: 28.81%\n",
      "Epoch [6/151], Loss: 2.5164, Accuracy: 34.45%\n",
      "Epoch [7/151], Loss: 2.2642, Accuracy: 39.84%\n",
      "Epoch [8/151], Loss: 2.0703, Accuracy: 44.03%\n",
      "Epoch [9/151], Loss: 1.9051, Accuracy: 47.78%\n",
      "Epoch [10/151], Loss: 1.7600, Accuracy: 51.04%\n",
      "Epoch [11/151], Loss: 1.6495, Accuracy: 53.82%\n",
      "Epoch [12/151], Loss: 1.5441, Accuracy: 56.25%\n",
      "Epoch [13/151], Loss: 1.4503, Accuracy: 58.60%\n",
      "Epoch [14/151], Loss: 1.3709, Accuracy: 60.71%\n",
      "Epoch [15/151], Loss: 1.2876, Accuracy: 62.97%\n",
      "Epoch [16/151], Loss: 1.1948, Accuracy: 65.11%\n",
      "Epoch [17/151], Loss: 1.1291, Accuracy: 66.70%\n",
      "Epoch [18/151], Loss: 1.0725, Accuracy: 68.15%\n",
      "Epoch [19/151], Loss: 1.0234, Accuracy: 69.36%\n",
      "Epoch [20/151], Loss: 0.9628, Accuracy: 71.10%\n",
      "Epoch [21/151], Loss: 0.9009, Accuracy: 72.93%\n",
      "Epoch [22/151], Loss: 0.8497, Accuracy: 74.20%\n",
      "Epoch [23/151], Loss: 0.8229, Accuracy: 74.68%\n",
      "Epoch [24/151], Loss: 0.7467, Accuracy: 76.81%\n",
      "Epoch [25/151], Loss: 0.7124, Accuracy: 77.86%\n",
      "Epoch [26/151], Loss: 0.6736, Accuracy: 78.65%\n",
      "Epoch [27/151], Loss: 0.6355, Accuracy: 79.79%\n",
      "Epoch [28/151], Loss: 0.6074, Accuracy: 80.71%\n",
      "Epoch [29/151], Loss: 0.5638, Accuracy: 82.10%\n",
      "Epoch [30/151], Loss: 0.5445, Accuracy: 82.44%\n",
      "Epoch [31/151], Loss: 0.5197, Accuracy: 83.24%\n",
      "Epoch [32/151], Loss: 0.4862, Accuracy: 84.30%\n",
      "Epoch [33/151], Loss: 0.4631, Accuracy: 84.92%\n",
      "Epoch [34/151], Loss: 0.4517, Accuracy: 85.33%\n",
      "Epoch [35/151], Loss: 0.4230, Accuracy: 86.17%\n",
      "Epoch [36/151], Loss: 0.3948, Accuracy: 87.08%\n",
      "Epoch [37/151], Loss: 0.3784, Accuracy: 87.73%\n",
      "Epoch [38/151], Loss: 0.3515, Accuracy: 88.48%\n",
      "Epoch [39/151], Loss: 0.3416, Accuracy: 88.78%\n",
      "Epoch [40/151], Loss: 0.3284, Accuracy: 89.03%\n",
      "Epoch [41/151], Loss: 0.3155, Accuracy: 89.48%\n",
      "Epoch [42/151], Loss: 0.3106, Accuracy: 89.78%\n",
      "Epoch [43/151], Loss: 0.2974, Accuracy: 90.10%\n",
      "Epoch [44/151], Loss: 0.2774, Accuracy: 90.74%\n",
      "Epoch [45/151], Loss: 0.2712, Accuracy: 91.05%\n",
      "Epoch [46/151], Loss: 0.2755, Accuracy: 90.80%\n",
      "Epoch [47/151], Loss: 0.2589, Accuracy: 91.42%\n",
      "Epoch [48/151], Loss: 0.2664, Accuracy: 91.12%\n",
      "Epoch [49/151], Loss: 0.2472, Accuracy: 91.76%\n",
      "Epoch [50/151], Loss: 0.2586, Accuracy: 91.44%\n",
      "Epoch [51/151], Loss: 0.2469, Accuracy: 91.85%\n",
      "Epoch [52/151], Loss: 0.2052, Accuracy: 93.16%\n",
      "Epoch [53/151], Loss: 0.2054, Accuracy: 93.16%\n",
      "Epoch [54/151], Loss: 0.2124, Accuracy: 93.02%\n",
      "Epoch [55/151], Loss: 0.1964, Accuracy: 93.41%\n",
      "Epoch [56/151], Loss: 0.1937, Accuracy: 93.48%\n",
      "Epoch [57/151], Loss: 0.2013, Accuracy: 93.36%\n",
      "Epoch [58/151], Loss: 0.2005, Accuracy: 93.45%\n",
      "Epoch [59/151], Loss: 0.1762, Accuracy: 94.09%\n",
      "Epoch [60/151], Loss: 0.1850, Accuracy: 93.93%\n",
      "Epoch [61/151], Loss: 0.1814, Accuracy: 93.99%\n",
      "Epoch [62/151], Loss: 0.1777, Accuracy: 94.21%\n",
      "Epoch [63/151], Loss: 0.1892, Accuracy: 93.65%\n",
      "Epoch [64/151], Loss: 0.1865, Accuracy: 93.91%\n",
      "Epoch [65/151], Loss: 0.1582, Accuracy: 94.69%\n",
      "Epoch [66/151], Loss: 0.1518, Accuracy: 94.97%\n",
      "Epoch [67/151], Loss: 0.1529, Accuracy: 94.93%\n",
      "Epoch [68/151], Loss: 0.1624, Accuracy: 94.68%\n",
      "Epoch [69/151], Loss: 0.1529, Accuracy: 94.92%\n",
      "Epoch [70/151], Loss: 0.1426, Accuracy: 95.27%\n",
      "Epoch [71/151], Loss: 0.1560, Accuracy: 94.89%\n",
      "Epoch [72/151], Loss: 0.1535, Accuracy: 94.94%\n",
      "Epoch [73/151], Loss: 0.1567, Accuracy: 94.89%\n",
      "Epoch [74/151], Loss: 0.1306, Accuracy: 95.70%\n",
      "Epoch [75/151], Loss: 0.1484, Accuracy: 95.13%\n",
      "Epoch [76/151], Loss: 0.1289, Accuracy: 95.64%\n",
      "Epoch [77/151], Loss: 0.1311, Accuracy: 95.69%\n",
      "Epoch [78/151], Loss: 0.1325, Accuracy: 95.71%\n",
      "Epoch [79/151], Loss: 0.1343, Accuracy: 95.65%\n",
      "Epoch [80/151], Loss: 0.1303, Accuracy: 95.71%\n",
      "Epoch [81/151], Loss: 0.1275, Accuracy: 95.82%\n",
      "Epoch [82/151], Loss: 0.1372, Accuracy: 95.50%\n",
      "Epoch [83/151], Loss: 0.1171, Accuracy: 96.14%\n",
      "Epoch [84/151], Loss: 0.1190, Accuracy: 96.13%\n",
      "Epoch [85/151], Loss: 0.1275, Accuracy: 95.80%\n",
      "Epoch [86/151], Loss: 0.1153, Accuracy: 96.31%\n",
      "Epoch [87/151], Loss: 0.1186, Accuracy: 96.18%\n",
      "Epoch [88/151], Loss: 0.1198, Accuracy: 96.12%\n",
      "Epoch [89/151], Loss: 0.1095, Accuracy: 96.49%\n",
      "Epoch [90/151], Loss: 0.1169, Accuracy: 96.07%\n",
      "Epoch [91/151], Loss: 0.1086, Accuracy: 96.43%\n",
      "Epoch [92/151], Loss: 0.1147, Accuracy: 96.25%\n",
      "Epoch [93/151], Loss: 0.1135, Accuracy: 96.30%\n",
      "Epoch [94/151], Loss: 0.1079, Accuracy: 96.42%\n",
      "Epoch [95/151], Loss: 0.1058, Accuracy: 96.51%\n",
      "Epoch [96/151], Loss: 0.1101, Accuracy: 96.39%\n",
      "Epoch [97/151], Loss: 0.1123, Accuracy: 96.35%\n",
      "Epoch [98/151], Loss: 0.1031, Accuracy: 96.68%\n",
      "Epoch [99/151], Loss: 0.0924, Accuracy: 96.96%\n",
      "Epoch [100/151], Loss: 0.1001, Accuracy: 96.74%\n",
      "Epoch [101/151], Loss: 0.1106, Accuracy: 96.45%\n",
      "Epoch [102/151], Loss: 0.0960, Accuracy: 96.85%\n",
      "Epoch [103/151], Loss: 0.0968, Accuracy: 96.79%\n",
      "Epoch [104/151], Loss: 0.1065, Accuracy: 96.37%\n",
      "Epoch [105/151], Loss: 0.1023, Accuracy: 96.70%\n",
      "Epoch [106/151], Loss: 0.0901, Accuracy: 97.09%\n",
      "Epoch [107/151], Loss: 0.0940, Accuracy: 96.91%\n",
      "Epoch [108/151], Loss: 0.1019, Accuracy: 96.71%\n",
      "Epoch [109/151], Loss: 0.0919, Accuracy: 96.97%\n",
      "Epoch [110/151], Loss: 0.0894, Accuracy: 97.08%\n",
      "Epoch [111/151], Loss: 0.0938, Accuracy: 97.04%\n",
      "Epoch [112/151], Loss: 0.0839, Accuracy: 97.26%\n",
      "Epoch [113/151], Loss: 0.0934, Accuracy: 96.95%\n",
      "Epoch [114/151], Loss: 0.0865, Accuracy: 97.23%\n",
      "Epoch [115/151], Loss: 0.0849, Accuracy: 97.29%\n",
      "Epoch [116/151], Loss: 0.0923, Accuracy: 97.06%\n",
      "Epoch [117/151], Loss: 0.0794, Accuracy: 97.36%\n",
      "Epoch [118/151], Loss: 0.0908, Accuracy: 97.05%\n",
      "Epoch [119/151], Loss: 0.0849, Accuracy: 97.25%\n",
      "Epoch [120/151], Loss: 0.0866, Accuracy: 97.19%\n",
      "Epoch [121/151], Loss: 0.0882, Accuracy: 97.20%\n",
      "Epoch [122/151], Loss: 0.0896, Accuracy: 97.08%\n",
      "Epoch [123/151], Loss: 0.0803, Accuracy: 97.46%\n",
      "Epoch [124/151], Loss: 0.0843, Accuracy: 97.24%\n",
      "Epoch [125/151], Loss: 0.0831, Accuracy: 97.24%\n",
      "Epoch [126/151], Loss: 0.0755, Accuracy: 97.55%\n",
      "Epoch [127/151], Loss: 0.0794, Accuracy: 97.40%\n",
      "Epoch [128/151], Loss: 0.0779, Accuracy: 97.48%\n",
      "Epoch [129/151], Loss: 0.0719, Accuracy: 97.64%\n",
      "Epoch [130/151], Loss: 0.0840, Accuracy: 97.32%\n",
      "Epoch [131/151], Loss: 0.0759, Accuracy: 97.51%\n",
      "Epoch [132/151], Loss: 0.0807, Accuracy: 97.39%\n",
      "Epoch [133/151], Loss: 0.0735, Accuracy: 97.65%\n",
      "Epoch [134/151], Loss: 0.0765, Accuracy: 97.58%\n",
      "Epoch [135/151], Loss: 0.0747, Accuracy: 97.59%\n",
      "Epoch [136/151], Loss: 0.0788, Accuracy: 97.48%\n",
      "Epoch [137/151], Loss: 0.0697, Accuracy: 97.73%\n",
      "Epoch [138/151], Loss: 0.0774, Accuracy: 97.55%\n",
      "Epoch [139/151], Loss: 0.0615, Accuracy: 97.95%\n",
      "Epoch [140/151], Loss: 0.0715, Accuracy: 97.68%\n",
      "Epoch [141/151], Loss: 0.0797, Accuracy: 97.46%\n",
      "Epoch [142/151], Loss: 0.0699, Accuracy: 97.75%\n",
      "Epoch [143/151], Loss: 0.0686, Accuracy: 97.80%\n",
      "Epoch [144/151], Loss: 0.0694, Accuracy: 97.75%\n",
      "Epoch [145/151], Loss: 0.0640, Accuracy: 97.94%\n",
      "Epoch [146/151], Loss: 0.0751, Accuracy: 97.59%\n",
      "Epoch [147/151], Loss: 0.0710, Accuracy: 97.75%\n",
      "Epoch [148/151], Loss: 0.0754, Accuracy: 97.55%\n",
      "Epoch [149/151], Loss: 0.0662, Accuracy: 97.91%\n",
      "Epoch [150/151], Loss: 0.0675, Accuracy: 97.80%\n",
      "Epoch [151/151], Loss: 0.0643, Accuracy: 97.96%\n",
      "Model saved successfully!\n",
      "Test Accuracy: 66.68%\n",
      "High-confidence Predictions: 6172, Percentage Correct High-confidence Predictions: 85.45%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# Check if GPU is available and set the device accordingly\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Hyperparameters\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 0.01\n",
    "WEIGHT_DECAY = 1e-4\n",
    "EPOCHS = 151\n",
    "CONFIDENCE_THRESHOLD = 0.99  # Confidence threshold for high-confidence predictions\n",
    "\n",
    "# Data augmentation and normalization for training and testing\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "# Load CIFAR-100 dataset\n",
    "train_dataset = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=transform_train)\n",
    "test_dataset = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Define ResNet block\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "# Define ResNet architecture\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes=100):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, out_channels, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.in_channels != out_channels:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
    "        self.in_channels = out_channels\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(out_channels, out_channels))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "def resnet101():\n",
    "    return ResNet(BasicBlock, [3, 4, 23, 3])\n",
    "\n",
    "# Training function\n",
    "def train(model, train_loader, optimizer, criterion, epochs, device):\n",
    "    model.to(device)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {total_loss/len(train_loader):.4f}, Accuracy: {100.0*correct/total:.2f}%\")\n",
    "\n",
    "# Initialize ResNet-101 and optimizer\n",
    "model = resnet101()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train the model\n",
    "train(model, train_loader, optimizer, criterion, EPOCHS, device)\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'resnet101_cifar100.pth')\n",
    "print(\"Model saved successfully!\")\n",
    "\n",
    "# Evaluate the model on test data\n",
    "def test(model, test_loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    high_confidence_correct = 0\n",
    "    high_confidence_total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            probabilities = F.softmax(outputs, dim=1)\n",
    "            confidence, predicted = probabilities.max(1)\n",
    "\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            # High confidence predictions\n",
    "            high_confidence_mask = confidence > CONFIDENCE_THRESHOLD\n",
    "            high_confidence_total += high_confidence_mask.sum().item()\n",
    "            high_confidence_correct += (predicted[high_confidence_mask] == targets[high_confidence_mask]).sum().item()\n",
    "\n",
    "    test_accuracy = 100.0 * correct / total\n",
    "    if high_confidence_total > 0:\n",
    "        high_confidence_accuracy = 100.0 * high_confidence_correct / high_confidence_total\n",
    "    else:\n",
    "        high_confidence_accuracy = 0.0\n",
    "\n",
    "    print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n",
    "    print(f\"High-confidence Predictions: {high_confidence_total}, Percentage Correct High-confidence Predictions: {high_confidence_accuracy:.2f}%\")\n",
    "\n",
    "# Test the model and check high-confidence predictions\n",
    "test(model, test_loader, device)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 12766.617331,
   "end_time": "2024-10-18T10:38:09.091608",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-10-18T07:05:22.474277",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
