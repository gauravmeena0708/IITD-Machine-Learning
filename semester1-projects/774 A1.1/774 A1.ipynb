{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_fOa1zdcjneG","executionInfo":{"status":"ok","timestamp":1723912295834,"user_tz":0,"elapsed":11640,"user":{"displayName":"Gaurav Meena","userId":"13738632202280078628"}},"outputId":"47debb32-08c5-488a-fe39-044a46781266"},"id":"_fOa1zdcjneG","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":null,"id":"6711d3f0-6702-48a7-8f6a-b2955dfe0b65","metadata":{"id":"6711d3f0-6702-48a7-8f6a-b2955dfe0b65","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1723899537542,"user_tz":0,"elapsed":420,"user":{"displayName":"Gaurav Meena","userId":"13738632202280078628"}},"outputId":"1635cbdf-e89f-4f41-d8b6-6fc309d6b9cd"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/COL774_AS1/train.csv /content/drive/MyDrive/COL774_AS1/train.csv /content/drive/MyDrive/COL774_AS1/test_pred.csv ['Operating Certificate Number', 'Gender', 'Hospital Service Area', 'Emergency Department Indicator', 'Permanent Facility Id', 'Payment Typology 1', 'Ethnicity', 'CCSR Diagnosis Description', 'Facility Name', 'Type of Admission', 'APR DRG Description', 'CCSR Procedure Description', 'Payment Typology 3', 'Hospital County', 'CCSR Procedure Code', 'Race', 'Zip Code - 3 digits', 'APR MDC Code', 'Payment Typology 2', 'APR MDC Description', 'APR DRG Code', 'Birth Weight']\n"]}],"source":["import pandas as pd\n","from sklearn.linear_model import Lasso\n","from sklearn.feature_selection import SelectFromModel\n","from sklearn.preprocessing import StandardScaler\n","import numpy as np\n","\n","def get_data(trainFile, testFile, predFile, dropcols):\n","    # Load datasets\n","    df_train = pd.read_csv(trainFile)\n","    df_test = pd.read_csv(testFile)\n","    df_pred = pd.read_csv(predFile)\n","\n","    # Drop specified columns\n","    df_train = df_train.drop(columns=dropcols)\n","    df_test = df_test.drop(columns=dropcols)\n","\n","    ycol = 'Total Costs'\n","    Y_trn = None\n","    if ycol in df_train.columns:\n","        Y_trn = df_train[[ycol]]\n","        df_train = df_train.drop(columns=[ycol])\n","\n","    X_trn_encoded = pd.get_dummies(df_train,columns=df_train.columns)\n","    X_tst_encoded = pd.get_dummies(df_test,columns=df_test.columns)\n","\n","    return df_train, Y_trn, df_test, df_pred, X_trn_encoded, X_tst_encoded\n","\n","# List of columns to remove\n","removeColumns = [\n","    'Operating Certificate Number', 'Zip Code - 3 digits', 'Gender', 'Race', 'CCSR Diagnosis Code',\n","    'CCSR Procedure Code', 'APR DRG Code', 'APR MDC Code', 'Payment Typology 2', 'Payment Typology 3',\n","    'Birth Weight', 'APR Severity of Illness Code'\n","]\n","\n","removeColumns = ['Operating Certificate Number','Gender','Hospital Service Area','Emergency Department Indicator','Permanent Facility Id','Payment Typology 1',\n"," 'Ethnicity','CCSR Diagnosis Description','Facility Name','Type of Admission','APR DRG Description','CCSR Procedure Description','Payment Typology 3',\n"," 'Hospital County','CCSR Procedure Code','Race','Zip Code - 3 digits','APR MDC Code','Payment Typology 2','APR MDC Description','APR DRG Code','Birth Weight']\n","\n","TrainPath = '/content/drive/MyDrive/COL774_AS1/train.csv'\n","TestPath = '/content/drive/MyDrive/COL774_AS1/test.csv'\n","PredPath = '/content/drive/MyDrive/COL774_AS1/test_pred.csv'\n","# Get the data\n","#X_train, Y_train, X_test, Y_test, X_train_encoded, X_test_encoded = get_data(TrainPath, TrainPath, PredPath, removeColumns)\n","\n","print(TrainPath, TrainPath, PredPath, removeColumns)\n"]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.linear_model import Ridge\n","from sklearn.metrics import mean_squared_error\n","from sklearn.preprocessing import StandardScaler\n","\n","def get_data(trainFile, testFile, predFile, dropcols):\n","    # Load datasets\n","    df_train = pd.read_csv(trainFile)\n","    df_test = pd.read_csv(testFile)\n","    df_pred = pd.read_csv(predFile)\n","\n","    # Drop specified columns\n","    df_train = df_train.drop(columns=dropcols)\n","    df_test = df_test.drop(columns=dropcols)\n","\n","    ycol = 'Total Costs'\n","    Y_trn = None\n","    if ycol in df_train.columns:\n","        Y_trn = df_train[[ycol]]\n","        df_train = df_train.drop(columns=[ycol])\n","\n","    return df_train, Y_trn, df_test, df_pred\n","\n","def one_hot_encode_and_scale(X_train, X_test, X_pred):\n","    # One-hot encode categorical variables\n","    X_train_encoded = pd.get_dummies(X_train)\n","    X_test_encoded = pd.get_dummies(X_test)\n","    X_pred_encoded = pd.get_dummies(X_pred)\n","\n","    # Align columns of test and prediction data to training data\n","    X_train_encoded, X_test_encoded = X_train_encoded.align(X_test_encoded, join='left', axis=1, fill_value=0)\n","    X_train_encoded, X_pred_encoded = X_train_encoded.align(X_pred_encoded, join='left', axis=1, fill_value=0)\n","\n","    # Standardize the features\n","    scaler = StandardScaler()\n","    X_train_scaled = scaler.fit_transform(X_train_encoded)\n","    X_test_scaled = scaler.transform(X_test_encoded)\n","    X_pred_scaled = scaler.transform(X_pred_encoded)\n","\n","    return X_train_scaled, X_test_scaled, X_pred_scaled, X_train_encoded.columns\n","\n","def select_top_features_ridge(X_train, Y_train, X_test, X_pred, top_n=300):\n","    # Fit Ridge regression\n","    ridge = Ridge(alpha=1.0)\n","    ridge.fit(X_train, Y_train.values.ravel())\n","\n","    # Get the absolute values of coefficients\n","    coefs = np.abs(ridge.coef_)\n","\n","    # Select top N features\n","    top_features_idx = np.argsort(coefs)[-top_n:]\n","    X_train_top = X_train[:, top_features_idx]\n","    X_test_top = X_test[:, top_features_idx]\n","    X_pred_top = X_pred[:, top_features_idx]\n","\n","    return X_train_top, X_test_top, X_pred_top\n","\n","def calculate_mse_and_predict(X_train, Y_train, X_test, Y_test):\n","    # Train Ridge regression on selected features\n","    ridge = Ridge(alpha=1.0)\n","    ridge.fit(X_train, Y_train.values.ravel())\n","\n","    # Predict on the test set\n","    Y_pred = ridge.predict(X_test)\n","\n","    # Calculate Mean Squared Error (MSE)\n","    mse = mean_squared_error(Y_test, Y_pred)\n","    return mse, Y_pred\n","\n","# Define file paths\n","TrainPath = \"train.csv\"\n","TestPath = \"test.csv\"\n","PredPath = \"pred.csv\"\n","\n","# List of columns to remove\n","removeColumns = [\n","    'Operating Certificate Number', 'Zip Code - 3 digits', 'Gender', 'Race', 'CCSR Diagnosis Code',\n","    'CCSR Procedure Code', 'APR DRG Code', 'APR MDC Code', 'Payment Typology 2', 'Payment Typology 3',\n","    'Birth Weight', 'APR Severity of Illness Code'\n","]\n","\n","# Get the data\n","X_train, Y_train, X_test, X_pred = get_data(TrainPath, TestPath, PredPath, removeColumns)\n","\n","# One-hot encode and scale the data\n","X_train_scaled, X_test_scaled, X_pred_scaled, feature_names = one_hot_encode_and_scale(X_train, X_test, X_pred)\n","\n","# Select the best 300 features using Ridge regression\n","X_train_top, X_test_top, X_pred_top = select_top_features_ridge(X_train_scaled, Y_train, X_test_scaled, X_pred_scaled, top_n=300)\n","\n","# Calculate MSE on the test set and get predictions\n","mse, Y_pred = calculate_mse_and_predict(X_train_top, Y_train, X_test_top, Y_train)\n","\n","print(\"Mean Squared Error on the test set:\", mse)\n"],"metadata":{"id":"G2YmopELs-XG","executionInfo":{"status":"ok","timestamp":1723816994586,"user_tz":-330,"elapsed":4941,"user":{"displayName":"Gaurav Meena","userId":"13738632202280078628"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ab282346-5343-4fec-f77e-aa03af85da0e"},"id":"G2YmopELs-XG","execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.10/dist-packages/sklearn/base.py:458: UserWarning: X has feature names, but SelectKBest was fitted without feature names\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Mean Squared Error: 14009555397386.83\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","\n","# Load data\n","df = pd.read_csv('/content/drive/MyDrive/COL774_AS1/train.csv')\n","\n","# Columns to be removed\n","Hospital Service Area,\n","Hospital County,\n","Operating Certificate Number,\n","Permanent Facility Id,Facility Name,Age Group,Zip Code - 3 digits,Gender,Race,Ethnicity,Type of Admission,Patient Disposition,CCSR Diagnosis Code,CCSR Diagnosis Description,CCSR Procedure Code,CCSR Procedure Description,APR DRG Code,APR DRG Description,APR MDC Code,APR MDC Description,APR Severity of Illness Code,APR Severity of Illness Description,APR Risk of Mortality,APR Medical Surgical Description,Payment Typology 1,Payment Typology 2,Payment Typology 3,Birth Weight,Emergency Department Indicator,Total Costs\n","\n","removeColumns = [\n","    'Hospital Service Area',\n","    'Operating Certificate Number', 'Gender', , 'Emergency Department Indicator',\n","    'Permanent Facility Id', 'Payment Typology 1', 'Ethnicity', 'CCSR Diagnosis Description',\n","    'Facility Name', 'Type of Admission', 'APR DRG Description', 'CCSR Procedure Description',\n","    'Payment Typology 3', 'Hospital County', 'CCSR Procedure Code', 'Race', 'Zip Code - 3 digits',\n","    'APR MDC Code', 'Payment Typology 2', 'APR MDC Description', 'APR DRG Code', 'Birth Weight'\n","]\n","\n","df1 = df.drop(columns=removeColumns)\n","categorical_columns = df1.columns\n","X_trn_encoded = pd.get_dummies(df1, columns=categorical_columns)\n","print(X_trn_encoded.shape)\n"],"metadata":{"id":"CZltUuAev3Lc"},"id":"CZltUuAev3Lc","execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_trn_encoded.head()"],"metadata":{"id":"ToJb7UAxtUuH","colab":{"base_uri":"https://localhost:8080/","height":224},"executionInfo":{"status":"ok","timestamp":1723900451391,"user_tz":0,"elapsed":456,"user":{"displayName":"Gaurav Meena","userId":"13738632202280078628"}},"outputId":"fb7d660b-ea10-46e3-8f71-2e3ea5579dcf"},"id":"ToJb7UAxtUuH","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Age Group  Patient Disposition  CCSR Diagnosis Code  \\\n","0          3                    8                  433   \n","1          5                   19                   29   \n","2          3                    8                   85   \n","3          2                    8                  112   \n","4          4                    8                  362   \n","\n","   APR Severity of Illness Code  APR Severity of Illness Description  \\\n","0                             1                                  3.0   \n","1                             3                                  2.0   \n","2                             1                                  3.0   \n","3                             2                                  4.0   \n","4                             4                                  1.0   \n","\n","   APR Risk of Mortality  APR Medical Surgical Description  Total Costs  \n","0                    3.0                                 1     27153.03  \n","1                    2.0                                 1     13483.80  \n","2                    3.0                                 3     21851.50  \n","3                    3.0                                 3     19588.31  \n","4                    4.0                                 1    175220.97  "],"text/html":["\n","  <div id=\"df-07732fd4-7c96-4c72-8075-ad12bf68fddc\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Age Group</th>\n","      <th>Patient Disposition</th>\n","      <th>CCSR Diagnosis Code</th>\n","      <th>APR Severity of Illness Code</th>\n","      <th>APR Severity of Illness Description</th>\n","      <th>APR Risk of Mortality</th>\n","      <th>APR Medical Surgical Description</th>\n","      <th>Total Costs</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>3</td>\n","      <td>8</td>\n","      <td>433</td>\n","      <td>1</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>1</td>\n","      <td>27153.03</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>5</td>\n","      <td>19</td>\n","      <td>29</td>\n","      <td>3</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>1</td>\n","      <td>13483.80</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>8</td>\n","      <td>85</td>\n","      <td>1</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3</td>\n","      <td>21851.50</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2</td>\n","      <td>8</td>\n","      <td>112</td>\n","      <td>2</td>\n","      <td>4.0</td>\n","      <td>3.0</td>\n","      <td>3</td>\n","      <td>19588.31</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>8</td>\n","      <td>362</td>\n","      <td>4</td>\n","      <td>1.0</td>\n","      <td>4.0</td>\n","      <td>1</td>\n","      <td>175220.97</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-07732fd4-7c96-4c72-8075-ad12bf68fddc')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-07732fd4-7c96-4c72-8075-ad12bf68fddc button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-07732fd4-7c96-4c72-8075-ad12bf68fddc');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-be4cdb98-bd70-45c9-9c79-009873ac656c\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-be4cdb98-bd70-45c9-9c79-009873ac656c')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-be4cdb98-bd70-45c9-9c79-009873ac656c button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"X_trn_encoded"}},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.feature_selection import mutual_info_regression\n","from sklearn.preprocessing import LabelEncoder\n","\n","# Load your dataset\n","df = pd.read_csv('/content/drive/MyDrive/COL774_AS1/train.csv')\n","\n","df.columns\n","\n","df['area'] = str(df['Facility Name']) + str(df['Zip Code - 3 digits'])\n","df['demographic'] = str(df['Age Group']) + str(df['Gender'])\n","df.drop(['Facility Name', 'Zip Code - 3 digits','Hospital Service Area', 'Hospital County','Operating Certificate Number', 'Permanent Facility Id'], axis=1, inplace=True)\n","df.columns"],"metadata":{"id":"H-Ps2_Kvv4Sw","executionInfo":{"status":"ok","timestamp":1723902188403,"user_tz":0,"elapsed":6001,"user":{"displayName":"Gaurav Meena","userId":"13738632202280078628"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"2bd3d333-a571-4ce9-cb61-f18e4866e80c"},"id":"H-Ps2_Kvv4Sw","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['Age Group', 'Gender', 'Race', 'Ethnicity', 'Type of Admission',\n","       'Patient Disposition', 'CCSR Diagnosis Code',\n","       'CCSR Diagnosis Description', 'CCSR Procedure Code',\n","       'CCSR Procedure Description', 'APR DRG Code', 'APR DRG Description',\n","       'APR MDC Code', 'APR MDC Description', 'APR Severity of Illness Code',\n","       'APR Severity of Illness Description', 'APR Risk of Mortality',\n","       'APR Medical Surgical Description', 'Payment Typology 1',\n","       'Payment Typology 2', 'Payment Typology 3', 'Birth Weight',\n","       'Emergency Department Indicator', 'Total Costs', 'area'],\n","      dtype='object')"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.model_selection import KFold\n","from sklearn.metrics import mean_squared_error\n","\n","# Load your dataset\n","df = pd.read_csv('/content/drive/MyDrive/COL774_AS1/train.csv')\n","\n","# Define the categorical columns to be target encoded\n","target_encode_cols = [\n","    'Type of Admission',\n","    'APR Severity of Illness Description',\n","    'APR Risk of Mortality'\n","]\n","\n","# Function to perform target encoding with K-Fold\n","def target_encode(train, target, col, n_splits=5):\n","    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n","    mean_target = train[target].mean()\n","    encoded_col = pd.Series(0, index=train.index)\n","\n","    for train_idx, valid_idx in kf.split(train):\n","        train_fold, valid_fold = train.iloc[train_idx], train.iloc[valid_idx]\n","        means = train_fold.groupby(col)[target].mean()\n","        encoded_col.iloc[valid_idx] = valid_fold[col].map(means)\n","\n","    # Replace NaN values (if any) with the global mean\n","    encoded_col.fillna(mean_target, inplace=True)\n","\n","    return encoded_col\n","\n","# Apply target encoding to the selected columns\n","for col in target_encode_cols:\n","    df[col + '_encoded'] = target_encode(df, 'Total Costs', col)\n","\n","# Drop the original columns if necessary\n","df = df.drop(columns=target_encode_cols)\n","\n","# Display the first few rows of the encoded dataframe\n","print(df.head())\n"],"metadata":{"id":"FZv7vudZymrX","executionInfo":{"status":"ok","timestamp":1723902421772,"user_tz":0,"elapsed":6887,"user":{"displayName":"Gaurav Meena","userId":"13738632202280078628"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"d94be089-c339-42a0-866e-23fcf1d25fdd"},"id":"FZv7vudZymrX","execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-3-59979d2a4a39>:24: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[29716.3860213  28249.53671448 28249.53671448 ... 29716.3860213\n"," 29716.3860213  29716.3860213 ]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n","  encoded_col.iloc[valid_idx] = valid_fold[col].map(means)\n","<ipython-input-3-59979d2a4a39>:24: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[13426.90098346 13426.90098346 33513.14700224 ... 20511.96141274\n"," 20511.96141274 72791.90073056]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n","  encoded_col.iloc[valid_idx] = valid_fold[col].map(means)\n","<ipython-input-3-59979d2a4a39>:24: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[15931.82895381 15931.82895381 26076.03971686 ... 15931.82895381\n"," 15931.82895381 67985.085915  ]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n","  encoded_col.iloc[valid_idx] = valid_fold[col].map(means)\n"]},{"output_type":"stream","name":"stdout","text":["   Hospital Service Area  Hospital County  Operating Certificate Number  \\\n","0                    6.0             22.0                     7001016.0   \n","1                    6.0              3.0                     7000006.0   \n","2                    6.0              3.0                     7000001.0   \n","3                    2.0             32.0                     3301007.0   \n","4                    6.0             26.0                     7002020.0   \n","\n","   Permanent Facility Id  Facility Name  Age Group  Zip Code - 3 digits  \\\n","0                 1301.0             70          3                 12.0   \n","1                 3058.0             93          5                  4.0   \n","2                 1178.0             11          3                  4.0   \n","3                  628.0            186          2                 32.0   \n","4                 1453.0             87          4                 14.0   \n","\n","   Gender  Race  Ethnicity  ...  APR Medical Surgical Description  \\\n","0       1     1          4  ...                                 1   \n","1       1     1          2  ...                                 1   \n","2       1     3          3  ...                                 3   \n","3       1     4          3  ...                                 3   \n","4       1     4          2  ...                                 1   \n","\n","   Payment Typology 1  Payment Typology 2  Payment Typology 3  Birth Weight  \\\n","0                   8                10.0                10.0           0.0   \n","1                   6                 5.0                10.0           0.0   \n","2                   6                 6.0                 5.0           0.0   \n","3                   8                10.0                10.0           0.0   \n","4                   6                10.0                10.0           0.0   \n","\n","   Emergency Department Indicator  Total Costs  Type of Admission_encoded  \\\n","0                               1     27153.03               29716.386021   \n","1                               2     13483.80               29810.664430   \n","2                               1     21851.50               28249.536714   \n","3                               1     19588.31               28307.885775   \n","4                               1    175220.97               28242.160500   \n","\n","   APR Severity of Illness Description_encoded  APR Risk of Mortality_encoded  \n","0                                 13426.900983                   15931.828954  \n","1                                 33593.618450                   37979.910081  \n","2                                 13426.900983                   15931.828954  \n","3                                 20516.498633                   15974.080909  \n","4                                 72852.016174                   26019.687138  \n","\n","[5 rows x 30 columns]\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import Ridge\n","from sklearn.metrics import mean_squared_error, r2_score\n","\n","# Load your dataset\n","df = pd.read_csv('/content/drive/MyDrive/COL774_AS1/train.csv')\n","\n","# Ensure the 'Total Costs' column is numeric\n","df['Total Costs'] = pd.to_numeric(df['Total Costs'], errors='coerce')\n","\n","# Create the 'Hospital_Zip' feature\n","df['Hospital_Zip'] = df['Facility Name'].astype(str) + '_' + df['Zip Code - 3 digits'].astype(str)\n","\n","def target_encode(train, target, col, alpha=1):\n","    mean_target = train[target].mean()  # Calculate the global mean of the target\n","    counts = train.groupby(col)[target].count()\n","    means = train.groupby(col)[target].mean()\n","\n","    # Apply smoothing\n","    smoothed_means = (counts * means + alpha * mean_target) / (counts + alpha)\n","\n","    return train[col].map(smoothed_means)\n","\n","# Apply target encoding\n","df['Hospital_Zip_encoded'] = target_encode(df, 'Total Costs', 'Hospital_Zip')\n","df = df.drop(columns=['Hospital_Zip', 'Hospital Service Area', 'Hospital County', 'Operating Certificate Number', 'Permanent Facility Id', 'Facility Name', 'Zip Code - 3 digits', 'Payment Typology 2',\n","                      'Payment Typology 3', 'Birth Weight', 'CCSR Diagnosis Description', 'CCSR Procedure Description', 'APR DRG Description', 'APR MDC Description', 'APR Severity of Illness Code'])\n","df['Age Group'] = target_encode(df, 'Total Costs', 'Age Group')\n","df['Gender'] = target_encode(df, 'Total Costs', 'Gender')\n","df['Race'] = target_encode(df, 'Total Costs', 'Race')\n","df['Ethnicity'] = target_encode(df, 'Total Costs', 'Ethnicity')\n","\n","df['CCSR Diagnosis Code'] = target_encode(df, 'Total Costs', 'CCSR Diagnosis Code')\n","df['CCSR Procedure Code'] = target_encode(df, 'Total Costs', 'CCSR Procedure Code')\n","df['APR DRG Code'] = target_encode(df, 'Total Costs', 'APR DRG Code')\n","df['APR MDC Code'] = target_encode(df, 'Total Costs', 'APR MDC Code')\n","\n","# Define new label encoding mappings\n","severity_mapping = {3: 1, 4:2, 2:3, 1:4}\n","mortality_mapping = {3: 1, 4:2, 2:3, 1:4}\n","medical_surgical_mapping = {2: 0, 1: 1, 3: 2}\n","emergency_mapping = {1: 0, 2: 1}\n","\n","df['APR Severity of Illness Description'] = df['APR Severity of Illness Description'].map(severity_mapping)\n","df['APR Risk of Mortality'] = df['APR Risk of Mortality'].map(mortality_mapping)\n","df['APR Medical Surgical Description'] = df['APR Medical Surgical Description'].map(medical_surgical_mapping)\n","df['Emergency Department Indicator'] = df['Emergency Department Indicator'].map(emergency_mapping)\n","\n","df_encoded = pd.get_dummies(df, columns=['Patient Disposition', 'Payment Typology 1'])\n","\n","# Define features (X) and target variable (y)\n","X_train = df_encoded.drop(columns=['Total Costs'])\n","y_train = df_encoded['Total Costs']\n","\n","test_file = '/content/drive/MyDrive/COL774_AS1/test.csv'\n","\n","X_train.shape"],"metadata":{"id":"9UWtnJ1OziI8","executionInfo":{"status":"ok","timestamp":1723905263754,"user_tz":0,"elapsed":4184,"user":{"displayName":"Gaurav Meena","userId":"13738632202280078628"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"2ac187da-f0e8-4375-f446-4e39db11b0d9"},"id":"9UWtnJ1OziI8","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(584004, 42)"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import Ridge\n","from sklearn.metrics import mean_squared_error, r2_score\n","\n","# Load the training dataset\n","df = pd.read_csv('/content/drive/MyDrive/COL774_AS1/train.csv')\n","\n","# Ensure the 'Total Costs' column is numeric\n","df['Total Costs'] = pd.to_numeric(df['Total Costs'], errors='coerce')\n","\n","# Create the 'Hospital_Zip' feature\n","df['Hospital_Zip'] = df['Facility Name'].astype(str) + '_' + df['Zip Code - 3 digits'].astype(str)\n","\n","def target_encode(train, target, col, alpha=1):\n","    mean_target = train[target].mean()  # Calculate the global mean of the target\n","    counts = train.groupby(col)[target].count()\n","    means = train.groupby(col)[target].mean()\n","\n","    # Apply smoothing\n","    smoothed_means = (counts * means + alpha * mean_target) / (counts + alpha)\n","\n","    return train[col].map(smoothed_means)\n","\n","# Apply target encoding\n","df['Hospital_Zip_encoded'] = target_encode(df, 'Total Costs', 'Hospital_Zip')\n","df = df.drop(columns=['Hospital_Zip', 'Hospital Service Area', 'Hospital County', 'Operating Certificate Number', 'Permanent Facility Id', 'Facility Name', 'Zip Code - 3 digits', 'Payment Typology 2',\n","                      'Payment Typology 3', 'Birth Weight', 'CCSR Diagnosis Description', 'CCSR Procedure Description', 'APR DRG Description', 'APR MDC Description', 'APR Severity of Illness Code'])\n","df['Age Group'] = target_encode(df, 'Total Costs', 'Age Group')\n","df['Gender'] = target_encode(df, 'Total Costs', 'Gender')\n","df['Race'] = target_encode(df, 'Total Costs', 'Race')\n","df['Ethnicity'] = target_encode(df, 'Total Costs', 'Ethnicity')\n","\n","df['CCSR Diagnosis Code'] = target_encode(df, 'Total Costs', 'CCSR Diagnosis Code')\n","df['CCSR Procedure Code'] = target_encode(df, 'Total Costs', 'CCSR Procedure Code')\n","df['APR DRG Code'] = target_encode(df, 'Total Costs', 'APR DRG Code')\n","df['APR MDC Code'] = target_encode(df, 'Total Costs', 'APR MDC Code')\n","\n","# Define new label encoding mappings\n","severity_mapping = {3: 1, 4:2, 2:3, 1:4}\n","mortality_mapping = {3: 1, 4:2, 2:3, 1:4}\n","medical_surgical_mapping = {2: 0, 1: 1, 3: 2}\n","emergency_mapping = {1: 0, 2: 1}\n","\n","df['APR Severity of Illness Description'] = df['APR Severity of Illness Description'].map(severity_mapping)\n","df['APR Risk of Mortality'] = df['APR Risk of Mortality'].map(mortality_mapping)\n","df['APR Medical Surgical Description'] = df['APR Medical Surgical Description'].map(medical_surgical_mapping)\n","df['Emergency Department Indicator'] = df['Emergency Department Indicator'].map(emergency_mapping)\n","\n","df_encoded = pd.get_dummies(df, columns=['Patient Disposition', 'Payment Typology 1'])\n","\n","# Define features (X) and target variable (y)\n","X_train = df_encoded.drop(columns=['Total Costs'])\n","y_train = df_encoded['Total Costs']\n","\n","# Load the test dataset\n","df_test = pd.read_csv('/content/drive/MyDrive/COL774_AS1/test.csv')\n","\n","# Apply the same preprocessing to the test data\n","df_test['Hospital_Zip'] = df_test['Facility Name'].astype(str) + '_' + df_test['Zip Code - 3 digits'].astype(str)\n","df_test['Hospital_Zip_encoded'] = target_encode(df, 'Total Costs', 'Hospital_Zip')\n","\n","df_test = df_test.drop(columns=['Hospital_Zip', 'Hospital Service Area', 'Hospital County', 'Operating Certificate Number', 'Permanent Facility Id', 'Facility Name', 'Zip Code - 3 digits', 'Payment Typology 2',\n","                                'Payment Typology 3', 'Birth Weight', 'CCSR Diagnosis Description', 'CCSR Procedure Description', 'APR DRG Description', 'APR MDC Description', 'APR Severity of Illness Code'])\n","df_test['Age Group'] = target_encode(df, 'Total Costs', 'Age Group')\n","df_test['Gender'] = target_encode(df, 'Total Costs', 'Gender')\n","df_test['Race'] = target_encode(df, 'Total Costs', 'Race')\n","df_test['Ethnicity'] = target_encode(df, 'Total Costs', 'Ethnicity')\n","\n","df_test['CCSR Diagnosis Code'] = target_encode(df, 'Total Costs', 'CCSR Diagnosis Code')\n","df_test['CCSR Procedure Code'] = target_encode(df, 'Total Costs', 'CCSR Procedure Code')\n","df_test['APR DRG Code'] = target_encode(df, 'Total Costs', 'APR DRG Code')\n","df_test['APR MDC Code'] = target_encode(df, 'Total Costs', 'APR MDC Code')\n","\n","df_test['APR Severity of Illness Description'] = df_test['APR Severity of Illness Description'].map(severity_mapping)\n","df_test['APR Risk of Mortality'] = df_test['APR Risk of Mortality'].map(mortality_mapping)\n","df_test['APR Medical Surgical Description'] = df_test['APR Medical Surgical Description'].map(medical_surgical_mapping)\n","df_test['Emergency Department Indicator'] = df_test['Emergency Department Indicator'].map(emergency_mapping)\n","\n","df_test_encoded = pd.get_dummies(df_test, columns=['Patient Disposition', 'Payment Typology 1'])\n","\n","# Align test data with training data\n","df_test_encoded = df_test_encoded.reindex(columns=X_train.columns, fill_value=0)\n","\n","# Train the model\n","model = Ridge()\n","model.fit(X_train, y_train)\n","\n","# Generate predictions\n","Y_pred = model.predict(df_test_encoded)\n","\n","# Compute RMSE based on the provided logic\n","errors = (y_train - Y_pred) ** 2  # Computing the error vector\n","errors = np.sort(errors)\n","percentile_value = 90  # Top 90% of errors\n","elements = int(percentile_value * len(errors) / 100)  # Taking the best 90% errors\n","errors = errors[:elements]\n","average_square_error = np.mean(errors)  # Average of square errors\n","rmse = (average_square_error) ** 0.5  # Root mean square\n","\n","# Output RMSE\n","print(\"Objective Function obtained on the test set = \" + str(rmse))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":383},"id":"VVRz4YQEorQ9","executionInfo":{"status":"error","timestamp":1723905730220,"user_tz":0,"elapsed":6617,"user":{"displayName":"Gaurav Meena","userId":"13738632202280078628"}},"outputId":"791be215-8a33-4af9-c007-009079386e4b"},"id":"VVRz4YQEorQ9","execution_count":null,"outputs":[{"output_type":"error","ename":"KeyError","evalue":"'Hospital_Zip'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-c92d45f06ff2>\u001b[0m in \u001b[0;36m<cell line: 61>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;31m# Apply the same preprocessing to the test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Hospital_Zip'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Facility Name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Zip Code - 3 digits'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m \u001b[0mdf_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Hospital_Zip_encoded'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Total Costs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Hospital_Zip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m df_test = df_test.drop(columns=['Hospital_Zip', 'Hospital Service Area', 'Hospital County', 'Operating Certificate Number', 'Permanent Facility Id', 'Facility Name', 'Zip Code - 3 digits', 'Payment Typology 2',\n","\u001b[0;32m<ipython-input-22-c92d45f06ff2>\u001b[0m in \u001b[0;36mtarget_encode\u001b[0;34m(train, target, col, alpha)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtarget_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mmean_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Calculate the global mean of the target\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mcounts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mmeans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mgroupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   8867\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You have to supply one of 'by' and 'level'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 8869\u001b[0;31m         return DataFrameGroupBy(\n\u001b[0m\u001b[1;32m   8870\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8871\u001b[0m             \u001b[0mkeys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   1276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgrouper\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m             grouper, exclusions, obj = get_grouper(\n\u001b[0m\u001b[1;32m   1279\u001b[0m                 \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1280\u001b[0m                 \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/groupby/grouper.py\u001b[0m in \u001b[0;36mget_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[0m\n\u001b[1;32m   1007\u001b[0m                 \u001b[0min_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1008\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1009\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1010\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGrouper\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mgpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m             \u001b[0;31m# Add key to exclusions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'Hospital_Zip'"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.linear_model import Ridge\n","from sklearn.model_selection import train_test_split\n","\n","# Load the dataset\n","df = pd.read_csv('/content/drive/MyDrive/COL774_AS1/train.csv')\n","\n","# Ensure the 'Total Costs' column is numeric\n","df['Total Costs'] = pd.to_numeric(df['Total Costs'], errors='coerce')\n","\n","# Create the 'Hospital_Zip' feature\n","df['Hospital_Zip'] = df['Facility Name'].astype(str) + '_' + df['Zip Code - 3 digits'].astype(str)\n","\n","def target_encode(train, target, col, alpha=1):\n","    mean_target = train[target].mean()  # Calculate the global mean of the target\n","    counts = train.groupby(col)[target].count()\n","    means = train.groupby(col)[target].mean()\n","\n","    # Apply smoothing\n","    smoothed_means = (counts * means + alpha * mean_target) / (counts + alpha)\n","\n","    return train[col].map(smoothed_means)\n","\n","# Apply target encoding\n","df['Hospital_Zip_encoded'] = target_encode(df, 'Total Costs', 'Hospital_Zip')\n","df = df.drop(columns=['Hospital_Zip', 'Hospital Service Area', 'Hospital County', 'Operating Certificate Number', 'Permanent Facility Id', 'Facility Name', 'Zip Code - 3 digits', 'Payment Typology 2',\n","                      'Payment Typology 3', 'Birth Weight', 'CCSR Diagnosis Description', 'CCSR Procedure Description', 'APR DRG Description', 'APR MDC Description', 'APR Severity of Illness Code',\n","                      'CCSR Diagnosis Code','CCSR Procedure Code','APR DRG Code'])\n","df['Age Group'] = target_encode(df, 'Total Costs', 'Age Group')\n","df['Gender'] = target_encode(df, 'Total Costs', 'Gender')\n","df['Race'] = target_encode(df, 'Total Costs', 'Race')\n","df['Ethnicity'] = target_encode(df, 'Total Costs', 'Ethnicity')\n","\n","#df['CCSR Diagnosis Code'] = target_encode(df, 'Total Costs', 'CCSR Diagnosis Code')\n","#df['CCSR Procedure Code'] = target_encode(df, 'Total Costs', 'CCSR Procedure Code')\n","#df['APR DRG Code'] = target_encode(df, 'Total Costs', 'APR DRG Code')\n","#df['APR MDC Code'] = target_encode(df, 'Total Costs', 'APR MDC Code')\n","\n","# Define new label encoding mappings\n","severity_mapping = {3: 1, 4:2, 2:3, 1:4}\n","mortality_mapping = {3: 1, 4:2, 2:3, 1:4}\n","medical_surgical_mapping = {2: 0, 1: 1, 3: 2}\n","emergency_mapping = {1: 0, 2: 1}\n","\n","df['APR Severity of Illness Description'] = df['APR Severity of Illness Description'].map(severity_mapping)\n","df['APR Risk of Mortality'] = df['APR Risk of Mortality'].map(mortality_mapping)\n","df['APR Medical Surgical Description'] = df['APR Medical Surgical Description'].map(medical_surgical_mapping)\n","df['Emergency Department Indicator'] = df['Emergency Department Indicator'].map(emergency_mapping)\n","\n","df_encoded = pd.get_dummies(df, columns=['Patient Disposition', 'Payment Typology 1','APR MDC Code'])\n","\n","# Define features (X) and target variable (y)\n","X = df_encoded.drop(columns=['Total Costs'])\n","y = df_encoded['Total Costs']\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Train the model\n","model = Ridge()\n","model.fit(X_train, y_train)\n","\n","# Generate predictions\n","Y_pred = model.predict(X_test)\n","\n","# Compute RMSE based on the provided logic\n","errors = (y_test - Y_pred) ** 2  # Computing the error vector\n","errors = np.sort(errors)\n","percentile_value = 90  # Top 90% of errors\n","elements = int(percentile_value * len(errors) / 100)  # Taking the best 90% errors\n","errors = errors[:elements]\n","average_square_error = np.mean(errors)  # Average of square errors\n","rmse = (average_square_error) ** 0.5  # Root mean square\n","\n","# Output RMSE\n","print(\"Objective Function obtained on the test set = \" + str(rmse))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yh3z5E2nxh81","executionInfo":{"status":"ok","timestamp":1723906025045,"user_tz":0,"elapsed":3906,"user":{"displayName":"Gaurav Meena","userId":"13738632202280078628"}},"outputId":"c710dc87-adfb-4549-9b54-4cf478db1128"},"id":"yh3z5E2nxh81","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Objective Function obtained on the test set = 15991.139688901061\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.linear_model import Ridge\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n","from sklearn.pipeline import Pipeline\n","from sklearn.feature_selection import SelectKBest, f_regression\n","\n","# Load the dataset\n","df = pd.read_csv('/content/drive/MyDrive/COL774_AS1/train.csv')\n","\n","# Ensure 'Total Costs' column is numeric and handle missing values\n","df['Total Costs'] = pd.to_numeric(df['Total Costs'], errors='coerce')\n","df = df.dropna(subset=['Total Costs'])  # Drop rows where 'Total Costs' is NaN\n","\n","# Create interaction features\n","df['Hospital_Zip'] = df['Facility Name'].astype(str) + '_' + df['Zip Code - 3 digits'].astype(str)\n","df['Age_Gender'] = df['Age Group'].astype(str) + '_' + df['Gender'].astype(str)\n","df['Race_Ethnicity'] = df['Race'].astype(str) + '_' + df['Ethnicity'].astype(str)\n","\n","def target_encode(train, target, col, alpha=1):\n","    mean_target = train[target].mean()  # Calculate the global mean of the target\n","    counts = train.groupby(col)[target].count()\n","    means = train.groupby(col)[target].mean()\n","\n","    # Apply smoothing\n","    smoothed_means = (counts * means + alpha * mean_target) / (counts + alpha)\n","\n","    return train[col].map(smoothed_means)\n","\n","# Apply target encoding\n","df['Hospital_Zip_encoded'] = target_encode(df, 'Total Costs', 'Hospital_Zip')\n","df['Age_Gender_encoded'] = target_encode(df, 'Total Costs', 'Age_Gender')\n","df['Race_Ethnicity_encoded'] = target_encode(df, 'Total Costs', 'Race_Ethnicity')\n","\n","df = df.drop(columns=['Age_Gender', 'Race_Ethnicity', 'Age Group', 'Hospital_Zip', 'Gender',\n","                      'Facility Name', 'Zip Code - 3 digits'])\n","\n","# Apply target encoding to additional columns\n","encoding_columns = ['CCSR Diagnosis Code', 'CCSR Procedure Code', 'APR DRG Code', 'APR MDC Code',\n","                     'APR Severity of Illness Code', 'Patient Disposition', 'Payment Typology 2',\n","                     'Payment Typology 3', 'Birth Weight', 'CCSR Diagnosis Description',\n","                     'CCSR Procedure Description', 'APR DRG Description', 'APR MDC Description','Emergency Department Indicator',\n","                    'APR Medical Surgical Description','APR Risk of Mortality','APR Severity of Illness Description']\n","\n","one_hot_columns = []\n","target_columns  = []\n","label_columns   = []\n","for col in encoding_columns:\n","    df[col] = target_encode(df, 'Total Costs', col)\n","\n","# Define new label encoding mappings\n","mappings = {\n","}\n","\n","for col, mapping in mappings.items():\n","    df[col] = df[col].map(mapping)\n","\n","# Use one-hot encoding for categorical variables\n","df_encoded = pd.get_dummies(df, columns=['Payment Typology 1'])\n","\n","# Define features (X) and target variable (y)\n","X = df_encoded.drop(columns=['Total Costs'])\n","y = df_encoded['Total Costs']\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Standardize features\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_test_scaled = scaler.transform(X_test)\n","\n","# Train the model\n","model = Ridge()\n","model.fit(X_train_scaled, y_train)\n","\n","# Generate predictions\n","Y_pred = model.predict(X_test_scaled)\n","\n","# Compute RMSE based on the provided logic\n","errors = (y_test - Y_pred) ** 2  # Computing the error vector\n","errors = np.sort(errors)\n","percentile_value = 90  # Top 90% of errors\n","elements = int(percentile_value * len(errors) / 100)  # Taking the best 90% errors\n","errors = errors[:elements]\n","average_square_error = np.mean(errors)  # Average of square errors\n","rmse = (average_square_error) ** 0.5  # Root mean square\n","\n","# Output RMSE\n","print(\"Objective Function obtained on the test set = \" + str(rmse))\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gAgqFoCBz775","executionInfo":{"status":"ok","timestamp":1723908121066,"user_tz":0,"elapsed":8473,"user":{"displayName":"Gaurav Meena","userId":"13738632202280078628"}},"outputId":"84f958e7-3ad9-4c75-a9a3-c3d532ec4e9b"},"id":"gAgqFoCBz775","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Objective Function obtained on the test set = 12882.591294246049\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.linear_model import Ridge\n","from sklearn.model_selection import train_test_split, cross_val_score\n","from sklearn.preprocessing import StandardScaler\n","\n","# Load the dataset\n","df = pd.read_csv('/content/drive/MyDrive/COL774_AS1/train.csv')\n","\n","# Ensure 'Total Costs' column is numeric and handle missing values\n","df['Total Costs'] = pd.to_numeric(df['Total Costs'], errors='coerce')\n","df = df.dropna(subset=['Total Costs'])  # Drop rows where 'Total Costs' is NaN\n","\n","# Create the 'Hospital_Zip' feature\n","df['Hospital_Zip'] = df['Facility Name'].astype(str) + '_' + df['Zip Code - 3 digits'].astype(str)\n","df['Age_Gender'] = df['Age Group'].astype(str) + '_' + df['Gender'].astype(str)\n","df['Race_Ethnicity'] = df['Race'].astype(str) + '_' + df['Ethnicity'].astype(str)\n","\n","def target_encode(train, target, col, alpha=1):\n","    mean_target = train[target].mean()  # Calculate the global mean of the target\n","    counts = train.groupby(col)[target].count()\n","    means = train.groupby(col)[target].mean()\n","\n","    # Apply smoothing\n","    smoothed_means = (counts * means + alpha * mean_target) / (counts + alpha)\n","\n","    return train[col].map(smoothed_means)\n","\n","# Apply target encoding\n","df['Hospital_Zip_encoded'] = target_encode(df, 'Total Costs', 'Hospital_Zip')\n","df['Age_Gender_encoded'] = target_encode(df, 'Total Costs', 'Age_Gender')\n","df['Race_Ethnicity_encoded'] = target_encode(df, 'Total Costs', 'Race_Ethnicity')\n","\n","df = df.drop(columns=['Age_Gender','Race_Ethnicity','Age Group','Hospital_Zip','Gender','Hospital Service Area', 'Hospital County', 'Operating Certificate Number', 'Permanent Facility Id', 'Facility Name', 'Zip Code - 3 digits'\n","                      ])\n","\n","# Apply target encoding and label encoding\n","encoding_columns = ['CCSR Diagnosis Code', 'CCSR Procedure Code', 'APR DRG Code','APR MDC Code','APR Severity of Illness Code','Patient Disposition','Payment Typology 2','Payment Typology 3', 'Birth Weight', 'CCSR Diagnosis Description', 'CCSR Procedure Description', 'APR DRG Description', 'APR MDC Description']\n","for col in encoding_columns:\n","    df[col] = target_encode(df, 'Total Costs', col)\n","\n","# Define new label encoding mappings\n","mappings = {\n","    'APR Severity of Illness Description': {3: 1, 4: 2, 2: 3, 1: 4},\n","    'APR Risk of Mortality': {3: 1, 4: 2, 2: 3, 1: 4},\n","    'APR Medical Surgical Description': {2: 1, 1: 3, 3: 5},\n","    'Emergency Department Indicator': {1: 1, 2: 4}\n","}\n","\n","for col, mapping in mappings.items():\n","    df[col] = df[col].map(mapping)\n","\n","df_encoded = pd.get_dummies(df, columns=['Payment Typology 1'])\n","\n","# Define features (X) and target variable (y)\n","X = df_encoded.drop(columns=['Total Costs'])\n","#print(X.columns)\n","y = df_encoded['Total Costs']\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Standardize features\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_test_scaled = scaler.transform(X_test)\n","\n"],"metadata":{"id":"x9Ev0H-b0qFK"},"id":"x9Ev0H-b0qFK","execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_e_RwbiE5BHY","executionInfo":{"status":"ok","timestamp":1723907651011,"user_tz":0,"elapsed":18582,"user":{"displayName":"Gaurav Meena","userId":"13738632202280078628"}},"outputId":"e832c8c6-c076-4e13-eb9b-663520757b92"},"id":"_e_RwbiE5BHY","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Objective Function obtained on the test set = 12846.032179378994\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.linear_model import Ridge\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.pipeline import Pipeline\n","from sklearn.metrics import mean_squared_error\n","\n","# Load the datasets\n","df_train = pd.read_csv('/content/drive/MyDrive/COL774_AS1/train.csv')\n","df_test = pd.read_csv('/content/drive/MyDrive/COL774_AS1/test.csv')\n","\n","# Define target encoding function\n","def target_encode(train, target, col, alpha=1):\n","    mean_target = train[target].mean()  # Calculate the global mean of the target\n","    counts = train.groupby(col)[target].count()\n","    means = train.groupby(col)[target].mean()\n","\n","    # Apply smoothing\n","    smoothed_means = (counts * means + alpha * mean_target) / (counts + alpha)\n","\n","    return train[col].map(smoothed_means)\n","\n","# Create a dictionary for target encoding during training\n","def create_encoding_dict(train, target_col, trgt_cols, alpha=1):\n","    encoding_dict = {}\n","    mean_target = train[target_col].mean()\n","    for col in trgt_cols:\n","        counts = train.groupby(col)[target_col].count()\n","        means = train.groupby(col)[target_col].mean()\n","        smoothed_means = (counts * means + alpha * mean_target) / (counts + alpha)\n","        encoding_dict[col] = smoothed_means\n","    return encoding_dict\n","\n","# Define preprocessing function\n","def preprocess_data(df, encoding_dict=None, target_col=None):\n","    # Create new features\n","    df['Hospital_Zip'] = df['Facility Name'].astype(str) + '_' + df['Zip Code - 3 digits'].astype(str)\n","    df['Age_Gender'] = df['Age Group'].astype(str) + '_' + df['Gender'].astype(str)\n","    df['Race_Ethnicity'] = df['Race'].astype(str) + '_' + df['Ethnicity'].astype(str)\n","\n","    # Drop unnecessary columns\n","    drop_cols = ['Hospital Service Area', 'Hospital County', 'Operating Certificate Number',\n","                 'Permanent Facility Id', 'Facility Name', 'Zip Code - 3 digits', 'Birth Weight',\n","                 'Age Group', 'Gender', 'Race', 'Ethnicity',\n","                 'Payment Typology 2', 'Payment Typology 3', 'CCSR Diagnosis Description',\n","                 'CCSR Procedure Description', 'APR DRG Description', 'APR MDC Description']\n","\n","    df = df.drop(columns=[col for col in drop_cols if col in df.columns])\n","\n","    # Apply target encoding if target column is provided\n","    trgt_cols = [\n","        'Hospital_Zip', 'Age_Gender', 'Race_Ethnicity', 'CCSR Diagnosis Code', 'CCSR Procedure Code',\n","        'APR DRG Code', 'APR MDC Code', 'APR Severity of Illness Code', 'Patient Disposition',\n","        'Payment Typology 1'\n","    ]\n","\n","    if target_col:\n","        for col in trgt_cols:\n","            if col in df.columns:\n","                df[col] = target_encode(df, target_col, col)\n","            else:\n","                print(f\"Warning: Column {col} not found in training data.\")\n","    else:\n","        # For test data, use encoding from the dictionary\n","        for col in trgt_cols:\n","            if col in df.columns:\n","                if col in encoding_dict:\n","                    df[col] = df[col].map(encoding_dict[col]).fillna(encoding_dict[col].mean())\n","                else:\n","                    df[col] = np.nan\n","\n","    # Apply one-hot encoding\n","    ohot_cols = ['Type of Admission', 'APR Medical Surgical Description', 'Emergency Department Indicator']\n","    df_encoded = pd.get_dummies(df, columns=ohot_cols)\n","\n","    return df_encoded\n","\n","# Preprocess training data to create new features\n","df_train_preprocessed = preprocess_data(df_train, target_col='Total Costs')\n","\n","# Create encoding dictionary from preprocessed training data\n","trgt_cols = [\n","    'Hospital_Zip', 'Age_Gender', 'Race_Ethnicity', 'CCSR Diagnosis Code', 'CCSR Procedure Code',\n","    'APR DRG Code', 'APR MDC Code', 'APR Severity of Illness Code', 'Patient Disposition',\n","    'Payment Typology 1'\n","]\n","encoding_dict = create_encoding_dict(df_train_preprocessed, 'Total Costs', trgt_cols)\n","\n","# Preprocess training data again to apply encoding\n","df_train_encoded = preprocess_data(df_train, encoding_dict=encoding_dict, target_col='Total Costs')\n","X_train = df_train_encoded.drop(columns=['Total Costs'])\n","y_train = df_train_encoded['Total Costs']\n","\n","# Preprocess test data\n","df_test_encoded = preprocess_data(df_test, encoding_dict=encoding_dict)  # No target column for test data\n","\n","# Ensure the test data has the same columns as the training data\n","missing_cols = set(X_train.columns) - set(df_test_encoded.columns)\n","for col in missing_cols:\n","    df_test_encoded[col] = 0  # Add missing columns with default value of 0\n","\n","df_test_encoded = df_test_encoded[X_train.columns]  # Reorder columns to match training set\n","\n","# Standardize the features\n","#scaler = StandardScaler()\n","#X_train_scaled = scaler.fit_transform(X_train)\n","#X_test_scaled = scaler.transform(df_test_encoded)\n","\n","# Train the model\n","model = Ridge()\n","model.fit(X_train, y_train)\n","\n","# Generate predictions\n","Y_pred = model.predict(df_test_encoded)\n","\n","# Load the true values from test_pred.csv\n","df_test_pred = pd.read_csv('/content/drive/MyDrive/COL774_AS1/test_pred.csv')\n","y_true = df_test_pred['Total Costs'].to_numpy()\n","\n","# Check dimensions\n","if Y_pred.shape[0] != y_true.shape[0]:\n","    print(\"Prediction file has wrong dimensions for part c\")\n","else:\n","    # Compute errors\n","    errors = (y_true - Y_pred) ** 2\n","    errors = np.sort(errors)\n","\n","    percentile_value = 90  # Percentage of samples to consider\n","    elements = int(percentile_value * len(errors) / 100)  # Taking the best 90% errors\n","    errors = errors[:elements]\n","\n","    average_square_error = np.mean(errors)  # Average of square errors\n","    rmse = np.sqrt(average_square_error)  # Root Mean Square Error\n","\n","    # Print RMSE\n","    print(\"Objective Function obtained on the test set =\", rmse)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vGmqFtBg6c7P","executionInfo":{"status":"ok","timestamp":1723914913703,"user_tz":0,"elapsed":14374,"user":{"displayName":"Gaurav Meena","userId":"13738632202280078628"}},"outputId":"2fb491e1-db7c-414f-ac85-0bf5134240e9"},"id":"vGmqFtBg6c7P","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Objective Function obtained on the test set = 41456.47243582985\n"]}]},{"cell_type":"code","source":["X_train.to_csv(\"X_train.csv\")\n","y_train.to_csv(\"y_train.csv\")\n","df_test_encoded.to_csv(\"df_test_encoded.csv\")"],"metadata":{"id":"a0m5s-_bN8sW"},"id":"a0m5s-_bN8sW","execution_count":null,"outputs":[]},{"cell_type":"code","source":["import sys\n","import pandas as pd\n","import numpy as np\n","from numpy import linalg\n","import argparse\n","\n","def print_usage():\n","    \"\"\"Print the usage instructions for the script.\"\"\"\n","    print(\"Usage: python linear.py <prob_type a or b> <train_file> <test_file> <sample_weights/regularization> <model_predictions> <model_weights> [<lambda_out>]\")\n","    sys.exit(1)\n","\n","def load_data(train_file_path, test_file_path, input_file_path):\n","    try:\n","        df_train = pd.read_csv(train_file_path)\n","        df_test = pd.read_csv(test_file_path)\n","        df_input = pd.read_csv(input_file_path, header=None, dtype=str)\n","        return df_train, df_test, df_input\n","    except Exception as e:\n","        print(f\"Unexpected error: {e}\")\n","        sys.exit(1)\n","\n","def process_data(input_data, prob_type):\n","    try:\n","        if data is not None:\n","            train, test, input = data\n","            train_nparray = train.to_numpy()\n","            test_nparray = test.to_numpy()\n","            X0 = train_nparray[:, :-1]\n","            X = np.hstack([np.ones((X0.shape[0], 1)), X0 ])\n","            Y = train_nparray[:, -1].reshape(-1, 1)\n","            X_test = np.hstack([np.ones((test_nparray.shape[0], 1)), test_nparray ])\n","\n","            if prob_type == 'a':\n","                input_variables = input.to_numpy().astype(np.float64).flatten()\n","                if len(input_variables) != X0.shape[0]:\n","                    raise ValueError(\"Number of weights must match the number of samples in X\")\n","            else:\n","                input_variables = [float(element) for element in input[0].tolist()]\n","\n","        return X, Y, input_variables, X_test\n","    except Exception as e:\n","        print(f\"Unexpected error in processing: {e}\")\n","        sys.exit(1)\n","\n","def get_lambda(X, Y, lambda_values, num_folds = 10):\n","    fold_size = len(X) // num_folds\n","    indices = np.arange(len(X))\n","    print(\"Lambda values: \", lambda_values)\n","    print(\"Total indices: \",len(indices))\n","\n","    best_lambda = None\n","    lowest_cv_error = float('inf')\n","\n","    for lmbda in lambda_values:\n","        cv_errors = []\n","        for i in range(num_folds):\n","            #print(i*fold_size,(i+1)*fold_size, (i+1)*fold_size-i*fold_size)\n","\n","            test_indices = indices[i*fold_size:(i+1)*fold_size]\n","            train_indices = np.delete(indices, test_indices)\n","\n","            X_train, X_test = X[train_indices], X[test_indices]\n","            Y_train, Y_test = Y[train_indices], Y[test_indices]\n","\n","            I = np.eye(X_train.shape[1])  # Identity matrix for regularization\n","            XTX = X_train.T @ X_train + lmbda * I\n","            XTY = X_train.T @ Y_train\n","\n","            w = linalg.solve(XTX, XTY)\n","\n","            Y_pred = X_test @ w\n","            mse = np.mean((Y_test - Y_pred) ** 2)\n","            cv_errors.append(mse)\n","\n","        #this is for avg, if sum you want, you use np.sum\n","        total_cv_error = np.sum(cv_errors)\n","\n","        if total_cv_error < lowest_cv_error:\n","            lowest_cv_error = total_cv_error\n","            best_lambda = lmbda\n","\n","    return best_lambda\n","\n","def generate_predictions(X_test, w_final, predictions_file, weights_file):\n","    w_final = w_final.reshape(-1, 1)\n","    Y_pred = X_test @ w_final\n","    np.savetxt(weights_file, w_final, delimiter=',', comments='')\n","    print(f\"Weights saved to {weights_file}\")\n","    np.savetxt(predictions_file, Y_pred, delimiter=',', comments='')\n","    print(f\"Predictions saved to {predictions_file}\")\n","\n","\n","def solve_a(processed_data, model_predictions_file, model_weights_file):\n","    X, Y, U, X_test = processed_data\n","    XTUX = X.T @ (X * U.reshape(-1, 1))\n","    XTUY = X.T @ (Y * U.reshape(-1, 1))\n","    weights = np.linalg.solve(XTUX, XTUY)\n","    generate_predictions(X_test, weights, model_predictions_file, model_weights_file)\n","\n","def solve_b(processed_data, model_predictions_file, model_weights_file, best_lambda_file):\n","    X, Y, lembdas, X_test = processed_data\n","    best_lambda = get_lambda(X, Y, lembdas, num_folds=10)\n","    np.savetxt(best_lambda_file, [best_lambda], delimiter=',', comments='')\n","    print(f\"Best Lambda saved to {best_lambda_file}\")\n","\n","    # Train the final model with the best lambda on the entire dataset\n","    I = np.eye(X.shape[1])\n","    XTX_regularised = X.T @ X + best_lambda * I\n","    XTY = X.T @ Y\n","    w_final = linalg.solve(XTX_regularised, XTY)\n","    generate_predictions(X_test, w_final, model_predictions_file, model_weights_file)\n","\n","if __name__ == \"__main__\":\n","    parser = argparse.ArgumentParser(description=\"Process command-line arguments for the script.\")\n","    parser.add_argument('prob_type', type=str, choices=[\"a\", \"b\"], help=\"Problem type\")\n","    parser.add_argument('train_file', type=str, help='Path to the training file.')\n","    parser.add_argument('test_file', type=str, help='Path to the test file.')\n","    parser.add_argument('input_file_1', type=str, help='Path to the either weights or regularization data')\n","    parser.add_argument('prediction_file', type=str, help='Path to the prediction file.')\n","    parser.add_argument('model_out', type=str, help='Path to the model output file.')\n","    parser.add_argument('lambda_out', type=str, nargs='?', default=None, help='Path to the lambda output file (optional).')\n","\n","    args = parser.parse_args()\n","\n","    data = load_data(args.train_file, args.test_file, args.input_file_1)\n","    processed_data = process_data(data, args.prob_type)\n","    if args.prob_type == 'b':\n","        if  args.lambda_out is None:\n","            print(\"Error: For problem type 'b', <lambda_out> is required.\")\n","            print_usage()\n","        solve_b(processed_data, args.prediction_file, args.model_out, args.lambda_out)\n","    elif args.prob_type == 'a':\n","        solve_a(processed_data, args.prediction_file, args.model_out)\n","    else:\n","        print(\"Error: Incorrect arguments.\")\n","        print_usage()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y2pZK1soAB_E","executionInfo":{"status":"ok","timestamp":1723913243038,"user_tz":0,"elapsed":6525,"user":{"displayName":"Gaurav Meena","userId":"13738632202280078628"}},"outputId":"8b35b16e-7954-4697-e9b6-6c6a2a64ec29"},"id":"y2pZK1soAB_E","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Objective Function obtained on the test set = 24490.48552848473\n"]}]},{"cell_type":"code","source":["out_inp = sys.argv[1]\n","weight_inp = sys.argv[2]\n","out_model = sys.argv[3]\n","weight_model = sys.argv[4]\n","\n","\n","\n","Train_file_path = 'train.csv'\n","Lamda_file_path = 'regularization.txt'\n","Weights1_file_path = 'sample_weights1.txt'\n","Weights2_file_path = 'sample_weights2.txt'\n","\n","#Read Training file, weights file\n","df_train  = pd.read_csv(Train_file_path)\n","df_W1     = pd.read_csv(Weights1_file_path, delimiter='\\t', header=None, dtype=str)\n","df_W2     = pd.read_csv(Weights2_file_path, delimiter='\\t', header=None, dtype=str)\n","df_lambda = pd.read_csv(Lamda_file_path, header=None)\n","\n","\n","#Get Numpy array, X0 without bias values, X with ones for bias, X^T and Y from the File\n","numpy_array = df_train.to_numpy()\n","X0 = numpy_array[:, :-1]\n","X = np.hstack([np.ones((X0.shape[0], 1)), X0 ])\n","X_T = X.T\n","Y = numpy_array[:, -1].reshape(-1, 1)\n","\n","\n","U = df_W1.to_numpy().astype(np.float64).flatten()\n","print(\"Shapes: X0, U: \", X0.shape[0], len(U))\n","if len(U) != X0.shape[0]:\n","    raise ValueError(\"Number of weights must match the number of samples in X\")\n","\n","XTUX = np.zeros((X.shape[1], X.shape[1]))\n","XTUY = np.zeros((X.shape[1], 1))\n","\n","for i in range(X.shape[0]):\n","    ui = U[i]\n","    x_i = X[i, :].reshape(-1, 1)\n","    XTUX += ui * (x_i @ x_i.T)\n","    XTUY += ui * x_i @ Y[i, :].reshape(-1, 1)\n","\n","weights = np.linalg.solve(XTUX, XTUY)\n","\n","#print(weights)"],"metadata":{"id":"HURrpl1aAxxe"},"id":"HURrpl1aAxxe","execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"YvU9hQ5wA_xm"},"id":"YvU9hQ5wA_xm","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}