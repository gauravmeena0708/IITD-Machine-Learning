{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision.transforms as transforms\nfrom torchvision.datasets import FashionMNIST\nfrom torch.utils.data import DataLoader\nimport torch.nn.functional as F\nfrom tqdm import tqdm\nimport pandas as pd\nfrom tabulate import tabulate\n\n# Hyperparameters\nbatch_size = 64\nlearning_rate = 0.001\nnum_epochs = 2\nconfidence_margin = 0.2\nabsolute_confidence_threshold = 0.9\nunconfident_penalty = 5.0\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Transformations with data augmentation and normalization\ntransform = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomCrop(28, padding=4),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5,), (0.5,))\n])\n\n# Load FashionMNIST dataset\ntrain_dataset = FashionMNIST(root=\"./data\", train=True, transform=transform, download=True)\ntest_dataset = FashionMNIST(root=\"./data\", train=False, transform=transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.5,), (0.5,))\n]), download=True)\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\nactual_labels = []\nfor _, labels in test_loader:\n    actual_labels.extend(labels.numpy())\nactual_labels = list(map(int, actual_labels))\n\n\n# Define a CNN model with batch normalization and dropout\nclass HighConfidenceFashionCNN(nn.Module):\n    def __init__(self):\n        super(HighConfidenceFashionCNN, self).__init__()\n        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n        self.bn1 = nn.BatchNorm2d(32)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n        self.bn2 = nn.BatchNorm2d(64)\n        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n        self.bn3 = nn.BatchNorm2d(128)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.fc1 = nn.Linear(128 * 3 * 3, 256)\n        self.dropout1 = nn.Dropout(0.4)\n        self.fc2 = nn.Linear(256, 128)\n        self.dropout2 = nn.Dropout(0.4)\n        self.fc3 = nn.Linear(128, 10)  # 10 classes\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n        x = x.view(-1, 128 * 3 * 3)\n        x = F.relu(self.fc1(x))\n        x = self.dropout1(x)\n        x = F.relu(self.fc2(x))\n        x = self.dropout2(x)\n        x = self.fc3(x)\n        return x\n\nmodel = HighConfidenceFashionCNN().to(device)\n\n# Optimizer and learning rate scheduler\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)\nscheduler = torch.optim.lr_scheduler.OneCycleLR(\n    optimizer, max_lr=0.01, steps_per_epoch=len(train_loader), epochs=num_epochs, anneal_strategy=\"linear\"\n)\n\n# Improved loss function to further prioritize high-confidence predictions\ndef custom_loss(outputs, labels, confidence_margin=0.2):\n    base_loss = F.cross_entropy(outputs, labels, reduction='none')\n    probs = F.softmax(outputs, dim=1)\n    top2_probs, _ = torch.topk(probs, 2, dim=1)\n    top_class_prob = top2_probs[:, 0]\n    second_class_prob = top2_probs[:, 1]\n    \n    confidence_penalty = torch.where(\n        (top_class_prob - second_class_prob) < confidence_margin,\n        unconfident_penalty * ((confidence_margin - (top_class_prob - second_class_prob)) ** 2),\n        torch.zeros_like(base_loss)\n    )\n\n    # Combine base loss and confidence penalty\n    loss = base_loss + confidence_penalty\n    return loss.mean()\n\ndef calculate_accuracy(model, loader):\n    model.eval()\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for images, labels in loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            _, predicted = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    accuracy = 100 * correct / total\n    return accuracy\n\n\n# Training function without progress bar\ndef train(model, loader, optimizer, epoch, max_epochs):\n    model.train()\n    total_loss = 0.0\n    \n    # Gradually increase the confidence margin as the model improves\n    dynamic_confidence_margin = 0.2 + 0.01 * (epoch / max_epochs)\n    \n    for images, labels in loader:\n        images, labels = images.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = custom_loss(outputs, labels, confidence_margin=dynamic_confidence_margin)\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n\n    return total_loss / len(loader)\n\n\n\n\n\n\n\n# Evaluation function to generate predictions DataFrame\ndef evaluate_with_temperature(model, loader, temperature=1.0):\n    model.eval()\n    sample_ids = []\n    predicted_labels = []\n\n    with torch.no_grad():\n        for batch_idx, (images, labels) in enumerate(loader):\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            \n            # Apply temperature scaling\n            outputs = outputs / temperature\n            probs = F.softmax(outputs, dim=1)  # Get probabilities with temperature scaling\n            \n            # Get top 2 predictions for each sample\n            top2_probs, top2_classes = torch.topk(probs, 2, dim=1)\n\n            for i in range(len(labels)):\n                sample_id = batch_idx * batch_size + i\n                top_class_prob = top2_probs[i][0].item()\n                second_class_prob = top2_probs[i][1].item()\n                \n                # Determine if the prediction is confident enough based on threshold\n                if (top_class_prob - second_class_prob) >= confidence_margin and top_class_prob >= absolute_confidence_threshold:\n                    predicted_class = top2_classes[i][0].item()\n                else:\n                    predicted_class = -1  # Predict -1 for unconfident\n\n                # Append to results\n                sample_ids.append(sample_id)\n                predicted_labels.append(predicted_class)\n\n    # Return IDs and predictions\n    return sample_ids, predicted_labels\n\n\n\ndef calculate_summary(actual_labels, predicted_labels, confidence_threshold=0.90):\n    # Determine the number of classes dynamically\n    classes = sorted(set(actual_labels) - {-1})\n    num_classes = len(classes)\n\n    # Initialize summary data\n    class_counts = {cls: 0 for cls in classes}\n    predictions_made = {cls: 0 for cls in classes}\n    correct_predictions = {cls: 0 for cls in classes}\n    unconfident_predictions = {cls: 0 for cls in classes}\n    \n    # Additional thresholds for score calculation\n    thresholds = [0.90, 0.95, 0.99]\n    scores_for_thresholds = {f\"Score_{threshold}\": {cls: 0 for cls in classes} for threshold in thresholds}\n    scores_for_thresholds[\"Score_Contribution\"] = {cls: 0 for cls in classes}  # Custom threshold score\n\n    # Process each prediction\n    for actual, predicted in zip(actual_labels, predicted_labels):\n        class_counts[actual] += 1\n        if predicted == actual:\n            correct_predictions[actual] += 1\n        if predicted == -1:\n            unconfident_predictions[actual] += 1\n        elif predicted in classes:\n            predictions_made[predicted] += 1\n    \n    # Calculate accuracy and score contribution for each class and each threshold\n    data = []\n    for cls in classes:\n        if predictions_made[cls] > 0:\n            accuracy = correct_predictions[cls] / predictions_made[cls]\n        else:\n            accuracy = 0\n\n        # Calculate score contributions for each threshold\n        score_contributions = {}\n        for threshold in thresholds:\n            if accuracy >= threshold:\n                score_contribution = correct_predictions[cls]\n            else:\n                score_contribution = -2 * predictions_made[cls]\n            score_contributions[f\"Score_{threshold}\"] = score_contribution\n\n        # Calculate score contribution for the custom threshold\n        if accuracy >= confidence_threshold:\n            score_contribution = correct_predictions[cls]\n        else:\n            score_contribution = -2 * predictions_made[cls]\n\n        # Append the row to data with all calculated values\n        data.append({\n            \"Class\": cls,\n            \"Actual\": class_counts[cls],\n            \"Predicted\": predictions_made[cls],\n            \"Correct\": correct_predictions[cls],\n            \"Incorrect\": predictions_made[cls] - correct_predictions[cls],\n            \"Unconfident (-1)\": unconfident_predictions[cls],\n            \"Accuracy\": accuracy,\n            \"Score_Contribution\": score_contribution,  # Custom threshold column\n            **score_contributions  # Add other threshold score columns dynamically\n        })\n\n    # Create a summary DataFrame with scores for each threshold\n    summary_df = pd.DataFrame(data)\n\n    # Calculate totals for each relevant column\n    total_row = {\n        \"Class\": \"Total\",\n        \"Actual\": sum(class_counts.values()),\n        \"Predicted\": sum(predictions_made.values()),\n        \"Correct\": sum(correct_predictions.values()),\n        \"Incorrect\": sum(predictions_made.values()) - sum(correct_predictions.values()),\n        \"Unconfident (-1)\": sum(unconfident_predictions.values()),\n        \"Accuracy\": \"\",  # Leave Accuracy empty in the total row\n        \"Score_Contribution\": summary_df[\"Score_Contribution\"].sum(),  # Custom threshold total\n    }\n\n    # Add totals for each additional score threshold\n    for threshold in thresholds:\n        total_row[f\"Score_{threshold}\"] = summary_df[f\"Score_{threshold}\"].sum()\n\n    # Convert total_row to DataFrame and use pd.concat to add it to summary_df\n    total_df = pd.DataFrame([total_row])\n    summary_df = pd.concat([summary_df, total_df], ignore_index=True)\n\n    return summary_df\n\n\n\n\n\nnum_epochs = 10\nfor epoch in range(num_epochs):\n    avg_train_loss = train(model, train_loader, optimizer, epoch, num_epochs)\n    overall_accuracy = calculate_accuracy(model, test_loader)\n    print(f\"Epoch [{epoch+1}/{num_epochs}], Average Training Loss: {avg_train_loss:.4f}, Overall Test Accuracy: {overall_accuracy:.2f}%\")\n\n    # Evaluate and print summary every 10 epochs\n    if epoch >= num_epochs - 10 or epoch % 10 == 0:\n        sample_ids, predicted_labels = evaluate_with_temperature(model, test_loader, temperature=temperature)\n        summary_df = calculate_summary(actual_labels, predicted_labels, confidence_threshold=0.99)\n        print(f\"\\nSummary for Confidence Threshold 0.99 - Epoch {epoch+1}\")\n        print(tabulate(summary_df, headers='keys', tablefmt='fancy_grid'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T05:07:33.082858Z","iopub.execute_input":"2024-11-06T05:07:33.083288Z"}},"outputs":[{"name":"stdout","text":"Epoch [1/10], Average Training Loss: 0.8311\nEpoch [1/10], Overall Test Accuracy: 81.59%\n\nSummary for Confidence Threshold 0.99 - Epoch 1\n╒════╤═════════╤══════════╤═════════════╤═══════════╤═════════════╤════════════════════╤════════════╤══════════════════════╤═════════════╤══════════════╤══════════════╕\n│    │ Class   │   Actual │   Predicted │   Correct │   Incorrect │   Unconfident (-1) │ Accuracy   │   Score_Contribution │   Score_0.9 │   Score_0.95 │   Score_0.99 │\n╞════╪═════════╪══════════╪═════════════╪═══════════╪═════════════╪════════════════════╪════════════╪══════════════════════╪═════════════╪══════════════╪══════════════╡\n│  0 │ 0       │     1000 │           0 │         0 │           0 │               1000 │ 0.0        │                    0 │           0 │            0 │            0 │\n├────┼─────────┼──────────┼─────────────┼───────────┼─────────────┼────────────────────┼────────────┼──────────────────────┼─────────────┼──────────────┼──────────────┤\n│  1 │ 1       │     1000 │         835 │       835 │           0 │                165 │ 1.0        │                  835 │         835 │          835 │          835 │\n├────┼─────────┼──────────┼─────────────┼───────────┼─────────────┼────────────────────┼────────────┼──────────────────────┼─────────────┼──────────────┼──────────────┤\n│  2 │ 2       │     1000 │           0 │         0 │           0 │               1000 │ 0.0        │                    0 │           0 │            0 │            0 │\n├────┼─────────┼──────────┼─────────────┼───────────┼─────────────┼────────────────────┼────────────┼──────────────────────┼─────────────┼──────────────┼──────────────┤\n│  3 │ 3       │     1000 │          12 │        12 │           0 │                988 │ 1.0        │                   12 │          12 │           12 │           12 │\n├────┼─────────┼──────────┼─────────────┼───────────┼─────────────┼────────────────────┼────────────┼──────────────────────┼─────────────┼──────────────┼──────────────┤\n│  4 │ 4       │     1000 │           0 │         0 │           0 │               1000 │ 0.0        │                    0 │           0 │            0 │            0 │\n├────┼─────────┼──────────┼─────────────┼───────────┼─────────────┼────────────────────┼────────────┼──────────────────────┼─────────────┼──────────────┼──────────────┤\n│  5 │ 5       │     1000 │         355 │       355 │           0 │                645 │ 1.0        │                  355 │         355 │          355 │          355 │\n├────┼─────────┼──────────┼─────────────┼───────────┼─────────────┼────────────────────┼────────────┼──────────────────────┼─────────────┼──────────────┼──────────────┤\n│  6 │ 6       │     1000 │           0 │         0 │           0 │               1000 │ 0.0        │                    0 │           0 │            0 │            0 │\n├────┼─────────┼──────────┼─────────────┼───────────┼─────────────┼────────────────────┼────────────┼──────────────────────┼─────────────┼──────────────┼──────────────┤\n│  7 │ 7       │     1000 │          93 │        93 │           0 │                907 │ 1.0        │                   93 │          93 │           93 │           93 │\n├────┼─────────┼──────────┼─────────────┼───────────┼─────────────┼────────────────────┼────────────┼──────────────────────┼─────────────┼──────────────┼──────────────┤\n│  8 │ 8       │     1000 │         633 │       633 │           0 │                367 │ 1.0        │                  633 │         633 │          633 │          633 │\n├────┼─────────┼──────────┼─────────────┼───────────┼─────────────┼────────────────────┼────────────┼──────────────────────┼─────────────┼──────────────┼──────────────┤\n│  9 │ 9       │     1000 │         223 │       223 │           0 │                777 │ 1.0        │                  223 │         223 │          223 │          223 │\n├────┼─────────┼──────────┼─────────────┼───────────┼─────────────┼────────────────────┼────────────┼──────────────────────┼─────────────┼──────────────┼──────────────┤\n│ 10 │ Total   │    10000 │        2151 │      2151 │           0 │               7849 │            │                 2151 │        2151 │         2151 │         2151 │\n╘════╧═════════╧══════════╧═════════════╧═══════════╧═════════════╧════════════════════╧════════════╧══════════════════════╧═════════════╧══════════════╧══════════════╛\nEpoch [2/10], Average Training Loss: 0.5238\nEpoch [2/10], Overall Test Accuracy: 84.44%\n\nSummary for Confidence Threshold 0.99 - Epoch 2\n╒════╤═════════╤══════════╤═════════════╤═══════════╤═════════════╤════════════════════╤════════════════════╤══════════════════════╤═════════════╤══════════════╤══════════════╕\n│    │ Class   │   Actual │   Predicted │   Correct │   Incorrect │   Unconfident (-1) │ Accuracy           │   Score_Contribution │   Score_0.9 │   Score_0.95 │   Score_0.99 │\n╞════╪═════════╪══════════╪═════════════╪═══════════╪═════════════╪════════════════════╪════════════════════╪══════════════════════╪═════════════╪══════════════╪══════════════╡\n│  0 │ 0       │     1000 │           0 │         0 │           0 │                999 │ 0.0                │                    0 │           0 │            0 │            0 │\n├────┼─────────┼──────────┼─────────────┼───────────┼─────────────┼────────────────────┼────────────────────┼──────────────────────┼─────────────┼──────────────┼──────────────┤\n│  1 │ 1       │     1000 │         902 │       902 │           0 │                 98 │ 1.0                │                  902 │         902 │          902 │          902 │\n├────┼─────────┼──────────┼─────────────┼───────────┼─────────────┼────────────────────┼────────────────────┼──────────────────────┼─────────────┼──────────────┼──────────────┤\n│  2 │ 2       │     1000 │          31 │        31 │           0 │                969 │ 1.0                │                   31 │          31 │           31 │           31 │\n├────┼─────────┼──────────┼─────────────┼───────────┼─────────────┼────────────────────┼────────────────────┼──────────────────────┼─────────────┼──────────────┼──────────────┤\n│  3 │ 3       │     1000 │          18 │        18 │           0 │                982 │ 1.0                │                   18 │          18 │           18 │           18 │\n├────┼─────────┼──────────┼─────────────┼───────────┼─────────────┼────────────────────┼────────────────────┼──────────────────────┼─────────────┼──────────────┼──────────────┤\n│  4 │ 4       │     1000 │           0 │         0 │           0 │               1000 │ 0.0                │                    0 │           0 │            0 │            0 │\n├────┼─────────┼──────────┼─────────────┼───────────┼─────────────┼────────────────────┼────────────────────┼──────────────────────┼─────────────┼──────────────┼──────────────┤\n│  5 │ 5       │     1000 │         648 │       644 │           4 │                356 │ 0.9938271604938271 │                  644 │         644 │          644 │          644 │\n├────┼─────────┼──────────┼─────────────┼───────────┼─────────────┼────────────────────┼────────────────────┼──────────────────────┼─────────────┼──────────────┼──────────────┤\n│  6 │ 6       │     1000 │           0 │         0 │           0 │               1000 │ 0.0                │                    0 │           0 │            0 │            0 │\n├────┼─────────┼──────────┼─────────────┼───────────┼─────────────┼────────────────────┼────────────────────┼──────────────────────┼─────────────┼──────────────┼──────────────┤\n│  7 │ 7       │     1000 │          87 │        87 │           0 │                912 │ 1.0                │                   87 │          87 │           87 │           87 │\n├────┼─────────┼──────────┼─────────────┼───────────┼─────────────┼────────────────────┼────────────────────┼──────────────────────┼─────────────┼──────────────┼──────────────┤\n│  8 │ 8       │     1000 │         648 │       648 │           0 │                352 │ 1.0                │                  648 │         648 │          648 │          648 │\n├────┼─────────┼──────────┼─────────────┼───────────┼─────────────┼────────────────────┼────────────────────┼──────────────────────┼─────────────┼──────────────┼──────────────┤\n│  9 │ 9       │     1000 │          78 │        78 │           0 │                920 │ 1.0                │                   78 │          78 │           78 │           78 │\n├────┼─────────┼──────────┼─────────────┼───────────┼─────────────┼────────────────────┼────────────────────┼──────────────────────┼─────────────┼──────────────┼──────────────┤\n│ 10 │ Total   │    10000 │        2412 │      2408 │           4 │               7588 │                    │                 2408 │        2408 │         2408 │         2408 │\n╘════╧═════════╧══════════╧═════════════╧═══════════╧═════════════╧════════════════════╧════════════════════╧══════════════════════╧═════════════╧══════════════╧══════════════╛\nEpoch [3/10], Average Training Loss: 0.4523\nEpoch [3/10], Overall Test Accuracy: 87.25%\n\nSummary for Confidence Threshold 0.99 - Epoch 3\n╒════╤═════════╤══════════╤═════════════╤═══════════╤═════════════╤════════════════════╤════════════════════╤══════════════════════╤═════════════╤══════════════╤══════════════╕\n│    │ Class   │   Actual │   Predicted │   Correct │   Incorrect │   Unconfident (-1) │ Accuracy           │   Score_Contribution │   Score_0.9 │   Score_0.95 │   Score_0.99 │\n╞════╪═════════╪══════════╪═════════════╪═══════════╪═════════════╪════════════════════╪════════════════════╪══════════════════════╪═════════════╪══════════════╪══════════════╡\n│  0 │ 0       │     1000 │           1 │         1 │           0 │                997 │ 1.0                │                    1 │           1 │            1 │            1 │\n├────┼─────────┼──────────┼─────────────┼───────────┼─────────────┼────────────────────┼────────────────────┼──────────────────────┼─────────────┼──────────────┼──────────────┤\n│  1 │ 1       │     1000 │         901 │       901 │           0 │                 98 │ 1.0                │                  901 │         901 │          901 │          901 │\n├────┼─────────┼──────────┼─────────────┼───────────┼─────────────┼────────────────────┼────────────────────┼──────────────────────┼─────────────┼──────────────┼──────────────┤\n│  2 │ 2       │     1000 │           7 │         7 │           0 │                993 │ 1.0                │                    7 │           7 │            7 │            7 │\n├────┼─────────┼──────────┼─────────────┼───────────┼─────────────┼────────────────────┼────────────────────┼──────────────────────┼─────────────┼──────────────┼──────────────┤\n│  3 │ 3       │     1000 │         280 │       276 │           4 │                724 │ 0.9857142857142858 │                 -560 │         276 │          276 │         -560 │\n├────┼─────────┼──────────┼─────────────┼───────────┼─────────────┼────────────────────┼────────────────────┼──────────────────────┼─────────────┼──────────────┼──────────────┤\n│  4 │ 4       │     1000 │           0 │         0 │           0 │                999 │ 0.0                │                    0 │           0 │            0 │            0 │\n├────┼─────────┼──────────┼─────────────┼───────────┼─────────────┼────────────────────┼────────────────────┼──────────────────────┼─────────────┼──────────────┼──────────────┤\n│  5 │ 5       │     1000 │         521 │       521 │           0 │                477 │ 1.0                │                  521 │         521 │          521 │          521 │\n├────┼─────────┼──────────┼─────────────┼───────────┼─────────────┼────────────────────┼────────────────────┼──────────────────────┼─────────────┼──────────────┼──────────────┤\n│  6 │ 6       │     1000 │           0 │         0 │           0 │               1000 │ 0.0                │                    0 │           0 │            0 │            0 │\n├────┼─────────┼──────────┼─────────────┼───────────┼─────────────┼────────────────────┼────────────────────┼──────────────────────┼─────────────┼──────────────┼──────────────┤\n│  7 │ 7       │     1000 │         442 │       440 │           2 │                560 │ 0.995475113122172  │                  440 │         440 │          440 │          440 │\n├────┼─────────┼──────────┼─────────────┼───────────┼─────────────┼────────────────────┼────────────────────┼──────────────────────┼─────────────┼──────────────┼──────────────┤\n│  8 │ 8       │     1000 │         799 │       799 │           0 │                201 │ 1.0                │                  799 │         799 │          799 │          799 │\n├────┼─────────┼──────────┼─────────────┼───────────┼─────────────┼────────────────────┼────────────────────┼──────────────────────┼─────────────┼──────────────┼──────────────┤\n│  9 │ 9       │     1000 │         371 │       371 │           0 │                629 │ 1.0                │                  371 │         371 │          371 │          371 │\n├────┼─────────┼──────────┼─────────────┼───────────┼─────────────┼────────────────────┼────────────────────┼──────────────────────┼─────────────┼──────────────┼──────────────┤\n│ 10 │ Total   │    10000 │        3322 │      3316 │           6 │               6678 │                    │                 2480 │        3316 │         3316 │         2480 │\n╘════╧═════════╧══════════╧═════════════╧═══════════╧═════════════╧════════════════════╧════════════════════╧══════════════════════╧═════════════╧══════════════╧══════════════╛\nEpoch [4/10], Average Training Loss: 0.4186\nEpoch [4/10], Overall Test Accuracy: 87.54%\n\nSummary for Confidence Threshold 0.99 - Epoch 4\n╒════╤═════════╤══════════╤═════════════╤═══════════╤═════════════╤════════════════════╤════════════════════╤══════════════════════╤═════════════╤══════════════╤══════════════╕\n│    │ Class   │   Actual │   Predicted │   Correct │   Incorrect │   Unconfident (-1) │ Accuracy           │   Score_Contribution │   Score_0.9 │   Score_0.95 │   Score_0.99 │\n╞════╪═════════╪══════════╪═════════════╪═══════════╪═════════════╪════════════════════╪════════════════════╪══════════════════════╪═════════════╪══════════════╪══════════════╡\n│  0 │ 0       │     1000 │          21 │        21 │           0 │                977 │ 1.0                │                   21 │          21 │           21 │           21 │\n├────┼─────────┼──────────┼─────────────┼───────────┼─────────────┼────────────────────┼────────────────────┼──────────────────────┼─────────────┼──────────────┼──────────────┤\n│  1 │ 1       │     1000 │         943 │       942 │           1 │                 57 │ 0.9989395546129375 │                  942 │         942 │          942 │          942 │\n├────┼─────────┼──────────┼─────────────┼───────────┼─────────────┼────────────────────┼────────────────────┼──────────────────────┼─────────────┼──────────────┼──────────────┤\n│  2 │ 2       │     1000 │          83 │        83 │           0 │                917 │ 1.0                │                   83 │          83 │           83 │           83 │\n├────┼─────────┼──────────┼─────────────┼───────────┼─────────────┼────────────────────┼────────────────────┼──────────────────────┼─────────────┼──────────────┼──────────────┤\n│  3 │ 3       │     1000 │         173 │       170 │           3 │                829 │ 0.9826589595375722 │                 -346 │         170 │          170 │         -346 │\n├────┼─────────┼──────────┼─────────────┼───────────┼─────────────┼────────────────────┼────────────────────┼──────────────────────┼─────────────┼──────────────┼──────────────┤\n│  4 │ 4       │     1000 │           0 │         0 │           0 │               1000 │ 0.0                │                    0 │           0 │            0 │            0 │\n├────┼─────────┼──────────┼─────────────┼───────────┼─────────────┼────────────────────┼────────────────────┼──────────────────────┼─────────────┼──────────────┼──────────────┤\n│  5 │ 5       │     1000 │         813 │       809 │           4 │                191 │ 0.995079950799508  │                  809 │         809 │          809 │          809 │\n├────┼─────────┼──────────┼─────────────┼───────────┼─────────────┼────────────────────┼────────────────────┼──────────────────────┼─────────────┼──────────────┼──────────────┤\n│  6 │ 6       │     1000 │           0 │         0 │           0 │               1000 │ 0.0                │                    0 │           0 │            0 │            0 │\n├────┼─────────┼──────────┼─────────────┼───────────┼─────────────┼────────────────────┼────────────────────┼──────────────────────┼─────────────┼──────────────┼──────────────┤\n│  7 │ 7       │     1000 │         337 │       337 │           0 │                660 │ 1.0                │                  337 │         337 │          337 │          337 │\n├────┼─────────┼──────────┼─────────────┼───────────┼─────────────┼────────────────────┼────────────────────┼──────────────────────┼─────────────┼──────────────┼──────────────┤\n│  8 │ 8       │     1000 │         863 │       863 │           0 │                137 │ 1.0                │                  863 │         863 │          863 │          863 │\n├────┼─────────┼──────────┼─────────────┼───────────┼─────────────┼────────────────────┼────────────────────┼──────────────────────┼─────────────┼──────────────┼──────────────┤\n│  9 │ 9       │     1000 │         497 │       496 │           1 │                502 │ 0.9979879275653923 │                  496 │         496 │          496 │          496 │\n├────┼─────────┼──────────┼─────────────┼───────────┼─────────────┼────────────────────┼────────────────────┼──────────────────────┼─────────────┼──────────────┼──────────────┤\n│ 10 │ Total   │    10000 │        3730 │      3721 │           9 │               6270 │                    │                 3205 │        3721 │         3721 │         3205 │\n╘════╧═════════╧══════════╧═════════════╧═══════════╧═════════════╧════════════════════╧════════════════════╧══════════════════════╧═════════════╧══════════════╧══════════════╛\nEpoch [5/10], Average Training Loss: 0.3871\nEpoch [5/10], Overall Test Accuracy: 87.97%\n\nSummary for Confidence Threshold 0.99 - Epoch 5\n╒════╤═════════╤══════════╤═════════════╤═══════════╤═════════════╤════════════════════╤════════════════════╤══════════════════════╤═════════════╤══════════════╤══════════════╕\n│    │ Class   │   Actual │   Predicted │   Correct │   Incorrect │   Unconfident (-1) │ Accuracy           │   Score_Contribution │   Score_0.9 │   Score_0.95 │   Score_0.99 │\n╞════╪═════════╪══════════╪═════════════╪═══════════╪═════════════╪════════════════════╪════════════════════╪══════════════════════╪═════════════╪══════════════╪══════════════╡\n│  0 │ 0       │     1000 │         239 │       236 │           3 │                762 │ 0.9874476987447699 │                 -478 │         236 │          236 │         -478 │\n├────┼─────────┼──────────┼─────────────┼───────────┼─────────────┼────────────────────┼────────────────────┼──────────────────────┼─────────────┼──────────────┼──────────────┤\n│  1 │ 1       │     1000 │         938 │       937 │           1 │                 62 │ 0.9989339019189766 │                  937 │         937 │          937 │          937 │\n├────┼─────────┼──────────┼─────────────┼───────────┼─────────────┼────────────────────┼────────────────────┼──────────────────────┼─────────────┼──────────────┼──────────────┤\n│  2 │ 2       │     1000 │         298 │       293 │           5 │                707 │ 0.9832214765100671 │                 -596 │         293 │          293 │         -596 │\n├────┼─────────┼──────────┼─────────────┼───────────┼─────────────┼────────────────────┼────────────────────┼──────────────────────┼─────────────┼──────────────┼──────────────┤\n│  3 │ 3       │     1000 │         140 │       138 │           2 │                861 │ 0.9857142857142858 │                 -280 │         138 │          138 │         -280 │\n├────┼─────────┼──────────┼─────────────┼───────────┼─────────────┼────────────────────┼────────────────────┼──────────────────────┼─────────────┼──────────────┼──────────────┤\n│  4 │ 4       │     1000 │           1 │         1 │           0 │                998 │ 1.0                │                    1 │           1 │            1 │            1 │\n├────┼─────────┼──────────┼─────────────┼───────────┼─────────────┼────────────────────┼────────────────────┼──────────────────────┼─────────────┼──────────────┼──────────────┤\n│  5 │ 5       │     1000 │         697 │       696 │           1 │                297 │ 0.9985652797704447 │                  696 │         696 │          696 │          696 │\n├────┼─────────┼──────────┼─────────────┼───────────┼─────────────┼────────────────────┼────────────────────┼──────────────────────┼─────────────┼──────────────┼──────────────┤\n│  6 │ 6       │     1000 │           2 │         2 │           0 │                990 │ 1.0                │                    2 │           2 │            2 │            2 │\n├────┼─────────┼──────────┼─────────────┼───────────┼─────────────┼────────────────────┼────────────────────┼──────────────────────┼─────────────┼──────────────┼──────────────┤\n│  7 │ 7       │     1000 │         686 │       678 │           8 │                321 │ 0.9883381924198251 │                -1372 │         678 │          678 │        -1372 │\n├────┼─────────┼──────────┼─────────────┼───────────┼─────────────┼────────────────────┼────────────────────┼──────────────────────┼─────────────┼──────────────┼──────────────┤\n│  8 │ 8       │     1000 │         877 │       876 │           1 │                124 │ 0.9988597491448119 │                  876 │         876 │          876 │          876 │\n├────┼─────────┼──────────┼─────────────┼───────────┼─────────────┼────────────────────┼────────────────────┼──────────────────────┼─────────────┼──────────────┼──────────────┤\n│  9 │ 9       │     1000 │         565 │       564 │           1 │                435 │ 0.9982300884955753 │                  564 │         564 │          564 │          564 │\n├────┼─────────┼──────────┼─────────────┼───────────┼─────────────┼────────────────────┼────────────────────┼──────────────────────┼─────────────┼──────────────┼──────────────┤\n│ 10 │ Total   │    10000 │        4443 │      4421 │          22 │               5557 │                    │                  350 │        4421 │         4421 │          350 │\n╘════╧═════════╧══════════╧═════════════╧═══════════╧═════════════╧════════════════════╧════════════════════╧══════════════════════╧═════════════╧══════════════╧══════════════╛\nEpoch [6/10], Average Training Loss: 0.3713\nEpoch [6/10], Overall Test Accuracy: 88.72%\n\nSummary for Confidence Threshold 0.99 - Epoch 6\n╒════╤═════════╤══════════╤═════════════╤═══════════╤═════════════╤════════════════════╤════════════════════╤══════════════════════╤═════════════╤══════════════╤══════════════╕\n│    │ Class   │   Actual │   Predicted │   Correct │   Incorrect │   Unconfident (-1) │ Accuracy           │   Score_Contribution │   Score_0.9 │   Score_0.95 │   Score_0.99 │\n╞════╪═════════╪══════════╪═════════════╪═══════════╪═════════════╪════════════════════╪════════════════════╪══════════════════════╪═════════════╪══════════════╪══════════════╡\n│  0 │ 0       │     1000 │          52 │        52 │           0 │                948 │ 1.0                │                   52 │          52 │           52 │           52 │\n├────┼─────────┼──────────┼─────────────┼───────────┼─────────────┼────────────────────┼────────────────────┼──────────────────────┼─────────────┼──────────────┼──────────────┤\n│  1 │ 1       │     1000 │         933 │       933 │           0 │                 66 │ 1.0                │                  933 │         933 │          933 │          933 │\n├────┼─────────┼──────────┼─────────────┼───────────┼─────────────┼────────────────────┼────────────────────┼──────────────────────┼─────────────┼──────────────┼──────────────┤\n│  2 │ 2       │     1000 │         177 │       175 │           2 │                825 │ 0.9887005649717514 │                 -354 │         175 │          175 │         -354 │\n├────┼─────────┼──────────┼─────────────┼───────────┼─────────────┼────────────────────┼────────────────────┼──────────────────────┼─────────────┼──────────────┼──────────────┤\n│  3 │ 3       │     1000 │         136 │       135 │           1 │                865 │ 0.9926470588235294 │                  135 │         135 │          135 │          135 │\n├────┼─────────┼──────────┼─────────────┼───────────┼─────────────┼────────────────────┼────────────────────┼──────────────────────┼─────────────┼──────────────┼──────────────┤\n│  4 │ 4       │     1000 │           6 │         6 │           0 │                994 │ 1.0                │                    6 │           6 │            6 │            6 │\n├────┼─────────┼──────────┼─────────────┼───────────┼─────────────┼────────────────────┼────────────────────┼──────────────────────┼─────────────┼──────────────┼──────────────┤\n│  5 │ 5       │     1000 │         597 │       597 │           0 │                403 │ 1.0                │                  597 │         597 │          597 │          597 │\n├────┼─────────┼──────────┼─────────────┼───────────┼─────────────┼────────────────────┼────────────────────┼──────────────────────┼─────────────┼──────────────┼──────────────┤\n│  6 │ 6       │     1000 │           0 │         0 │           0 │                998 │ 0.0                │                    0 │           0 │            0 │            0 │\n├────┼─────────┼──────────┼─────────────┼───────────┼─────────────┼────────────────────┼────────────────────┼──────────────────────┼─────────────┼──────────────┼──────────────┤\n│  7 │ 7       │     1000 │         249 │       249 │           0 │                750 │ 1.0                │                  249 │         249 │          249 │          249 │\n├────┼─────────┼──────────┼─────────────┼───────────┼─────────────┼────────────────────┼────────────────────┼──────────────────────┼─────────────┼──────────────┼──────────────┤\n│  8 │ 8       │     1000 │         866 │       866 │           0 │                134 │ 1.0                │                  866 │         866 │          866 │          866 │\n├────┼─────────┼──────────┼─────────────┼───────────┼─────────────┼────────────────────┼────────────────────┼──────────────────────┼─────────────┼──────────────┼──────────────┤\n│  9 │ 9       │     1000 │         805 │       804 │           1 │                196 │ 0.9987577639751553 │                  804 │         804 │          804 │          804 │\n├────┼─────────┼──────────┼─────────────┼───────────┼─────────────┼────────────────────┼────────────────────┼──────────────────────┼─────────────┼──────────────┼──────────────┤\n│ 10 │ Total   │    10000 │        3821 │      3817 │           4 │               6179 │                    │                 3288 │        3817 │         3817 │         3288 │\n╘════╧═════════╧══════════╧═════════════╧═══════════╧═════════════╧════════════════════╧════════════════════╧══════════════════════╧═════════════╧══════════════╧══════════════╛\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T04:50:03.541469Z","iopub.execute_input":"2024-11-06T04:50:03.541853Z","iopub.status.idle":"2024-11-06T04:54:26.086416Z","shell.execute_reply.started":"2024-11-06T04:50:03.541817Z","shell.execute_reply":"2024-11-06T04:54:26.085394Z"}},"outputs":[{"name":"stdout","text":"Epoch [1/10], Average Training Loss: 0.2322\nEpoch [1/10], Overall Test Accuracy: 92.01%\nEpoch [2/10], Average Training Loss: 0.2233\nEpoch [2/10], Overall Test Accuracy: 91.66%\nEpoch [3/10], Average Training Loss: 0.2203\nEpoch [3/10], Overall Test Accuracy: 92.33%\nEpoch [4/10], Average Training Loss: 0.2171\nEpoch [4/10], Overall Test Accuracy: 92.17%\nEpoch [5/10], Average Training Loss: 0.2180\nEpoch [5/10], Overall Test Accuracy: 92.35%\nEpoch [6/10], Average Training Loss: 0.2133\nEpoch [6/10], Overall Test Accuracy: 92.23%\nEpoch [7/10], Average Training Loss: 0.2129\nEpoch [7/10], Overall Test Accuracy: 92.46%\nEpoch [8/10], Average Training Loss: 0.2115\nEpoch [8/10], Overall Test Accuracy: 92.40%\nEpoch [9/10], Average Training Loss: 0.2085\nEpoch [9/10], Overall Test Accuracy: 92.50%\nEpoch [10/10], Average Training Loss: 0.2088\nEpoch [10/10], Overall Test Accuracy: 92.33%\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T04:56:02.919884Z","iopub.execute_input":"2024-11-06T04:56:02.920415Z","iopub.status.idle":"2024-11-06T04:56:29.404603Z","shell.execute_reply.started":"2024-11-06T04:56:02.920345Z","shell.execute_reply":"2024-11-06T04:56:29.403589Z"}},"outputs":[{"name":"stdout","text":"\nSummary for Confidence Threshold 0.99 - Epoch 10\n╒════╤═════════╤══════════╤═════════════╤═══════════╤═════════════╤════════════════════╤════════════════════╤══════════════════════╤═════════════╤══════════════╤══════════════╕\n│    │ Class   │   Actual │   Predicted │   Correct │   Incorrect │   Unconfident (-1) │ Accuracy           │   Score_Contribution │   Score_0.9 │   Score_0.95 │   Score_0.99 │\n╞════╪═════════╪══════════╪═════════════╪═══════════╪═════════════╪════════════════════╪════════════════════╪══════════════════════╪═════════════╪══════════════╪══════════════╡\n│  0 │ 0       │     1000 │         645 │       625 │          20 │                360 │ 0.9689922480620154 │                -1290 │         625 │          625 │        -1290 │\n├────┼─────────┼──────────┼─────────────┼───────────┼─────────────┼────────────────────┼────────────────────┼──────────────────────┼─────────────┼──────────────┼──────────────┤\n│  1 │ 1       │     1000 │         981 │       980 │           1 │                 16 │ 0.9989806320081549 │                  980 │         980 │          980 │          980 │\n├────┼─────────┼──────────┼─────────────┼───────────┼─────────────┼────────────────────┼────────────────────┼──────────────────────┼─────────────┼──────────────┼──────────────┤\n│  2 │ 2       │     1000 │         763 │       741 │          22 │                242 │ 0.9711664482306684 │                -1526 │         741 │          741 │        -1526 │\n├────┼─────────┼──────────┼─────────────┼───────────┼─────────────┼────────────────────┼────────────────────┼──────────────────────┼─────────────┼──────────────┼──────────────┤\n│  3 │ 3       │     1000 │         737 │       719 │          18 │                271 │ 0.9755766621438263 │                -1474 │         719 │          719 │        -1474 │\n├────┼─────────┼──────────┼─────────────┼───────────┼─────────────┼────────────────────┼────────────────────┼──────────────────────┼─────────────┼──────────────┼──────────────┤\n│  4 │ 4       │     1000 │         735 │       715 │          20 │                269 │ 0.9727891156462585 │                -1470 │         715 │          715 │        -1470 │\n├────┼─────────┼──────────┼─────────────┼───────────┼─────────────┼────────────────────┼────────────────────┼──────────────────────┼─────────────┼──────────────┼──────────────┤\n│  5 │ 5       │     1000 │         959 │       953 │           6 │                 33 │ 0.9937434827945777 │                  953 │         953 │          953 │          953 │\n├────┼─────────┼──────────┼─────────────┼───────────┼─────────────┼────────────────────┼────────────────────┼──────────────────────┼─────────────┼──────────────┼──────────────┤\n│  6 │ 6       │     1000 │         451 │       437 │          14 │                520 │ 0.9689578713968958 │                 -902 │         437 │          437 │         -902 │\n├────┼─────────┼──────────┼─────────────┼───────────┼─────────────┼────────────────────┼────────────────────┼──────────────────────┼─────────────┼──────────────┼──────────────┤\n│  7 │ 7       │     1000 │         962 │       939 │          23 │                 58 │ 0.9760914760914761 │                -1924 │         939 │          939 │        -1924 │\n├────┼─────────┼──────────┼─────────────┼───────────┼─────────────┼────────────────────┼────────────────────┼──────────────────────┼─────────────┼──────────────┼──────────────┤\n│  8 │ 8       │     1000 │         991 │       981 │          10 │                 19 │ 0.9899091826437941 │                -1982 │         981 │          981 │        -1982 │\n├────┼─────────┼──────────┼─────────────┼───────────┼─────────────┼────────────────────┼────────────────────┼──────────────────────┼─────────────┼──────────────┼──────────────┤\n│  9 │ 9       │     1000 │         907 │       903 │           4 │                 81 │ 0.9955898566703418 │                  903 │         903 │          903 │          903 │\n├────┼─────────┼──────────┼─────────────┼───────────┼─────────────┼────────────────────┼────────────────────┼──────────────────────┼─────────────┼──────────────┼──────────────┤\n│ 10 │ Total   │    10000 │        8131 │      7993 │         138 │               1869 │                    │                -7732 │        7993 │         7993 │        -7732 │\n╘════╧═════════╧══════════╧═════════════╧═══════════╧═════════════╧════════════════════╧════════════════════╧══════════════════════╧═════════════╧══════════════╧══════════════╛\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Temperature scaling parameter\ntemperature = 2.0  # Adjust temperature to a suitable value (can be tuned)\ndef calculate_summary(actual_labels, predicted_labels, confidence_threshold=0.90):\n    # Determine the number of classes dynamically\n    classes = sorted(set(actual_labels) - {-1})\n    num_classes = len(classes)\n\n    # Initialize summary data\n    class_counts = {cls: 0 for cls in classes}\n    predictions_made = {cls: 0 for cls in classes}\n    correct_predictions = {cls: 0 for cls in classes}\n    unconfident_predictions = {cls: 0 for cls in classes}\n    \n    # Additional thresholds for score calculation\n    thresholds = [0.90, 0.95, 0.99]\n    scores_for_thresholds = {f\"Score_{threshold}\": {cls: 0 for cls in classes} for threshold in thresholds}\n    scores_for_thresholds[\"Score_Contribution\"] = {cls: 0 for cls in classes}  # Custom threshold score\n\n    # Process each prediction\n    for actual, predicted in zip(actual_labels, predicted_labels):\n        class_counts[actual] += 1\n        if predicted == actual:\n            correct_predictions[actual] += 1\n        if predicted == -1:\n            unconfident_predictions[actual] += 1\n        elif predicted in classes:\n            predictions_made[predicted] += 1\n    \n    # Calculate accuracy and score contribution for each class and each threshold\n    data = []\n    for cls in classes:\n        if predictions_made[cls] > 0:\n            accuracy = correct_predictions[cls] / predictions_made[cls]\n        else:\n            accuracy = 0\n\n        # Calculate score contributions for each threshold\n        score_contributions = {}\n        for threshold in thresholds:\n            if accuracy >= threshold:\n                score_contribution = correct_predictions[cls]\n            else:\n                score_contribution = -2 * predictions_made[cls]\n            score_contributions[f\"Score_{threshold}\"] = score_contribution\n\n        # Calculate score contribution for the custom threshold\n        if accuracy >= confidence_threshold:\n            score_contribution = correct_predictions[cls]\n        else:\n            score_contribution = -2 * predictions_made[cls]\n\n        # Append the row to data with all calculated values\n        data.append({\n            \"Class\": cls,\n            \"Actual\": class_counts[cls],\n            \"Predicted\": predictions_made[cls],\n            \"Correct\": correct_predictions[cls],\n            \"Incorrect\": predictions_made[cls] - correct_predictions[cls],\n            \"Unconfident (-1)\": unconfident_predictions[cls],\n            \"Accuracy\": accuracy,\n            \"Score_Contribution\": score_contribution,  # Custom threshold column\n            **score_contributions  # Add other threshold score columns dynamically\n        })\n\n    # Create a summary DataFrame with scores for each threshold\n    summary_df = pd.DataFrame(data)\n\n    # Calculate totals for each relevant column\n    total_row = {\n        \"Class\": \"Total\",\n        \"Actual\": sum(class_counts.values()),\n        \"Predicted\": sum(predictions_made.values()),\n        \"Correct\": sum(correct_predictions.values()),\n        \"Incorrect\": sum(predictions_made.values()) - sum(correct_predictions.values()),\n        \"Unconfident (-1)\": sum(unconfident_predictions.values()),\n        \"Accuracy\": \"\",  # Leave Accuracy empty in the total row\n        \"Score_Contribution\": summary_df[\"Score_Contribution\"].sum(),  # Custom threshold total\n    }\n\n    # Add totals for each additional score threshold\n    for threshold in thresholds:\n        total_row[f\"Score_{threshold}\"] = summary_df[f\"Score_{threshold}\"].sum()\n\n    # Convert total_row to DataFrame and use pd.concat to add it to summary_df\n    total_df = pd.DataFrame([total_row])\n    summary_df = pd.concat([summary_df, total_df], ignore_index=True)\n\n    return summary_df\n\n# Use evaluate_with_temperature in place of evaluate\nsample_ids, predicted_labels = evaluate_with_temperature(model, test_loader, temperature=temperature)\nsummary_df = calculate_summary(actual_labels, predicted_labels, confidence_threshold=0.99)\nprint(f\"\\nSummary with Temperature Scaling (T={temperature})\")\nprint(tabulate(summary_df, headers='keys', tablefmt='fancy_grid'))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T05:04:41.290328Z","iopub.execute_input":"2024-11-06T05:04:41.291301Z","iopub.status.idle":"2024-11-06T05:04:43.774703Z","shell.execute_reply.started":"2024-11-06T05:04:41.291245Z","shell.execute_reply":"2024-11-06T05:04:43.773699Z"}},"outputs":[{"name":"stdout","text":"\nSummary with Temperature Scaling (T=2.0)\n╒════╤═════════╤══════════╤═════════════╤═══════════╤═════════════╤════════════════════╤════════════════════╤══════════════════════╤═════════════╤══════════════╤══════════════╕\n│    │ Class   │   Actual │   Predicted │   Correct │   Incorrect │   Unconfident (-1) │ Accuracy           │   Score_Contribution │   Score_0.9 │   Score_0.95 │   Score_0.99 │\n╞════╪═════════╪══════════╪═════════════╪═══════════╪═════════════╪════════════════════╪════════════════════╪══════════════════════╪═════════════╪══════════════╪══════════════╡\n│  0 │ 0       │     1000 │         402 │       401 │           1 │                594 │ 0.9975124378109452 │                  401 │         401 │          401 │          401 │\n├────┼─────────┼──────────┼─────────────┼───────────┼─────────────┼────────────────────┼────────────────────┼──────────────────────┼─────────────┼──────────────┼──────────────┤\n│  1 │ 1       │     1000 │         959 │       959 │           0 │                 40 │ 1.0                │                  959 │         959 │          959 │          959 │\n├────┼─────────┼──────────┼─────────────┼───────────┼─────────────┼────────────────────┼────────────────────┼──────────────────────┼─────────────┼──────────────┼──────────────┤\n│  2 │ 2       │     1000 │         424 │       421 │           3 │                579 │ 0.9929245283018868 │                  421 │         421 │          421 │          421 │\n├────┼─────────┼──────────┼─────────────┼───────────┼─────────────┼────────────────────┼────────────────────┼──────────────────────┼─────────────┼──────────────┼──────────────┤\n│  3 │ 3       │     1000 │         426 │       423 │           3 │                577 │ 0.9929577464788732 │                  423 │         423 │          423 │          423 │\n├────┼─────────┼──────────┼─────────────┼───────────┼─────────────┼────────────────────┼────────────────────┼──────────────────────┼─────────────┼──────────────┼──────────────┤\n│  4 │ 4       │     1000 │         348 │       347 │           1 │                653 │ 0.9971264367816092 │                  347 │         347 │          347 │          347 │\n├────┼─────────┼──────────┼─────────────┼───────────┼─────────────┼────────────────────┼────────────────────┼──────────────────────┼─────────────┼──────────────┼──────────────┤\n│  5 │ 5       │     1000 │         896 │       893 │           3 │                104 │ 0.9966517857142857 │                  893 │         893 │          893 │          893 │\n├────┼─────────┼──────────┼─────────────┼───────────┼─────────────┼────────────────────┼────────────────────┼──────────────────────┼─────────────┼──────────────┼──────────────┤\n│  6 │ 6       │     1000 │         244 │       243 │           1 │                751 │ 0.9959016393442623 │                  243 │         243 │          243 │          243 │\n├────┼─────────┼──────────┼─────────────┼───────────┼─────────────┼────────────────────┼────────────────────┼──────────────────────┼─────────────┼──────────────┼──────────────┤\n│  7 │ 7       │     1000 │         786 │       782 │           4 │                216 │ 0.9949109414758269 │                  782 │         782 │          782 │          782 │\n├────┼─────────┼──────────┼─────────────┼───────────┼─────────────┼────────────────────┼────────────────────┼──────────────────────┼─────────────┼──────────────┼──────────────┤\n│  8 │ 8       │     1000 │         951 │       948 │           3 │                 52 │ 0.9968454258675079 │                  948 │         948 │          948 │          948 │\n├────┼─────────┼──────────┼─────────────┼───────────┼─────────────┼────────────────────┼────────────────────┼──────────────────────┼─────────────┼──────────────┼──────────────┤\n│  9 │ 9       │     1000 │         811 │       810 │           1 │                187 │ 0.998766954377312  │                  810 │         810 │          810 │          810 │\n├────┼─────────┼──────────┼─────────────┼───────────┼─────────────┼────────────────────┼────────────────────┼──────────────────────┼─────────────┼──────────────┼──────────────┤\n│ 10 │ Total   │    10000 │        6247 │      6227 │          20 │               3753 │                    │                 6227 │        6227 │         6227 │         6227 │\n╘════╧═════════╧══════════╧═════════════╧═══════════╧═════════════╧════════════════════╧════════════════════╧══════════════════════╧═════════════╧══════════════╧══════════════╛\n","output_type":"stream"}],"execution_count":8}]}