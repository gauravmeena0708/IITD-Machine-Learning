{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f8074d9",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-10-18T16:23:58.441924Z",
     "iopub.status.busy": "2024-10-18T16:23:58.441548Z",
     "iopub.status.idle": "2024-10-18T19:05:48.392636Z",
     "shell.execute_reply": "2024-10-18T19:05:48.391519Z"
    },
    "papermill": {
     "duration": 9709.957317,
     "end_time": "2024-10-18T19:05:48.394742",
     "exception": false,
     "start_time": "2024-10-18T16:23:58.437425",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data/cifar-100-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 169001437/169001437 [00:04<00:00, 34902777.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-100-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/251], Loss: 4.1057, Train Accuracy: 6.37%\n",
      "Test Accuracy: 11.40%\n",
      "High-confidence Predictions: 0, Percentage Correct High-confidence Predictions: 0.00%\n",
      "Model saved with accuracy: 11.40%\n",
      "Epoch [2/251], Loss: 3.5012, Train Accuracy: 15.03%\n",
      "Test Accuracy: 19.25%\n",
      "High-confidence Predictions: 41, Percentage Correct High-confidence Predictions: 82.93%\n",
      "Model saved with accuracy: 19.25%\n",
      "Epoch [3/251], Loss: 3.0033, Train Accuracy: 23.12%\n",
      "Test Accuracy: 26.28%\n",
      "High-confidence Predictions: 201, Percentage Correct High-confidence Predictions: 86.07%\n",
      "Model saved with accuracy: 26.28%\n",
      "Epoch [4/251], Loss: 2.5684, Train Accuracy: 30.45%\n",
      "Test Accuracy: 34.75%\n",
      "High-confidence Predictions: 432, Percentage Correct High-confidence Predictions: 93.29%\n",
      "Model saved with accuracy: 34.75%\n",
      "Epoch [5/251], Loss: 2.1537, Train Accuracy: 37.83%\n",
      "Test Accuracy: 41.50%\n",
      "High-confidence Predictions: 673, Percentage Correct High-confidence Predictions: 92.12%\n",
      "Model saved with accuracy: 41.50%\n",
      "Epoch [6/251], Loss: 1.8367, Train Accuracy: 43.47%\n",
      "Test Accuracy: 44.91%\n",
      "High-confidence Predictions: 1103, Percentage Correct High-confidence Predictions: 87.76%\n",
      "Model saved with accuracy: 44.91%\n",
      "Epoch [7/251], Loss: 1.5730, Train Accuracy: 48.08%\n",
      "Test Accuracy: 48.86%\n",
      "High-confidence Predictions: 1447, Percentage Correct High-confidence Predictions: 91.29%\n",
      "Model saved with accuracy: 48.86%\n",
      "Epoch [8/251], Loss: 1.3418, Train Accuracy: 52.69%\n",
      "Test Accuracy: 50.75%\n",
      "High-confidence Predictions: 1660, Percentage Correct High-confidence Predictions: 92.59%\n",
      "Model saved with accuracy: 50.75%\n",
      "Epoch [9/251], Loss: 1.1402, Train Accuracy: 56.35%\n",
      "Test Accuracy: 53.69%\n",
      "High-confidence Predictions: 2186, Percentage Correct High-confidence Predictions: 91.99%\n",
      "Model saved with accuracy: 53.69%\n",
      "Epoch [10/251], Loss: 0.9693, Train Accuracy: 59.50%\n",
      "Test Accuracy: 57.11%\n",
      "High-confidence Predictions: 2312, Percentage Correct High-confidence Predictions: 94.98%\n",
      "Model saved with accuracy: 57.11%\n",
      "Epoch [11/251], Loss: 0.8229, Train Accuracy: 62.51%\n",
      "Test Accuracy: 59.00%\n",
      "High-confidence Predictions: 2718, Percentage Correct High-confidence Predictions: 94.44%\n",
      "Model saved with accuracy: 59.00%\n",
      "Epoch [12/251], Loss: 0.6761, Train Accuracy: 65.42%\n",
      "Test Accuracy: 59.68%\n",
      "High-confidence Predictions: 3044, Percentage Correct High-confidence Predictions: 94.42%\n",
      "Model saved with accuracy: 59.68%\n",
      "Epoch [13/251], Loss: 0.5542, Train Accuracy: 67.75%\n",
      "Test Accuracy: 60.54%\n",
      "High-confidence Predictions: 3174, Percentage Correct High-confidence Predictions: 93.60%\n",
      "Model saved with accuracy: 60.54%\n",
      "Epoch [14/251], Loss: 0.4829, Train Accuracy: 69.06%\n",
      "Test Accuracy: 60.57%\n",
      "High-confidence Predictions: 3276, Percentage Correct High-confidence Predictions: 93.53%\n",
      "Model saved with accuracy: 60.57%\n",
      "Epoch [15/251], Loss: 0.3531, Train Accuracy: 71.89%\n",
      "Test Accuracy: 61.82%\n",
      "High-confidence Predictions: 3800, Percentage Correct High-confidence Predictions: 92.89%\n",
      "Model saved with accuracy: 61.82%\n",
      "Epoch [16/251], Loss: 0.2217, Train Accuracy: 74.54%\n",
      "Test Accuracy: 63.63%\n",
      "High-confidence Predictions: 3997, Percentage Correct High-confidence Predictions: 92.57%\n",
      "Model saved with accuracy: 63.63%\n",
      "Epoch [17/251], Loss: 0.1146, Train Accuracy: 76.33%\n",
      "Test Accuracy: 64.22%\n",
      "High-confidence Predictions: 4135, Percentage Correct High-confidence Predictions: 92.58%\n",
      "Model saved with accuracy: 64.22%\n",
      "Epoch [18/251], Loss: 0.0183, Train Accuracy: 78.38%\n",
      "Test Accuracy: 64.74%\n",
      "High-confidence Predictions: 4338, Percentage Correct High-confidence Predictions: 91.22%\n",
      "Model saved with accuracy: 64.74%\n",
      "Epoch [19/251], Loss: -0.0739, Train Accuracy: 80.29%\n",
      "Test Accuracy: 64.79%\n",
      "High-confidence Predictions: 4588, Percentage Correct High-confidence Predictions: 91.30%\n",
      "Model saved with accuracy: 64.79%\n",
      "Epoch [20/251], Loss: -0.1563, Train Accuracy: 82.26%\n",
      "Test Accuracy: 64.49%\n",
      "High-confidence Predictions: 4807, Percentage Correct High-confidence Predictions: 90.41%\n",
      "Early stopping counter: 1 out of 20\n",
      "Epoch [21/251], Loss: -0.2502, Train Accuracy: 83.89%\n",
      "Test Accuracy: 64.99%\n",
      "High-confidence Predictions: 4901, Percentage Correct High-confidence Predictions: 89.66%\n",
      "Model saved with accuracy: 64.99%\n",
      "Epoch [22/251], Loss: -0.3117, Train Accuracy: 85.30%\n",
      "Test Accuracy: 64.74%\n",
      "High-confidence Predictions: 5057, Percentage Correct High-confidence Predictions: 89.58%\n",
      "Early stopping counter: 1 out of 20\n",
      "Epoch [23/251], Loss: -0.3675, Train Accuracy: 86.43%\n",
      "Test Accuracy: 65.54%\n",
      "High-confidence Predictions: 5278, Percentage Correct High-confidence Predictions: 88.78%\n",
      "Model saved with accuracy: 65.54%\n",
      "Epoch [24/251], Loss: -0.4349, Train Accuracy: 87.91%\n",
      "Test Accuracy: 64.46%\n",
      "High-confidence Predictions: 5195, Percentage Correct High-confidence Predictions: 88.18%\n",
      "Early stopping counter: 1 out of 20\n",
      "Epoch [25/251], Loss: -0.5001, Train Accuracy: 89.21%\n",
      "Test Accuracy: 65.43%\n",
      "High-confidence Predictions: 5397, Percentage Correct High-confidence Predictions: 87.73%\n",
      "Early stopping counter: 2 out of 20\n",
      "Epoch [26/251], Loss: -0.5291, Train Accuracy: 89.82%\n",
      "Test Accuracy: 66.03%\n",
      "High-confidence Predictions: 5602, Percentage Correct High-confidence Predictions: 87.15%\n",
      "Model saved with accuracy: 66.03%\n",
      "Epoch [27/251], Loss: -0.5856, Train Accuracy: 91.11%\n",
      "Test Accuracy: 65.90%\n",
      "High-confidence Predictions: 5871, Percentage Correct High-confidence Predictions: 85.69%\n",
      "Early stopping counter: 1 out of 20\n",
      "Epoch [28/251], Loss: -0.6144, Train Accuracy: 91.59%\n",
      "Test Accuracy: 65.21%\n",
      "High-confidence Predictions: 5831, Percentage Correct High-confidence Predictions: 85.90%\n",
      "Early stopping counter: 2 out of 20\n",
      "Epoch [29/251], Loss: -0.6319, Train Accuracy: 92.13%\n",
      "Test Accuracy: 65.27%\n",
      "High-confidence Predictions: 5811, Percentage Correct High-confidence Predictions: 85.87%\n",
      "Early stopping counter: 3 out of 20\n",
      "Epoch [30/251], Loss: -0.6679, Train Accuracy: 92.81%\n",
      "Test Accuracy: 66.03%\n",
      "High-confidence Predictions: 5994, Percentage Correct High-confidence Predictions: 84.88%\n",
      "Early stopping counter: 4 out of 20\n",
      "Epoch [31/251], Loss: -0.6925, Train Accuracy: 93.40%\n",
      "Test Accuracy: 66.03%\n",
      "High-confidence Predictions: 6123, Percentage Correct High-confidence Predictions: 84.42%\n",
      "Early stopping counter: 5 out of 20\n",
      "Epoch [32/251], Loss: -0.7024, Train Accuracy: 93.53%\n",
      "Test Accuracy: 65.66%\n",
      "High-confidence Predictions: 6070, Percentage Correct High-confidence Predictions: 84.66%\n",
      "Early stopping counter: 6 out of 20\n",
      "Epoch [33/251], Loss: -0.7163, Train Accuracy: 93.84%\n",
      "Test Accuracy: 65.61%\n",
      "High-confidence Predictions: 6198, Percentage Correct High-confidence Predictions: 84.33%\n",
      "Early stopping counter: 7 out of 20\n",
      "Epoch [34/251], Loss: -0.7372, Train Accuracy: 94.34%\n",
      "Test Accuracy: 65.94%\n",
      "High-confidence Predictions: 6249, Percentage Correct High-confidence Predictions: 84.59%\n",
      "Early stopping counter: 8 out of 20\n",
      "Epoch [35/251], Loss: -0.7603, Train Accuracy: 94.85%\n",
      "Test Accuracy: 66.30%\n",
      "High-confidence Predictions: 6279, Percentage Correct High-confidence Predictions: 84.49%\n",
      "Model saved with accuracy: 66.30%\n",
      "Epoch [36/251], Loss: -0.7677, Train Accuracy: 94.98%\n",
      "Test Accuracy: 66.45%\n",
      "High-confidence Predictions: 6365, Percentage Correct High-confidence Predictions: 83.75%\n",
      "Model saved with accuracy: 66.45%\n",
      "Epoch [37/251], Loss: -0.7694, Train Accuracy: 94.98%\n",
      "Test Accuracy: 65.04%\n",
      "High-confidence Predictions: 6330, Percentage Correct High-confidence Predictions: 83.24%\n",
      "Early stopping counter: 1 out of 20\n",
      "Epoch [38/251], Loss: -0.7876, Train Accuracy: 95.44%\n",
      "Test Accuracy: 66.74%\n",
      "High-confidence Predictions: 6517, Percentage Correct High-confidence Predictions: 83.80%\n",
      "Model saved with accuracy: 66.74%\n",
      "Epoch [39/251], Loss: -0.7954, Train Accuracy: 95.59%\n",
      "Test Accuracy: 67.06%\n",
      "High-confidence Predictions: 6590, Percentage Correct High-confidence Predictions: 83.82%\n",
      "Model saved with accuracy: 67.06%\n",
      "Epoch [40/251], Loss: -0.8104, Train Accuracy: 96.00%\n",
      "Test Accuracy: 66.71%\n",
      "High-confidence Predictions: 6553, Percentage Correct High-confidence Predictions: 83.41%\n",
      "Early stopping counter: 1 out of 20\n",
      "Epoch [41/251], Loss: -0.8081, Train Accuracy: 95.78%\n",
      "Test Accuracy: 66.83%\n",
      "High-confidence Predictions: 6619, Percentage Correct High-confidence Predictions: 82.57%\n",
      "Early stopping counter: 2 out of 20\n",
      "Epoch [42/251], Loss: -0.8153, Train Accuracy: 96.03%\n",
      "Test Accuracy: 67.05%\n",
      "High-confidence Predictions: 6686, Percentage Correct High-confidence Predictions: 83.53%\n",
      "Early stopping counter: 3 out of 20\n",
      "Epoch [43/251], Loss: -0.8210, Train Accuracy: 96.18%\n",
      "Test Accuracy: 66.56%\n",
      "High-confidence Predictions: 6628, Percentage Correct High-confidence Predictions: 82.88%\n",
      "Early stopping counter: 4 out of 20\n",
      "Epoch [44/251], Loss: -0.8228, Train Accuracy: 96.25%\n",
      "Test Accuracy: 66.97%\n",
      "High-confidence Predictions: 6704, Percentage Correct High-confidence Predictions: 82.98%\n",
      "Early stopping counter: 5 out of 20\n",
      "Epoch [45/251], Loss: -0.8404, Train Accuracy: 96.56%\n",
      "Test Accuracy: 66.91%\n",
      "High-confidence Predictions: 6770, Percentage Correct High-confidence Predictions: 82.30%\n",
      "Early stopping counter: 6 out of 20\n",
      "Epoch [46/251], Loss: -0.8424, Train Accuracy: 96.62%\n",
      "Test Accuracy: 66.36%\n",
      "High-confidence Predictions: 6809, Percentage Correct High-confidence Predictions: 82.24%\n",
      "Early stopping counter: 7 out of 20\n",
      "Epoch [47/251], Loss: -0.8448, Train Accuracy: 96.71%\n",
      "Test Accuracy: 66.98%\n",
      "High-confidence Predictions: 6799, Percentage Correct High-confidence Predictions: 82.34%\n",
      "Early stopping counter: 8 out of 20\n",
      "Epoch [48/251], Loss: -0.8493, Train Accuracy: 96.72%\n",
      "Test Accuracy: 66.65%\n",
      "High-confidence Predictions: 6853, Percentage Correct High-confidence Predictions: 82.29%\n",
      "Early stopping counter: 9 out of 20\n",
      "Epoch [49/251], Loss: -0.8454, Train Accuracy: 96.64%\n",
      "Test Accuracy: 66.53%\n",
      "High-confidence Predictions: 6774, Percentage Correct High-confidence Predictions: 82.76%\n",
      "Early stopping counter: 10 out of 20\n",
      "Epoch [50/251], Loss: -0.8570, Train Accuracy: 96.98%\n",
      "Test Accuracy: 66.81%\n",
      "High-confidence Predictions: 6878, Percentage Correct High-confidence Predictions: 81.87%\n",
      "Early stopping counter: 11 out of 20\n",
      "Epoch [51/251], Loss: -0.8647, Train Accuracy: 97.08%\n",
      "Test Accuracy: 67.43%\n",
      "High-confidence Predictions: 6786, Percentage Correct High-confidence Predictions: 82.40%\n",
      "Model saved with accuracy: 67.43%\n",
      "Epoch [52/251], Loss: -0.8653, Train Accuracy: 97.09%\n",
      "Test Accuracy: 67.54%\n",
      "High-confidence Predictions: 6916, Percentage Correct High-confidence Predictions: 82.40%\n",
      "Model saved with accuracy: 67.54%\n",
      "Epoch [53/251], Loss: -0.8675, Train Accuracy: 97.22%\n",
      "Test Accuracy: 67.18%\n",
      "High-confidence Predictions: 6897, Percentage Correct High-confidence Predictions: 82.73%\n",
      "Early stopping counter: 1 out of 20\n",
      "Epoch [54/251], Loss: -0.8691, Train Accuracy: 97.18%\n",
      "Test Accuracy: 67.34%\n",
      "High-confidence Predictions: 6872, Percentage Correct High-confidence Predictions: 82.39%\n",
      "Early stopping counter: 2 out of 20\n",
      "Epoch [55/251], Loss: -0.8714, Train Accuracy: 97.22%\n",
      "Test Accuracy: 66.97%\n",
      "High-confidence Predictions: 7018, Percentage Correct High-confidence Predictions: 81.48%\n",
      "Early stopping counter: 3 out of 20\n",
      "Epoch [56/251], Loss: -0.8710, Train Accuracy: 97.23%\n",
      "Test Accuracy: 67.48%\n",
      "High-confidence Predictions: 7022, Percentage Correct High-confidence Predictions: 81.90%\n",
      "Early stopping counter: 4 out of 20\n",
      "Epoch [57/251], Loss: -0.8694, Train Accuracy: 97.19%\n",
      "Test Accuracy: 67.56%\n",
      "High-confidence Predictions: 6932, Percentage Correct High-confidence Predictions: 82.53%\n",
      "Model saved with accuracy: 67.56%\n",
      "Epoch [58/251], Loss: -0.8864, Train Accuracy: 97.56%\n",
      "Test Accuracy: 66.66%\n",
      "High-confidence Predictions: 6996, Percentage Correct High-confidence Predictions: 81.02%\n",
      "Early stopping counter: 1 out of 20\n",
      "Epoch [59/251], Loss: -0.8903, Train Accuracy: 97.71%\n",
      "Test Accuracy: 67.09%\n",
      "High-confidence Predictions: 6931, Percentage Correct High-confidence Predictions: 82.11%\n",
      "Early stopping counter: 2 out of 20\n",
      "Epoch [60/251], Loss: -0.8943, Train Accuracy: 97.73%\n",
      "Test Accuracy: 67.28%\n",
      "High-confidence Predictions: 7038, Percentage Correct High-confidence Predictions: 81.66%\n",
      "Early stopping counter: 3 out of 20\n",
      "Epoch [61/251], Loss: -0.8884, Train Accuracy: 97.66%\n",
      "Test Accuracy: 66.87%\n",
      "High-confidence Predictions: 6978, Percentage Correct High-confidence Predictions: 81.64%\n",
      "Early stopping counter: 4 out of 20\n",
      "Epoch [62/251], Loss: -0.8796, Train Accuracy: 97.45%\n",
      "Test Accuracy: 67.33%\n",
      "High-confidence Predictions: 7098, Percentage Correct High-confidence Predictions: 81.39%\n",
      "Early stopping counter: 5 out of 20\n",
      "Epoch [63/251], Loss: -0.8993, Train Accuracy: 97.91%\n",
      "Test Accuracy: 67.17%\n",
      "High-confidence Predictions: 7079, Percentage Correct High-confidence Predictions: 81.20%\n",
      "Early stopping counter: 6 out of 20\n",
      "Epoch [64/251], Loss: -0.8931, Train Accuracy: 97.76%\n",
      "Test Accuracy: 67.62%\n",
      "High-confidence Predictions: 7026, Percentage Correct High-confidence Predictions: 82.47%\n",
      "Model saved with accuracy: 67.62%\n",
      "Epoch [65/251], Loss: -0.8982, Train Accuracy: 97.85%\n",
      "Test Accuracy: 67.71%\n",
      "High-confidence Predictions: 7235, Percentage Correct High-confidence Predictions: 80.98%\n",
      "Model saved with accuracy: 67.71%\n",
      "Epoch [66/251], Loss: -0.9019, Train Accuracy: 97.90%\n",
      "Test Accuracy: 66.89%\n",
      "High-confidence Predictions: 7121, Percentage Correct High-confidence Predictions: 81.11%\n",
      "Early stopping counter: 1 out of 20\n",
      "Epoch [67/251], Loss: -0.9056, Train Accuracy: 98.02%\n",
      "Test Accuracy: 67.67%\n",
      "High-confidence Predictions: 7140, Percentage Correct High-confidence Predictions: 81.58%\n",
      "Early stopping counter: 2 out of 20\n",
      "Epoch [68/251], Loss: -0.9037, Train Accuracy: 97.97%\n",
      "Test Accuracy: 67.56%\n",
      "High-confidence Predictions: 7189, Percentage Correct High-confidence Predictions: 80.94%\n",
      "Early stopping counter: 3 out of 20\n",
      "Epoch [69/251], Loss: -0.9126, Train Accuracy: 98.16%\n",
      "Test Accuracy: 67.91%\n",
      "High-confidence Predictions: 7152, Percentage Correct High-confidence Predictions: 81.29%\n",
      "Model saved with accuracy: 67.91%\n",
      "Epoch [70/251], Loss: -0.9027, Train Accuracy: 97.92%\n",
      "Test Accuracy: 67.46%\n",
      "High-confidence Predictions: 7214, Percentage Correct High-confidence Predictions: 81.20%\n",
      "Early stopping counter: 1 out of 20\n",
      "Epoch [71/251], Loss: -0.9009, Train Accuracy: 97.85%\n",
      "Test Accuracy: 67.83%\n",
      "High-confidence Predictions: 7189, Percentage Correct High-confidence Predictions: 81.44%\n",
      "Early stopping counter: 2 out of 20\n",
      "Epoch [72/251], Loss: -0.9104, Train Accuracy: 98.04%\n",
      "Test Accuracy: 67.58%\n",
      "High-confidence Predictions: 7172, Percentage Correct High-confidence Predictions: 81.51%\n",
      "Early stopping counter: 3 out of 20\n",
      "Epoch [73/251], Loss: -0.9098, Train Accuracy: 98.09%\n",
      "Test Accuracy: 67.52%\n",
      "High-confidence Predictions: 7213, Percentage Correct High-confidence Predictions: 80.80%\n",
      "Early stopping counter: 4 out of 20\n",
      "Epoch [74/251], Loss: -0.9112, Train Accuracy: 98.20%\n",
      "Test Accuracy: 67.40%\n",
      "High-confidence Predictions: 7171, Percentage Correct High-confidence Predictions: 80.81%\n",
      "Early stopping counter: 5 out of 20\n",
      "Epoch [75/251], Loss: -0.9137, Train Accuracy: 98.17%\n",
      "Test Accuracy: 68.00%\n",
      "High-confidence Predictions: 7293, Percentage Correct High-confidence Predictions: 81.35%\n",
      "Model saved with accuracy: 68.00%\n",
      "Epoch [76/251], Loss: -0.9200, Train Accuracy: 98.37%\n",
      "Test Accuracy: 67.93%\n",
      "High-confidence Predictions: 7213, Percentage Correct High-confidence Predictions: 81.64%\n",
      "Early stopping counter: 1 out of 20\n",
      "Epoch [77/251], Loss: -0.9200, Train Accuracy: 98.27%\n",
      "Test Accuracy: 67.95%\n",
      "High-confidence Predictions: 7201, Percentage Correct High-confidence Predictions: 82.11%\n",
      "Early stopping counter: 2 out of 20\n",
      "Epoch [78/251], Loss: -0.9163, Train Accuracy: 98.28%\n",
      "Test Accuracy: 67.29%\n",
      "High-confidence Predictions: 7339, Percentage Correct High-confidence Predictions: 80.08%\n",
      "Early stopping counter: 3 out of 20\n",
      "Epoch [79/251], Loss: -0.9213, Train Accuracy: 98.30%\n",
      "Test Accuracy: 67.84%\n",
      "High-confidence Predictions: 7356, Percentage Correct High-confidence Predictions: 81.13%\n",
      "Early stopping counter: 4 out of 20\n",
      "Epoch [80/251], Loss: -0.9104, Train Accuracy: 98.11%\n",
      "Test Accuracy: 67.02%\n",
      "High-confidence Predictions: 7259, Percentage Correct High-confidence Predictions: 80.44%\n",
      "Early stopping counter: 5 out of 20\n",
      "Epoch [81/251], Loss: -0.9268, Train Accuracy: 98.44%\n",
      "Test Accuracy: 67.58%\n",
      "High-confidence Predictions: 7274, Percentage Correct High-confidence Predictions: 81.29%\n",
      "Early stopping counter: 6 out of 20\n",
      "Epoch [82/251], Loss: -0.9268, Train Accuracy: 98.48%\n",
      "Test Accuracy: 68.02%\n",
      "High-confidence Predictions: 7326, Percentage Correct High-confidence Predictions: 81.34%\n",
      "Model saved with accuracy: 68.02%\n",
      "Epoch [83/251], Loss: -0.9338, Train Accuracy: 98.62%\n",
      "Test Accuracy: 67.34%\n",
      "High-confidence Predictions: 7338, Percentage Correct High-confidence Predictions: 80.88%\n",
      "Early stopping counter: 1 out of 20\n",
      "Epoch [84/251], Loss: -0.9291, Train Accuracy: 98.54%\n",
      "Test Accuracy: 68.18%\n",
      "High-confidence Predictions: 7335, Percentage Correct High-confidence Predictions: 81.34%\n",
      "Model saved with accuracy: 68.18%\n",
      "Epoch [85/251], Loss: -0.9241, Train Accuracy: 98.37%\n",
      "Test Accuracy: 67.48%\n",
      "High-confidence Predictions: 7307, Percentage Correct High-confidence Predictions: 80.72%\n",
      "Early stopping counter: 1 out of 20\n",
      "Epoch [86/251], Loss: -0.8844, Train Accuracy: 97.59%\n",
      "Test Accuracy: 67.34%\n",
      "High-confidence Predictions: 7281, Percentage Correct High-confidence Predictions: 80.77%\n",
      "Early stopping counter: 2 out of 20\n",
      "Epoch [87/251], Loss: -0.9260, Train Accuracy: 98.46%\n",
      "Test Accuracy: 69.00%\n",
      "High-confidence Predictions: 7386, Percentage Correct High-confidence Predictions: 81.84%\n",
      "Model saved with accuracy: 69.00%\n",
      "Epoch [88/251], Loss: -0.9357, Train Accuracy: 98.61%\n",
      "Test Accuracy: 68.13%\n",
      "High-confidence Predictions: 7417, Percentage Correct High-confidence Predictions: 80.79%\n",
      "Early stopping counter: 1 out of 20\n",
      "Epoch [89/251], Loss: -0.9301, Train Accuracy: 98.49%\n",
      "Test Accuracy: 68.36%\n",
      "High-confidence Predictions: 7439, Percentage Correct High-confidence Predictions: 80.63%\n",
      "Early stopping counter: 2 out of 20\n",
      "Epoch [90/251], Loss: -0.9326, Train Accuracy: 98.56%\n",
      "Test Accuracy: 68.64%\n",
      "High-confidence Predictions: 7397, Percentage Correct High-confidence Predictions: 81.17%\n",
      "Early stopping counter: 3 out of 20\n",
      "Epoch [91/251], Loss: -0.9273, Train Accuracy: 98.48%\n",
      "Test Accuracy: 68.22%\n",
      "High-confidence Predictions: 7360, Percentage Correct High-confidence Predictions: 81.10%\n",
      "Early stopping counter: 4 out of 20\n",
      "Epoch [92/251], Loss: -0.9308, Train Accuracy: 98.53%\n",
      "Test Accuracy: 68.95%\n",
      "High-confidence Predictions: 7430, Percentage Correct High-confidence Predictions: 81.49%\n",
      "Early stopping counter: 5 out of 20\n",
      "Epoch [93/251], Loss: -0.9322, Train Accuracy: 98.64%\n",
      "Test Accuracy: 68.23%\n",
      "High-confidence Predictions: 7418, Percentage Correct High-confidence Predictions: 80.86%\n",
      "Early stopping counter: 6 out of 20\n",
      "Epoch [94/251], Loss: -0.9410, Train Accuracy: 98.71%\n",
      "Test Accuracy: 68.75%\n",
      "High-confidence Predictions: 7406, Percentage Correct High-confidence Predictions: 81.43%\n",
      "Early stopping counter: 7 out of 20\n",
      "Epoch [95/251], Loss: -0.9390, Train Accuracy: 98.70%\n",
      "Test Accuracy: 68.48%\n",
      "High-confidence Predictions: 7466, Percentage Correct High-confidence Predictions: 80.70%\n",
      "Early stopping counter: 8 out of 20\n",
      "Epoch [96/251], Loss: -0.9329, Train Accuracy: 98.52%\n",
      "Test Accuracy: 68.29%\n",
      "High-confidence Predictions: 7471, Percentage Correct High-confidence Predictions: 80.52%\n",
      "Early stopping counter: 9 out of 20\n",
      "Epoch [97/251], Loss: -0.9414, Train Accuracy: 98.76%\n",
      "Test Accuracy: 68.23%\n",
      "High-confidence Predictions: 7371, Percentage Correct High-confidence Predictions: 80.90%\n",
      "Early stopping counter: 10 out of 20\n",
      "Epoch [98/251], Loss: -0.9317, Train Accuracy: 98.53%\n",
      "Test Accuracy: 67.68%\n",
      "High-confidence Predictions: 7344, Percentage Correct High-confidence Predictions: 80.62%\n",
      "Early stopping counter: 11 out of 20\n",
      "Epoch [99/251], Loss: -0.9268, Train Accuracy: 98.42%\n",
      "Test Accuracy: 68.37%\n",
      "High-confidence Predictions: 7394, Percentage Correct High-confidence Predictions: 81.00%\n",
      "Early stopping counter: 12 out of 20\n",
      "Epoch [100/251], Loss: -0.9296, Train Accuracy: 98.50%\n",
      "Test Accuracy: 68.09%\n",
      "High-confidence Predictions: 7445, Percentage Correct High-confidence Predictions: 80.95%\n",
      "Early stopping counter: 13 out of 20\n",
      "Epoch [101/251], Loss: -0.9428, Train Accuracy: 98.84%\n",
      "Test Accuracy: 68.72%\n",
      "High-confidence Predictions: 7495, Percentage Correct High-confidence Predictions: 80.91%\n",
      "Early stopping counter: 14 out of 20\n",
      "Epoch [102/251], Loss: -0.9368, Train Accuracy: 98.68%\n",
      "Test Accuracy: 68.26%\n",
      "High-confidence Predictions: 7437, Percentage Correct High-confidence Predictions: 80.50%\n",
      "Early stopping counter: 15 out of 20\n",
      "Epoch [103/251], Loss: -0.9445, Train Accuracy: 98.80%\n",
      "Test Accuracy: 68.55%\n",
      "High-confidence Predictions: 7432, Percentage Correct High-confidence Predictions: 80.85%\n",
      "Early stopping counter: 16 out of 20\n",
      "Epoch [104/251], Loss: -0.9466, Train Accuracy: 98.83%\n",
      "Test Accuracy: 68.77%\n",
      "High-confidence Predictions: 7445, Percentage Correct High-confidence Predictions: 81.50%\n",
      "Early stopping counter: 17 out of 20\n",
      "Epoch [105/251], Loss: -0.9399, Train Accuracy: 98.72%\n",
      "Test Accuracy: 68.96%\n",
      "High-confidence Predictions: 7493, Percentage Correct High-confidence Predictions: 80.62%\n",
      "Early stopping counter: 18 out of 20\n",
      "Epoch [106/251], Loss: -0.9407, Train Accuracy: 98.73%\n",
      "Test Accuracy: 67.90%\n",
      "High-confidence Predictions: 7498, Percentage Correct High-confidence Predictions: 80.02%\n",
      "Early stopping counter: 19 out of 20\n",
      "Epoch [107/251], Loss: -0.9387, Train Accuracy: 98.68%\n",
      "Test Accuracy: 67.68%\n",
      "High-confidence Predictions: 7390, Percentage Correct High-confidence Predictions: 80.24%\n",
      "Early stopping counter: 20 out of 20\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# Check if GPU is available and set the device accordingly\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Hyperparameters\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 0.001\n",
    "WEIGHT_DECAY = 1e-4\n",
    "EPOCHS = 251\n",
    "CONFIDENCE_THRESHOLD = 0.95  # Confidence threshold for high-confidence predictions\n",
    "PATIENCE = 20  # Early stopping patience\n",
    "\n",
    "# Data augmentation and normalization for training and testing\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "# Load CIFAR-100 dataset\n",
    "train_dataset = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=transform_train)\n",
    "test_dataset = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Define ResNet block\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "# Define ResNet architecture\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes=100):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, out_channels, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.in_channels != out_channels:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
    "        self.in_channels = out_channels\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(out_channels, out_channels))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "def resnet101():\n",
    "    return ResNet(BasicBlock, [3, 4, 23, 3])\n",
    "\n",
    "# Test function to evaluate the model\n",
    "def test(model, test_loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    high_confidence_correct = 0\n",
    "    high_confidence_total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            probabilities = F.softmax(outputs, dim=1)\n",
    "            confidence, predicted = probabilities.max(1)\n",
    "\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            # High confidence predictions\n",
    "            high_confidence_mask = confidence > CONFIDENCE_THRESHOLD\n",
    "            high_confidence_total += high_confidence_mask.sum().item()\n",
    "            high_confidence_correct += (predicted[high_confidence_mask] == targets[high_confidence_mask]).sum().item()\n",
    "\n",
    "    test_accuracy = 100.0 * correct / total\n",
    "    if high_confidence_total > 0:\n",
    "        high_confidence_accuracy = 100.0 * high_confidence_correct / high_confidence_total\n",
    "    else:\n",
    "        high_confidence_accuracy = 0.0\n",
    "\n",
    "    print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n",
    "    print(f\"High-confidence Predictions: {high_confidence_total}, Percentage Correct High-confidence Predictions: {high_confidence_accuracy:.2f}%\")\n",
    "\n",
    "    return test_accuracy\n",
    "\n",
    "# Early stopping class\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, verbose=False):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.best_accuracy = 0\n",
    "\n",
    "    def __call__(self, accuracy, model):\n",
    "        if self.best_score is None:\n",
    "            self.best_score = accuracy\n",
    "            self.save_checkpoint(model)\n",
    "        elif accuracy <= self.best_score:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f\"Early stopping counter: {self.counter} out of {self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = accuracy\n",
    "            self.save_checkpoint(model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, model):\n",
    "        \"\"\"Saves the model when validation accuracy improves.\"\"\"\n",
    "        self.best_accuracy = self.best_score\n",
    "        torch.save(model.state_dict(), 'best_resnet101_cifar100.pth')\n",
    "        print(f\"Model saved with accuracy: {self.best_accuracy:.2f}%\")\n",
    "\n",
    "# Training function with early stopping\n",
    "def train_with_early_stopping(model, train_loader, test_loader, optimizer, criterion, epochs, device, patience):\n",
    "    model.to(device)\n",
    "    early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        train_accuracy = 100.0 * correct / total\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {total_loss/len(train_loader):.4f}, Train Accuracy: {train_accuracy:.2f}%\")\n",
    "\n",
    "        # Check validation accuracy after each epoch\n",
    "        test_accuracy = test(model, test_loader, device)\n",
    "\n",
    "        # Early stopping check\n",
    "        early_stopping(test_accuracy, model)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "# Custom loss function with high-confidence penalty\n",
    "class ConfidencePenaltyLoss(nn.Module):\n",
    "    def __init__(self, confidence_threshold=0.99, penalty_scale=5.0):\n",
    "        super(ConfidencePenaltyLoss, self).__init__()\n",
    "        self.cross_entropy_loss = nn.CrossEntropyLoss()\n",
    "        self.confidence_threshold = confidence_threshold\n",
    "        self.penalty_scale = penalty_scale\n",
    "\n",
    "    def forward(self, outputs, targets):\n",
    "        probabilities = F.softmax(outputs, dim=1)\n",
    "        confidence, predicted = probabilities.max(1)\n",
    "        \n",
    "        # Standard cross-entropy loss\n",
    "        loss = self.cross_entropy_loss(outputs, targets)\n",
    "        \n",
    "        # Penalize wrong predictions with high confidence\n",
    "        incorrect_high_confidence_mask = (predicted != targets) & (confidence > self.confidence_threshold)\n",
    "        high_confidence_penalty = confidence[incorrect_high_confidence_mask] * self.penalty_scale\n",
    "        penalty = high_confidence_penalty.sum()\n",
    "        \n",
    "        total_loss = loss + penalty\n",
    "        return total_loss\n",
    "\n",
    "# Label Smoothing Loss implementation\n",
    "class LabelSmoothingCrossEntropyLoss(nn.Module):\n",
    "    def __init__(self, smoothing=0.1):\n",
    "        \"\"\"\n",
    "        Constructor for the label smoothing loss.\n",
    "        :param smoothing: Label smoothing factor (between 0 and 1).\n",
    "        \"\"\"\n",
    "        super(LabelSmoothingCrossEntropyLoss, self).__init__()\n",
    "        self.smoothing = smoothing\n",
    "        self.confidence = 1.0 - smoothing\n",
    "\n",
    "    def forward(self, outputs, targets):\n",
    "        \"\"\"\n",
    "        Forward pass for label smoothing loss.\n",
    "        :param outputs: Predictions from the model (logits).\n",
    "        :param targets: Ground truth labels.\n",
    "        \"\"\"\n",
    "        log_probs = F.log_softmax(outputs, dim=-1)\n",
    "        # Create a smoothed target distribution\n",
    "        with torch.no_grad():\n",
    "            num_classes = outputs.size(-1)\n",
    "            smooth_targets = torch.full_like(log_probs, self.smoothing / (num_classes - 1))\n",
    "            smooth_targets.scatter_(1, targets.unsqueeze(1), self.confidence)\n",
    "        \n",
    "        loss = (-smooth_targets * log_probs).sum(dim=-1).mean()\n",
    "        return loss\n",
    "\n",
    "# Custom loss that focuses on high-confidence correct predictions\n",
    "class HighConfidenceCorrectLoss(nn.Module):\n",
    "    def __init__(self, confidence_threshold=0.99, penalty_scale=1.5, reward_scale=2.0):\n",
    "        \"\"\"\n",
    "        Custom loss to focus on high-confidence correct predictions.\n",
    "        :param confidence_threshold: Confidence level above which correct predictions are rewarded.\n",
    "        :param penalty_scale: Scale for penalizing high-confidence incorrect predictions.\n",
    "        :param reward_scale: Scale for rewarding high-confidence correct predictions.\n",
    "        \"\"\"\n",
    "        super(HighConfidenceCorrectLoss, self).__init__()\n",
    "        self.cross_entropy_loss = nn.CrossEntropyLoss()\n",
    "        self.confidence_threshold = confidence_threshold\n",
    "        self.penalty_scale = penalty_scale\n",
    "        self.reward_scale = reward_scale\n",
    "\n",
    "    def forward(self, outputs, targets):\n",
    "        probabilities = F.softmax(outputs, dim=1)\n",
    "        confidence, predicted = probabilities.max(1)\n",
    "\n",
    "        # Standard cross-entropy loss\n",
    "        base_loss = self.cross_entropy_loss(outputs, targets)\n",
    "\n",
    "        # High-confidence correct predictions\n",
    "        correct_high_confidence_mask = (predicted == targets) & (confidence > self.confidence_threshold)\n",
    "        incorrect_high_confidence_mask = (predicted != targets) & (confidence > self.confidence_threshold)\n",
    "\n",
    "        # Reward correct high-confidence predictions\n",
    "        reward = -confidence[correct_high_confidence_mask].sum() * self.reward_scale\n",
    "\n",
    "        # Penalize incorrect high-confidence predictions\n",
    "        penalty = confidence[incorrect_high_confidence_mask].sum() * self.penalty_scale\n",
    "\n",
    "        total_loss = base_loss + penalty + reward\n",
    "        return total_loss\n",
    "\n",
    "# Training function with focus on high-confidence correct predictions\n",
    "def train_with_high_confidence_focus(model, train_loader, test_loader, optimizer, criterion, epochs, device, patience):\n",
    "    model.to(device)\n",
    "    early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        high_confidence_correct = 0\n",
    "\n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            # Count high-confidence correct predictions\n",
    "            probabilities = F.softmax(outputs, dim=1)\n",
    "            confidence, _ = probabilities.max(1)\n",
    "            high_confidence_correct += (confidence > CONFIDENCE_THRESHOLD).sum().item()\n",
    "\n",
    "        train_accuracy = 100.0 * correct / total\n",
    "        high_confidence_ratio = 100.0 * high_confidence_correct / total\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {total_loss/len(train_loader):.4f}, \"\n",
    "              f\"Train Accuracy: {train_accuracy:.2f}%, High-Confidence Correct: {high_confidence_ratio:.2f}%\")\n",
    "\n",
    "        # Check validation accuracy after each epoch\n",
    "        test_accuracy = test(model, test_loader, device)\n",
    "        scheduler.step(test_accuracy)\n",
    "        # Early stopping check\n",
    "        early_stopping(test_accuracy, model)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "# Custom loss function that rewards high-confidence correct predictions\n",
    "class HighConfidenceRewardLoss(nn.Module):\n",
    "    def __init__(self, reward_scale=1.0):\n",
    "        super(HighConfidenceRewardLoss, self).__init__()\n",
    "        self.cross_entropy_loss = nn.CrossEntropyLoss()\n",
    "        self.reward_scale = reward_scale\n",
    "\n",
    "    def forward(self, outputs, targets):\n",
    "        probabilities = F.softmax(outputs, dim=1)\n",
    "        confidence, predicted = probabilities.max(1)\n",
    "        \n",
    "        # Standard cross-entropy loss\n",
    "        loss = self.cross_entropy_loss(outputs, targets)\n",
    "        \n",
    "        # Reward high-confidence correct predictions\n",
    "        correct_mask = predicted.eq(targets)\n",
    "        high_confidence_correct = confidence[correct_mask]\n",
    "        reward = (high_confidence_correct * self.reward_scale).sum()\n",
    "        \n",
    "        # Total loss is cross-entropy loss minus the reward\n",
    "        total_loss = loss - reward / outputs.size(0)  # Normalize by batch size\n",
    "        return total_loss\n",
    "\n",
    "# Initialize ResNet-101 and optimizer\n",
    "model = resnet101()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=5, verbose=True)\n",
    "criterion = HighConfidenceRewardLoss(reward_scale=1.0)\n",
    "\n",
    "# Train the model with early stopping\n",
    "train_with_early_stopping(model, train_loader, test_loader, optimizer, criterion, EPOCHS, device, PATIENCE)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 9713.973651,
   "end_time": "2024-10-18T19:05:49.641145",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-10-18T16:23:55.667494",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
